// Copyright Â© 2023-2026 Wei Shen <shenwei356@gmail.com>
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

package cmd

import (
	"bufio"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/shenwei356/LexicMap/lexicmap/cmd/genome"
	"github.com/shenwei356/bio/seq"
	"github.com/shenwei356/xopen"
	"github.com/spf13/cobra"
	"github.com/twotwotwo/sorts/sortutil"
)

var subseqCmd = &cobra.Command{
	Use:   "subseq",
	Short: "Extract subsequence via 1) reference name, sequence ID, position and strand, or 2) search result",
	Long: `Extract subsequence via 1) reference name, sequence ID, position and strand, or 2) search result

Input:
  - Manually specify reference name, sequence ID, region, and strand.
  - Or give the search result file generated by "lexicmap search".
    - If the search result data has no header row, after filtering using tools like awk,
      please switch on the flag -H/--no-header-row.

Tips:
  - The aligned region can be extended with -U/--upstream and/or -D/--downstream.
  - If the search results are merged from multiple indexes, it would report error
    "reference name not found". You can switch on -e/--ignore-err to ignore this.

Output:
  - FASTA format, with a sequence ID in the format of "seqid:begin-end:strand".
    The begin and end are positions in the indexed sequence, and begin is <= end.
    And the sequence is reverse-complementary when the strand is "-".

Attention:
  1. When manually specifying the genome and region, the option -s/--seq-id is optional.
     1) If given, the positions are these in the original sequence.
     2) If not given, the positions are these in the concatenated sequence.
  2. All degenerate bases in reference genomes were converted to the lexicographic first bases.
     E.g., N was converted to A. Therefore, consecutive A's in output might be N's in the genomes.

`,
	Run: func(cmd *cobra.Command, args []string) {
		opt := getOptions(cmd)
		seq.ValidateSeq = false

		timeStart0 := time.Now()

		// ------------------------------

		dbDir := getFlagString(cmd, "index")
		if dbDir == "" {
			checkError(fmt.Errorf("flag -d/--index needed"))
		}

		outFile := getFlagString(cmd, "out-file")
		lineWidth := getFlagNonNegativeInt(cmd, "line-width")

		upstream := getFlagNonNegativeInt(cmd, "upstream")
		downstream := getFlagNonNegativeInt(cmd, "downstream")

		// ---------------------------------------------------------------

		fileSearchResult := getFlagString(cmd, "search-result")
		maxOpenFiles := getFlagPositiveInt(cmd, "max-open-files")

		if fileSearchResult != "" {
			noHeader := getFlagBool(cmd, "no-header-row")

			ignoreErr := getFlagBool(cmd, "ignore-err")

			outputLog := opt.Verbose || opt.Log2File
			verbose := opt.Verbose

			bufferSizeS := getFlagString(cmd, "buffer-size")
			if bufferSizeS == "" {
				checkError(fmt.Errorf("value of buffer size. supported unit: K, M, G"))
			}

			bufferSize, err := ParseByteSize(bufferSizeS)
			if err != nil {
				checkError(fmt.Errorf("invalid value of buffer size. supported unit: K, M, G"))
			}

			buf := make([]byte, bufferSize)
			ncols := 20
			// items := make([]string, ncols)
			var poolItems = &sync.Pool{New: func() interface{} {
				items := make([]string, ncols)
				return &items
			}}

			fh, err := xopen.Ropen(fileSearchResult)
			checkError(err)

			// --------------------------------------------------
			if outputLog {
				log.Infof("loading index: %s", dbDir)
			}

			// info file
			fileInfo := filepath.Join(dbDir, FileInfo)
			info, err := readIndexInfo(fileInfo)
			if err != nil {
				checkError(fmt.Errorf("failed to read info file: %s", err))
			}
			if info.MainVersion != MainVersion {
				checkError(fmt.Errorf("index main versions do not match: %d (index) != %d (tool). please re-create the index", info.MainVersion, MainVersion))
			}

			if maxOpenFiles < info.GenomeBatches {
				log.Warningf("the value of --max-open-files (%d) should be larger than the number of genome batches (%d)", maxOpenFiles, info.GenomeBatches)
			}

			// genomes.map file for mapping index to genome id
			refname2idx, err := readGenomeMapName2Idx(filepath.Join(dbDir, FileGenomeIndex))
			if err != nil {
				checkError(fmt.Errorf("failed to read genomes index mapping file: %s", err))
			}

			// --------------------------------------------------
			// genome readers
			nRdr := maxOpenFiles / info.GenomeBatches // 1 is for the output file
			if nRdr > opt.NumCPUs {
				nRdr = opt.NumCPUs
			}
			if outputLog {
				log.Infof("  creating reader pools for %d genome batches, each with %d readers...", info.GenomeBatches, nRdr)
			}
			readers := make([]chan *genome.Reader, info.GenomeBatches)
			for i := 0; i < info.GenomeBatches; i++ {
				readers[i] = make(chan *genome.Reader, nRdr)
			}

			var wg sync.WaitGroup
			tokens := make(chan int, opt.NumCPUs)
			for i := 0; i < info.GenomeBatches; i++ {
				for j := 0; j < nRdr; j++ {
					tokens <- 1
					wg.Add(1)
					go func(i int) {
						fileGenomes := filepath.Join(dbDir, DirGenomes, batchDir(i), FileGenomes)
						rdr, err := genome.NewReader(fileGenomes)
						if err != nil {
							checkError(fmt.Errorf("failed to create genome reader: %s", err))
						}

						readers[i] <- rdr

						wg.Done()
						<-tokens
					}(i)
				}
			}
			wg.Wait()

			// --------------------------------------------------

			// output file handler
			outfh, gw, w, err := outStream(outFile, strings.HasSuffix(outFile, ".gz"), opt.CompressionLevel)
			checkError(err)
			defer func() {
				outfh.Flush()
				if gw != nil {
					gw.Close()
				}
				w.Close()
			}()

			if outputLog {
				log.Infof("extracting subsequences...")
			}

			scanner := bufio.NewScanner(fh)
			scanner.Buffer(buf, int(bufferSize))

			fmt2 := ">%s:%d-%d:%s query=%s sgenome=%s sseqid=%s qcovGnm=%s cls=%s hsp=%s qcovHSP=%s alenHSP=%s " +
				"pident=%s gaps=%s qstart=%s qend=%s sstart=%s send=%s sstr=%s slen=%s evalue=%s bitscore=%s\n"

			// output
			type Subseq struct {
				ID     uint64
				Header string
				Seq    *seq.Seq
				Genome *genome.Genome
			}
			var poolSubseq = &sync.Pool{New: func() interface{} {
				return &Subseq{}
			}}
			ch := make(chan *Subseq, opt.NumCPUs)
			m := make(map[uint64]*Subseq, opt.NumCPUs) // the buffer to output sorte
			done := make(chan int)
			var nSuccess int
			go func() {
				var id, _id uint64
				var ok bool
				var _n int
				for result := range ch {
					_n++
					if verbose && ((_n < 1024 && _n&127 == 0) || _n&1023 == 0) {
						fmt.Fprintf(os.Stderr, "\r%d subsequences extracted from %d records", nSuccess, _n)
					}

					_id = result.ID
					if _id == id {
						if result.Seq != nil {
							nSuccess++
							outfh.WriteString(result.Header)
							outfh.Write(result.Seq.FormatSeq(lineWidth))
							outfh.WriteByte('\n')
							genome.RecycleGenome(result.Genome)
							poolSubseq.Put(result)
						}

						id++
						continue
					}

					m[_id] = result

					if result, ok = m[id]; ok {
						if result.Seq != nil {
							nSuccess++
							outfh.WriteString(result.Header)
							outfh.Write(result.Seq.FormatSeq(lineWidth))
							outfh.WriteByte('\n')
							genome.RecycleGenome(result.Genome)
							poolSubseq.Put(result)
						}

						delete(m, id)
						id++
					}
				}
				if len(m) > 0 {
					ids := make([]uint64, len(m))
					i := 0
					for id = range m {
						ids[i] = id
						i++
					}
					sortutil.Uint64s(ids)
					var result *Subseq
					for _, id = range ids {
						result = m[id]

						if result.Seq != nil {
							nSuccess++
							outfh.WriteString(result.Header)
							outfh.Write(result.Seq.FormatSeq(lineWidth))
							outfh.WriteByte('\n')
							genome.RecycleGenome(result.Genome)
							poolSubseq.Put(result)
						}
					}
				}

				if verbose {
					fmt.Fprintf(os.Stderr, "\r%d subsequences extracted from %d records", nSuccess, _n)
					fmt.Fprintln(os.Stderr)
				}

				done <- 1
			}()

			// output ^

			token := make(chan int, opt.NumCPUs)

			var line string
			var n uint64
			headerLine := !noHeader

			for scanner.Scan() {
				line = strings.TrimRight(scanner.Text(), "\r\n")
				if line == "" {
					continue
				}
				if headerLine {
					headerLine = false
					continue
				}

				wg.Add(1)
				token <- 1
				go func(line string, n uint64) {
					var query, qlen, hits, sgenome, sseqid, qcovGnm, cls, hsp, qcovHSP, alenHSP string
					var pident, gaps, qstart, qend, _sstart, _send, sstr, slen, evalue, bitscore string
					var sstart, send int
					var __end int
					var eStart, eEnd int

					items := poolItems.Get().(*[]string)

					stringSplitNByByte(line, '\t', ncols, items)
					if len(*items) < ncols {
						checkError(fmt.Errorf("the input has only %d columns (<%d), please use output from 'lexicmap search'", ncols, len(*items)))
					}

					defer func() {
						poolItems.Put(items)

						wg.Done()
						<-token
					}()

					bitscore = (*items)[19]

					query = (*items)[0]
					qlen = (*items)[1]
					_ = qlen
					hits = (*items)[2]
					_ = hits

					sgenome = (*items)[3]
					sseqid = (*items)[4]
					qcovGnm = (*items)[5]
					cls = (*items)[6]
					hsp = (*items)[7]
					qcovHSP = (*items)[8]
					alenHSP = (*items)[9]
					pident = (*items)[10]
					gaps = (*items)[11]
					qstart = (*items)[12]
					qend = (*items)[13]
					_sstart = (*items)[14]
					_send = (*items)[15]
					sstr = (*items)[16]
					slen = (*items)[17]
					evalue = (*items)[18]

					if i := strings.IndexByte(bitscore, '\t'); i > 0 { // the search result has >=20 columns
						bitscore = bitscore[:i]
					}

					var batchIDAndRefIDs *[]uint64
					var ok bool
					// var fileGenome string
					var tSeq *genome.Genome
					var genomeBatch, genomeIdx int
					var rdr *genome.Reader

					if batchIDAndRefIDs, ok = refname2idx[sgenome]; !ok {
						if ignoreErr {
							subseq := poolSubseq.Get().(*Subseq)
							subseq.ID = n
							subseq.Header = ""
							subseq.Seq = nil
							subseq.Genome = nil
							ch <- subseq
							return
						} else {
							checkError(fmt.Errorf("reference name not found: %s. Please switch on -e/--ignore-err if search results are merged from multiple indexes", sgenome))
						}
					}

					sstart, _ = strconv.Atoi(_sstart)
					send, _ = strconv.Atoi(_send)

					if sstr == "+" {
						eStart = sstart - upstream
						eEnd = send + downstream
					} else {
						eStart = sstart - downstream
						eEnd = send + upstream
					}
					if eStart < 1 {
						eStart = 1
					}

					var batchIDAndRefID uint64
					found := false
					_sseqid := []byte(sseqid)
					var err error
					for _, batchIDAndRefID = range *batchIDAndRefIDs {
						genomeBatch = int(batchIDAndRefID >> BITS_GENOME_IDX)
						genomeIdx = int(batchIDAndRefID & MASK_GENOME_IDX)

						rdr = <-readers[genomeBatch]

						tSeq, __end, err = rdr.SubSeq2(genomeIdx, _sseqid, eStart-1, eEnd-1)
						__end++ // returned end is 0-based.

						// if __end != send {
						// 	checkError(fmt.Errorf("unequal end position: %d != %d", send, __end))
						// }

						readers[genomeBatch] <- rdr

						if err == nil && tSeq != nil {
							found = true
							break
						}
						// the sequence might not be in this genome chunk
					}
					if !found {
						if ignoreErr {
							subseq := poolSubseq.Get().(*Subseq)
							subseq.ID = n
							subseq.Header = ""
							subseq.Seq = nil
							subseq.Genome = nil
							ch <- subseq
							return
						} else {
							checkError(fmt.Errorf("failed to extract subsequence: %s:%s-%s:%s with upstream=%d downstream=%d. Please switch on -e/--ignore-err if search results are merged from multiple indexes", sseqid, _sstart, _send, sstr, upstream, downstream))
						}
					}

					eEnd = __end // update end

					s, err := seq.NewSeq(seq.DNAredundant, tSeq.Seq)
					checkError(err)

					if sstr == "-" {
						s.RevComInplace()
					}

					header := fmt.Sprintf(fmt2, sseqid, eStart, eEnd, sstr,
						query, sgenome, sseqid, qcovGnm, cls, hsp, qcovHSP, alenHSP,
						pident, gaps, qstart, qend, _sstart, _send, sstr, slen, evalue, bitscore,
					)
					subseq := poolSubseq.Get().(*Subseq)
					subseq.ID = n
					subseq.Header = header
					subseq.Seq = s
					subseq.Genome = tSeq
					ch <- subseq

				}(line, n)

				n++
			}
			if err = scanner.Err(); err != nil {
				checkError(fmt.Errorf("failed to scan file %s: %s", fileSearchResult, err))
			}

			wg.Wait()
			close(ch)
			<-done

			if outputLog {
				log.Infof("%d subsequences extracted from %d records", nSuccess, n)
			}
			if n == 0 {
				log.Warningf("does the input has header row? If not, please switch on -H/--no-header-row")
			}

			for _, chRdr := range readers {
				wg.Add(1)
				go func(chRdr chan *genome.Reader) {
					close(chRdr)
					for rdr := range chRdr {
						checkError(rdr.Close())
					}
					wg.Done()
				}(chRdr)
			}
			wg.Wait()

			if outputLog {
				log.Info()
				log.Infof("elapsed time: %s", time.Since(timeStart0))
				log.Info()
			}

			return
		}

		// ---------------------------------------------------------------

		refname := getFlagString(cmd, "ref-name")
		if refname == "" {
			checkError(fmt.Errorf("flag -n/--ref-name needed"))
		}

		seqid := getFlagString(cmd, "seq-id")
		var concatenatedPositions bool
		if seqid == "" {
			concatenatedPositions = true
		}

		var reRegion = regexp.MustCompile(`\-?\d+:\-?\d+`)

		region := getFlagString(cmd, "region")
		if region == "" {
			checkError(fmt.Errorf("flag -r/--region needed"))
		}
		revcom := getFlagBool(cmd, "revcom")

		if !reRegion.MatchString(region) {
			checkError(fmt.Errorf(`invalid region: %s. type "lexicmap utils subseq -h" for more examples`, region))
		}
		var start, end int
		var err error

		r := strings.Split(region, ":")
		start, err = strconv.Atoi(r[0])
		checkError(err)
		end, err = strconv.Atoi(r[1])
		checkError(err)
		if start <= 0 || end <= 0 {
			checkError(fmt.Errorf("both begin and end position should not be <= 0"))
		}
		if start > end {
			checkError(fmt.Errorf("begin position should be < end position"))
		}

		// ---------------------------------------------------------------

		// info file
		fileInfo := filepath.Join(dbDir, FileInfo)
		info, err := readIndexInfo(fileInfo)
		if err != nil {
			checkError(fmt.Errorf("failed to read info file: %s", err))
		}
		if info.MainVersion != MainVersion {
			checkError(fmt.Errorf("index main versions do not match: %d (index) != %d (tool). please re-create the index", info.MainVersion, MainVersion))
		}

		// genomes.map file for mapping index to genome id
		m, err := readGenomeMapName2Idx(filepath.Join(dbDir, FileGenomeIndex))
		if err != nil {
			checkError(fmt.Errorf("failed to read genomes index mapping file: %s", err))
		}

		var batchIDAndRefIDs *[]uint64

		var ok bool
		if batchIDAndRefIDs, ok = m[refname]; !ok {
			checkError(fmt.Errorf("reference name not found: %s", refname))
		}

		var tSeq *genome.Genome
		var genomeBatch, genomeIdx int
		var rdr *genome.Reader

		var _end int

		var eStart, eEnd int
		if !revcom {
			eStart = start - upstream
			eEnd = end + downstream
		} else {
			eStart = start - downstream
			eEnd = end + upstream
		}
		if eStart < 1 {
			eStart = 1
		}

		found := false
		_seqid := []byte(seqid)
		for _, batchIDAndRefID := range *batchIDAndRefIDs {
			genomeBatch = int(batchIDAndRefID >> BITS_GENOME_IDX)
			genomeIdx = int(batchIDAndRefID & MASK_GENOME_IDX)

			fileGenome := filepath.Join(dbDir, DirGenomes, batchDir(genomeBatch), FileGenomes)
			rdr, err = genome.NewReader(fileGenome)
			if err != nil {
				checkError(fmt.Errorf("failed to read genome data file: %s", err))
			}

			if concatenatedPositions {
				tSeq, err = rdr.SubSeq(genomeIdx, eStart-1, eEnd-1)
			} else {
				tSeq, _end, err = rdr.SubSeq2(genomeIdx, _seqid, eStart-1, eEnd-1)
				_end++ // returned end is 0-based.
			}

			if err == nil && tSeq != nil {
				found = true
				break
				// checkError(fmt.Errorf("failed to read subsequence: %s", err))
			}
			// the sequence might not be in this genome chunk
		}
		if !found {
			checkError(fmt.Errorf("failed to extract subsequence: %s:%d-%d with upstream=%d downstream=%d: %s", refname, start, end, upstream, downstream, err))
		}

		eEnd = _end // update end

		// output file handler
		outfh, gw, w, err := outStream(outFile, strings.HasSuffix(outFile, ".gz"), opt.CompressionLevel)
		checkError(err)
		defer func() {
			outfh.Flush()
			if gw != nil {
				gw.Close()
			}
			w.Close()
		}()

		s, err := seq.NewSeq(seq.DNAredundant, tSeq.Seq)
		checkError(err)

		strand := "+"
		if revcom {
			strand = "-"
			s.RevComInplace()
		}

		if concatenatedPositions {
			fmt.Fprintf(outfh, ">%s:%d-%d:%s\n", refname, eStart, eEnd, strand)
		} else {
			fmt.Fprintf(outfh, ">%s:%d-%d:%s\n", seqid, eStart, eEnd, strand)
		}
		outfh.Write(s.FormatSeq(lineWidth))
		outfh.WriteByte('\n')

		genome.RecycleGenome(tSeq)
		checkError(rdr.Close())
	},
}

func init() {
	utilsCmd.AddCommand(subseqCmd)

	subseqCmd.Flags().StringP("index", "d", "",
		formatFlagUsage(`Index directory created by "lexicmap index".`))

	subseqCmd.Flags().StringP("ref-name", "n", "",
		formatFlagUsage(`Reference name.`))

	subseqCmd.Flags().StringP("seq-id", "s", "",
		formatFlagUsage(`Sequence ID. If the value is empty, the positions in the region are treated as that in the concatenated sequence.`))

	subseqCmd.Flags().StringP("out-file", "o", "-",
		formatFlagUsage(`Out file, supports the ".gz" suffix ("-" for stdout).`))

	subseqCmd.Flags().StringP("region", "r", "",
		formatFlagUsage(`Region of the subsequence (1-based).`))

	subseqCmd.Flags().BoolP("revcom", "R", false,
		formatFlagUsage("Extract subsequence on the negative strand."))

	subseqCmd.Flags().IntP("line-width", "w", 60,
		formatFlagUsage("Line width of sequence (0 for no wrap)."))

	// -------------------------------------------------------
	// from search result file

	subseqCmd.Flags().StringP("buffer-size", "b", "20M",
		formatFlagUsage(`Size of buffer, supported unit: K, M, G. You need increase the value when "bufio.Scanner: token too long" error reported`))

	subseqCmd.Flags().IntP("max-open-files", "", 1024,
		formatFlagUsage(`Maximum opened files. It mainly affects candidate subsequence extraction. Increase this value if you have hundreds of genome batches or have multiple queries, and do not forgot to set a bigger "ulimit -n" in shell if the value is > 1024.`))

	subseqCmd.Flags().StringP("search-result", "f", "",
		formatFlagUsage(`Use search result file from "lexicmap search" as input. It can be "-" to accept filtered result from stdin`))

	subseqCmd.Flags().BoolP("no-header-row", "H", false,
		formatFlagUsage(`The search result file has no header row, this happens when using tools like awk to filter the file.`))

	subseqCmd.Flags().IntP("upstream", "U", 0,
		formatFlagUsage(`Extract extra N bp on the upstream of the aligned/specified region.`))

	subseqCmd.Flags().IntP("downstream", "D", 0,
		formatFlagUsage(`Extract extra N bp on the downstream of the aligned/specified region.`))

	subseqCmd.Flags().BoolP("ignore-err", "e", false,
		formatFlagUsage(`Ignore errors such as 'reference name not found' or 'failed to extract subsequence'. Switch on this flag if search results are merged from multiple indexes.`))

	subseqCmd.SetUsageTemplate(usageTemplate(""))
}
