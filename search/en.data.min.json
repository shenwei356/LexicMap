[{"id":0,"href":"/LexicMap/tutorials/misc/index-gtdb/","title":"Indexing GTDB","parent":"More","content":"Info:\nhttps://gtdb.ecogenomic.org/ Tools:\nhttps://github.com/pirovc/genome_updater, for downloading genomes https://github.com/shenwei356/seqkit, for checking sequence files https://github.com/shenwei356/rush, for running jobs Data:\ntime genome_updater.sh -d \u0026quot;refseq,genbank\u0026quot; -g \u0026quot;archaea,bacteria\u0026quot; \\ -f \u0026quot;genomic.fna.gz\u0026quot; -o \u0026quot;GTDB_complete\u0026quot; -M \u0026quot;gtdb\u0026quot; -t 12 -m -L curl cd GTDB_complete/2024-01-30_19-34-40/ # ----------------- check the file integrity ----------------- genomes=files # corrupted files # find $genomes -name \u0026quot;*.gz\u0026quot; \\ fd \u0026quot;.gz$\u0026quot; $genomes \\ | rush --eta 'seqkit seq -w 0 {} \u0026gt; /dev/null; if [ $? -ne 0 ]; then echo {}; fi' \\ \u0026gt; failed.txt # empty files find $genomes -name \u0026quot;*.gz\u0026quot; -size 0 \u0026gt;\u0026gt; failed.txt # delete these files cat failed.txt | rush '/bin/rm {}' # redownload them: # run the genome_updater command again, with the flag -i Indexing. On a 48-CPU machine, time: 8h:19m:28s, ram: 73 GB, index size: 906 GB. If you don\u0026rsquo;t have enough memory, please decrease the value of -b.\nlexicmap index \\ -I files/ \\ --ref-name-regexp '^(\\w{3}_\\d{9}\\.\\d+)' \\ -O gtdb_complete.lmi --log gtdb_complete.lmi.log \\ -b 5000 Files:\n$ du -sh files gtdb_complete.lmi --apparent-size 413G files 907G gtdb_complete.lmi $ dirsize gtdb_complete.lmi gtdb_complete.lmi: 905.34 GiB (972,098,200,328) 542.34 GiB seeds 362.99 GiB genomes 9.60 MiB genomes.map.bin 156.28 KiB masks.bin 616 B info.toml 168 B genomes.chunks.bin ","description":"Info:\nhttps://gtdb.ecogenomic.org/ Tools:\nhttps://github.com/pirovc/genome_updater, for downloading genomes https://github.com/shenwei356/seqkit, for checking sequence files https://github.com/shenwei356/rush, for running jobs Data:\ntime genome_updater.sh -d \u0026quot;refseq,genbank\u0026quot; -g \u0026quot;archaea,bacteria\u0026quot; \\ -f \u0026quot;genomic.fna.gz\u0026quot; -o \u0026quot;GTDB_complete\u0026quot; -M \u0026quot;gtdb\u0026quot; -t 12 -m -L curl cd GTDB_complete/2024-01-30_19-34-40/ # ----------------- check the file integrity ----------------- genomes=files # corrupted files # find $genomes -name \u0026quot;*.gz\u0026quot; \\ fd \u0026quot;.gz$\u0026quot; $genomes \\ | rush --eta 'seqkit seq -w 0 {} \u0026gt; /dev/null; if [ $? -ne 0 ]; then echo {}; fi' \\ \u0026gt; failed.txt # empty files find $genomes -name \u0026quot;*.gz\u0026quot; -size 0 \u0026gt;\u0026gt; failed.txt # delete these files cat failed.txt | rush '/bin/rm {}' # redownload them: # run the genome_updater command again, with the flag -i Indexing. On a 48-CPU machine, time: 8h:19m:28s, ram: 73 GB, index size: 906 GB. If you don\u0026rsquo;t have enough memory, please decrease the value of -b.\n"},{"id":1,"href":"/LexicMap/usage/utils/masks/","title":"masks","parent":"utils","content":"$ lexicmap utils masks -h View masks of the index or generate new masks randomly Usage: lexicmap utils masks [flags] { -d \u0026lt;index path\u0026gt; | [-k \u0026lt;k\u0026gt;] [-n \u0026lt;masks\u0026gt;] [-s \u0026lt;seed\u0026gt;] } [-o out.tsv.gz] Flags: -h, --help help for masks -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. -k, --kmer int ► Maximum k-mer size. K needs to be \u0026lt;= 32. (default 31) -m, --masks int ► Number of masks. (default 40000) -o, --out-file string ► Out file, supports and recommends a \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) -p, --prefix int ► Length of mask k-mer prefix for checking low-complexity (0 for no checking). (default 15) -s, --seed int ► The seed for generating random masks. (default 1) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples $ lexicmap utils masks --quiet -d demo.lmi/ | head -n 10 1 AAAAAAATTCTCGGCGGTGTTTCCAGGCGCA 2 AAAAAACGTGGCGTCCCCTGTATAACGGCTA 3 AAAAAAGAGGGGAAGCAAGCTGAAGGATATG 4 AAAAAATACAGGCTGGCATCTTTAACCCACC 5 AAAAAATCCAGGGTTCCGTTAAGGATCTGTC 6 AAAAACATTCATGCTAGCATACCTTGGCAAC 7 AAAAACCACAATGTGGAAGCACGAGAGGATT 8 AAAAACCTGTACCCACCCGACGTGGATCCTC 9 AAAAACGTAGGCGTACCTCTCATAGCTTGTA 10 AAAAACTATGGATACTTGCCGTAAATCACCT $ lexicmap utils masks --quiet -d demo.lmi/ | tail -n 10 19991 TTTTTGAACTTGTGAAAAAGGCAGATGTGTG 19992 TTTTTGCGTTTATGCTGCCCTCAAACCATCT 19993 TTTTTGGATCCACTGTACGAGCACACTACCC 19994 TTTTTGTGGCTCATCGGGATCGGGAGCAGTC 19995 TTTTTTACATGTTGGGCTAGGGGCGGTTCAC 19996 TTTTTTATCGGACGCCAAGTTTGTAATCGTC 19997 TTTTTTCTTGCATCGTATTCAGCACGTTCCT 19998 TTTTTTGCCGAGTGACCCCGAAAAGCTCACA 19999 TTTTTTTATCGAGGCATGGTTGAAGACGGGT 20000 TTTTTTTCCGTAACTAGGTTCTGGCGATTCC # check a specific mask $ lexicmap utils masks --quiet -d demo.lmi/ -m 12345 12345 GCTGCACACGCAAAGACTCACGTCTTCAACG Freqency of prefixes.\n$ lexicmap utils masks --quiet -d demo.lmi/ \\ | csvtk mutate -Ht -f 2 -p \u0026#39;^(.{7})\u0026#39; \\ | csvtk freq -Ht -f 3 -nr \\ | head -n 10 AAAAAAT 2 AAAAACC 2 AAAAACT 2 AAAAAGG 2 AAAAAGT 2 AAAAATT 2 AAAACCA 2 AAAACCC 2 AAAACGA 2 AAAACTA 2 $ lexicmap utils masks --quiet -d demo.lmi/ \\ | csvtk mutate -Ht -f 2 -p \u0026#39;^(.{7})\u0026#39; \\ | csvtk freq -Ht -f 3 -n \\ | head -n 10 AAAAAAA 1 AAAAAAC 1 AAAAAAG 1 AAAAACA 1 AAAAACG 1 AAAAAGA 1 AAAAAGC 1 AAAAATA 1 AAAAATC 1 AAAAATG 1 Frequency of frequencies. i.e., for 20,000 masks, 47 = 16384. In them, 3,616 of them are duplicated 2 times. 12768 + 2 * 3616 = 20000.\n$ lexicmap utils masks --quiet -d demo.lmi/ \\ | csvtk mutate -Ht -f 2 -p \u0026#39;^(.{7})\u0026#39; \\ | csvtk freq -Ht -f 3 -n \\ | csvtk freq -Ht -f 2 -k 1 12768 2 3616 ","description":"$ lexicmap utils masks -h View masks of the index or generate new masks randomly Usage: lexicmap utils masks [flags] { -d \u0026lt;index path\u0026gt; | [-k \u0026lt;k\u0026gt;] [-n \u0026lt;masks\u0026gt;] [-s \u0026lt;seed\u0026gt;] } [-o out.tsv.gz] Flags: -h, --help help for masks -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. -k, --kmer int ► Maximum k-mer size. K needs to be \u0026lt;= 32. (default 31) -m, --masks int ► Number of masks. (default 40000) -o, --out-file string ► Out file, supports and recommends a \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) -p, --prefix int ► Length of mask k-mer prefix for checking low-complexity (0 for no checking). (default 15) -s, --seed int ► The seed for generating random masks. (default 1) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples $ lexicmap utils masks --quiet -d demo.lmi/ | head -n 10 1 AAAAAAATTCTCGGCGGTGTTTCCAGGCGCA 2 AAAAAACGTGGCGTCCCCTGTATAACGGCTA 3 AAAAAAGAGGGGAAGCAAGCTGAAGGATATG 4 AAAAAATACAGGCTGGCATCTTTAACCCACC 5 AAAAAATCCAGGGTTCCGTTAAGGATCTGTC 6 AAAAACATTCATGCTAGCATACCTTGGCAAC 7 AAAAACCACAATGTGGAAGCACGAGAGGATT 8 AAAAACCTGTACCCACCCGACGTGGATCCTC 9 AAAAACGTAGGCGTACCTCTCATAGCTTGTA 10 AAAAACTATGGATACTTGCCGTAAATCACCT $ lexicmap utils masks --quiet -d demo.lmi/ | tail -n 10 19991 TTTTTGAACTTGTGAAAAAGGCAGATGTGTG 19992 TTTTTGCGTTTATGCTGCCCTCAAACCATCT 19993 TTTTTGGATCCACTGTACGAGCACACTACCC 19994 TTTTTGTGGCTCATCGGGATCGGGAGCAGTC 19995 TTTTTTACATGTTGGGCTAGGGGCGGTTCAC 19996 TTTTTTATCGGACGCCAAGTTTGTAATCGTC 19997 TTTTTTCTTGCATCGTATTCAGCACGTTCCT 19998 TTTTTTGCCGAGTGACCCCGAAAAGCTCACA 19999 TTTTTTTATCGAGGCATGGTTGAAGACGGGT 20000 TTTTTTTCCGTAACTAGGTTCTGGCGATTCC # check a specific mask $ lexicmap utils masks --quiet -d demo.lmi/ -m 12345 12345 GCTGCACACGCAAAGACTCACGTCTTCAACG Freqency of prefixes.\n"},{"id":2,"href":"/LexicMap/usage/index/","title":"index","parent":"Usage","content":" Terminology differences In the LexicMap source code and command line options, the term \u0026ldquo;mask\u0026rdquo; is used, following the terminology in the LexicHash paper. In the LexicMap manuscript, however, we use \u0026ldquo;probe\u0026rdquo; as it is easier to understand. Because these masks, which consist of thousands of k-mers and capture k-mers from sequences through prefix matching, function similarly to DNA probes in molecular biology. Usage $ lexicmap index -h Generate an index from FASTA/Q sequences Input: *1. Sequences of each reference genome should be saved in separate FASTA/Q files, with reference identifiers in the file names. 2. Input plain or gzip/xz/zstd/bzip2 compressed FASTA/Q files can be given via positional arguments or the flag -X/--infile-list with a list of input files. Flag -S/--skip-file-check is optional for skipping file checking if you trust the file list. 3. Input can also be a directory containing sequence files via the flag -I/--in-dir, with multiple-level sub-directories allowed. A regular expression for matching sequencing files is available via the flag -r/--file-regexp. 4. Some non-isolate assemblies might have extremely large genomes (e.g., GCA_000765055.1, \u0026gt;150 mb). The flag -g/--max-genome is used to skip these input files, and the file list would be written to a file (-G/--big-genomes). Changes since v0.5.0: - Genomes with any single contig larger than the threshold will be skipped as before. - However, fragmented (with many contigs) genomes with the total bases larger than the threshold will be split into chunks and alignments from these chunks will be merged in \u0026#34;lexicmap search\u0026#34;. You need to increase the value for indexing fungi genomes. 5. Maximum genome size: 268,435,456. More precisely: $total_bases + ($num_contigs - 1) * 1000 \u0026lt;= 268,435,456, as we concatenate contigs with 1000-bp intervals of N’s to reduce the sequence scale to index. 6. A flag -l/--min-seq-len can filter out sequences shorter than the threshold (default is the k value). Attention: *1) ► You can rename the sequence files for convenience, e.g., GCF_000017205.1.fa.gz, because the genome identifiers in the index and search result would be: the basenames of files with common FASTA/Q file extensions removed, which are extracted via the flag -N/--ref-name-regexp. ► The extracted genome identifiers better be distinct, which will be shown in search results and are used to extract subsequences in the command \u0026#34;lexicmap utils subseq\u0026#34;. 2) ► Unwanted sequences like plasmids can be filtered out by content in FASTA/Q header via regular expressions (-B/--seq-name-filter). 3) All degenerate bases are converted to their lexicographic first bases. E.g., N is converted to A. code bases saved A A A C C C G G G T/U T T M A/C A R A/G A W A/T A S C/G C Y C/T C K G/T G V A/C/G A H A/C/T A D A/G/T A B C/G/T C N A/C/G/T A Important parameters: --- Genome data --- *1. -b/--batch-size, ► Maximum number of genomes in each batch (maximum: 131072, default: 5000). ► If the number of input files exceeds this number, input files are split into multiple batches and indexes are built for all batches. In the end, seed files are merged, while genome data files are kept unchanged and collected. ■ Bigger values increase indexing memory occupation and increase batch searching speed, while single query searching speed is not affected. --- LexicHash mask generation --- 0. -M/--mask-file, ► File with custom masks, which could be exported from an existing index or newly generated by \u0026#34;lexicmap utils masks\u0026#34;. This flag oversides -k/--kmer, -m/--masks, -s/--rand-seed, etc. *1. -k/--kmer, ► K-mer size (maximum: 32, default: 31). ■ Bigger values improve the search specificity and do not increase the index size. *2. -m/--masks, ► Number of LexicHash masks (default: 20000). ■ Bigger values improve the search sensitivity slightly, increase the index size, and slow down the search (seed matching) speed. --- Seeds data (k-mer-value data) --- *1. --seed-max-desert ► Maximum length of distances between seeds (default: 100). The default value of 100 guarantees queries \u0026gt;=200 bp would match at least two seeds. ► Large regions with no seeds are called sketching deserts. Deserts with seed distance larger than this value will be filled by choosing k-mers roughly every --seed-in-desert-dist (50 by default) bases. ■ Big values decrease the search sensitivity for distant targets, speed up the indexing speed, decrease the indexing memory occupation and decrease the index size. While the alignment speed is almost not affected. 2. -c/--chunks, ► Number of seed file chunks (maximum: 128, default: value of -j/--threads). ► Bigger values accelerate the search speed at the cost of a high disk reading load. The maximum number should not exceed the maximum number of open files set by the operating systems. ► Make sure the value of \u0026#39;-j/--threads\u0026#39; in \u0026#39;lexicmap search\u0026#39; is \u0026gt;= this value. *3. -J/--seed-data-threads ► Number of threads for writing seed data and merging seed chunks from all batches (maximum: -c/--chunks, default: 8). ■ The actual value is min(--seed-data-threads, max(1, --max-open-files/($batches_1_round + 2))), where $batches_1_round = min(int($input_files / --batch-size), --max-open-files). ■ Bigger values increase indexing speed at the cost of slightly higher memory occupation. 4. --partitions, ► Number of partitions for indexing each seed file (default: 4096). ► Bigger values bring a little higher memory occupation. ► After indexing, \u0026#34;lexicmap utils reindex-seeds\u0026#34; can be used to reindex the seeds data with another value of this flag. *5. --max-open-files, ► Maximum number of open files (default: 1024). ► It\u0026#39;s only used in merging indexes of multiple genome batches. If there are \u0026gt;100 batches, ($input_files / --batch-size), please increase this value and set a bigger \u0026#34;ulimit -n\u0026#34; in shell. Usage: lexicmap index [flags] [-k \u0026lt;k\u0026gt;] [-m \u0026lt;masks\u0026gt;] { -I \u0026lt;seqs dir\u0026gt; | -X \u0026lt;file list\u0026gt;} -O \u0026lt;out dir\u0026gt; Flags: -b, --batch-size int ► Maximum number of genomes in each batch (maximum value: 131072) (default 5000) -G, --big-genomes string ► Out file of skipped files with $total_bases + ($num_contigs - 1) * $contig_interval \u0026gt;= -g/--max-genome. The second column is one of the skip types: no_valid_seqs, too_large_genome, too_many_seqs. -c, --chunks int ► Number of chunks for storing seeds (k-mer-value data) files. Max: 128. Default: the value of -j/--threads. (default 16) --contig-interval int ► Length of interval (N\u0026#39;s) between contigs in a genome. It can\u0026#39;t be too small (\u0026lt;1000) or some alignments might be fragmented (default 1000) --debug ► Print debug information. -r, --file-regexp string ► Regular expression for matching sequence files in -I/--in-dir, case ignored. Attention: use double quotation marks for patterns containing commas, e.g., -p \u0026#39;\u0026#34;A{2,}\u0026#34;\u0026#39;. (default \u0026#34;\\\\.(f[aq](st[aq])?|fna)(\\\\.gz|\\\\.xz|\\\\.zst|\\\\.bz2)?$\u0026#34;) --force ► Overwrite existing output directory. -h, --help help for index -I, --in-dir string ► Input directory containing FASTA/Q files. Directory and file symlinks are followed. -k, --kmer int ► Maximum k-mer size. K needs to be \u0026lt;= 32. (default 31) -M, --mask-file string ► File of custom masks. This flag oversides -k/--kmer, -m/--masks, -s/--rand-seed etc. -m, --masks int ► Number of LexicHash masks. (default 20000) -g, --max-genome int ► Maximum genome size. Genomes with any single contig larger than the threshold will be skipped, while fragmented (with many contigs) genomes larger than the threshold will be split into chunks and alignments from these chunks will be merged in \u0026#34;lexicmap search\u0026#34;. The value needs to be smaller than the maximum supported genome size: 268435456. (default 15000000) --max-open-files int ► Maximum opened files, used in merging indexes. If there are \u0026gt;100 batches, please increase this value and set a bigger \u0026#34;ulimit -n\u0026#34; in shell. (default 1024) -l, --min-seq-len int ► Maximum sequence length to index. The value would be k for values \u0026lt;= 0. (default -1) --no-desert-filling ► Disable sketching desert filling (only for debug). -O, --out-dir string ► Output LexicMap index directory. --partitions int ► Number of partitions for indexing seeds (k-mer-value data) files. The value needs to be the power of 4. (default 4096) -s, --rand-seed int ► Rand seed for generating random masks. (default 1) -N, --ref-name-regexp string ► Regular expression (must contains \u0026#34;(\u0026#34; and \u0026#34;)\u0026#34;) for extracting the reference name from the filename. Attention: use double quotation marks for patterns containing commas, e.g., -p \u0026#39;\u0026#34;A{2,}\u0026#34;\u0026#39;. (default \u0026#34;(?i)(.+)\\\\.(f[aq](st[aq])?|fna)(\\\\.gz|\\\\.xz|\\\\.zst|\\\\.bz2)?$\u0026#34;) --save-seed-pos ► Save seed positions, which can be inspected with \u0026#34;lexicmap utils seed-pos\u0026#34;. -J, --seed-data-threads int ► Number of threads for writing seed data and merging seed chunks from all batches, the value should be in range of [1, -c/--chunks]. If there are \u0026gt;100 batches, please also increase the value of --max-open-files and set a bigger \u0026#34;ulimit -n\u0026#34; in shell. (default 8) -d, --seed-in-desert-dist int ► Distance of k-mers to fill deserts. (default 50) -D, --seed-max-desert int ► Maximum length of sketching deserts, or maximum seed distance. Deserts with seed distance larger than this value will be filled by choosing k-mers roughly every --seed-in-desert-dist bases. (default 100) -B, --seq-name-filter strings ► List of regular expressions for filtering out sequences by contents in FASTA/Q header/name, case ignored. -S, --skip-file-check ► Skip input file checking when given files or a file list. Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples See Building an index ","description":" Terminology differences In the LexicMap source code and command line options, the term \u0026ldquo;mask\u0026rdquo; is used, following the terminology in the LexicHash paper. In the LexicMap manuscript, however, we use \u0026ldquo;probe\u0026rdquo; as it is easier to understand. Because these masks, which consist of thousands of k-mers and capture k-mers from sequences through prefix matching, function similarly to DNA probes in molecular biology. Usage $ lexicmap index -h Generate an index from FASTA/Q sequences Input: *1. Sequences of each reference genome should be saved in separate FASTA/Q files, with reference identifiers in the file names. 2. Input plain or gzip/xz/zstd/bzip2 compressed FASTA/Q files can be given via positional arguments or the flag -X/--infile-list with a list of input files. Flag -S/--skip-file-check is optional for skipping file checking if you trust the file list. 3. Input can also be a directory containing sequence files via the flag -I/--in-dir, with multiple-level sub-directories allowed. A regular expression for matching sequencing files is available via the flag -r/--file-regexp. 4. Some non-isolate assemblies might have extremely large genomes (e.g., GCA_000765055.1, \u0026gt;150 mb). The flag -g/--max-genome is used to skip these input files, and the file list would be written to a file (-G/--big-genomes). Changes since v0.5.0: - Genomes with any single contig larger than the threshold will be skipped as before. - However, fragmented (with many contigs) genomes with the total bases larger than the threshold will be split into chunks and alignments from these chunks will be merged in \u0026#34;lexicmap search\u0026#34;. You need to increase the value for indexing fungi genomes. 5. Maximum genome size: 268,435,456. More precisely: $total_bases + ($num_contigs - 1) * 1000 \u0026lt;= 268,435,456, as we concatenate contigs with 1000-bp intervals of N’s to reduce the sequence scale to index. 6. A flag -l/--min-seq-len can filter out sequences shorter than the threshold (default is the k value). Attention: *1) ► You can rename the sequence files for convenience, e.g., GCF_000017205.1.fa.gz, because the genome identifiers in the index and search result would be: the basenames of files with common FASTA/Q file extensions removed, which are extracted via the flag -N/--ref-name-regexp. ► The extracted genome identifiers better be distinct, which will be shown in search results and are used to extract subsequences in the command \u0026#34;lexicmap utils subseq\u0026#34;. 2) ► Unwanted sequences like plasmids can be filtered out by content in FASTA/Q header via regular expressions (-B/--seq-name-filter). 3) All degenerate bases are converted to their lexicographic first bases. E.g., N is converted to A. code bases saved A A A C C C G G G T/U T T M A/C A R A/G A W A/T A S C/G C Y C/T C K G/T G V A/C/G A H A/C/T A D A/G/T A B C/G/T C N A/C/G/T A Important parameters: --- Genome data --- *1. -b/--batch-size, ► Maximum number of genomes in each batch (maximum: 131072, default: 5000). ► If the number of input files exceeds this number, input files are split into multiple batches and indexes are built for all batches. In the end, seed files are merged, while genome data files are kept unchanged and collected. ■ Bigger values increase indexing memory occupation and increase batch searching speed, while single query searching speed is not affected. --- LexicHash mask generation --- 0. -M/--mask-file, ► File with custom masks, which could be exported from an existing index or newly generated by \u0026#34;lexicmap utils masks\u0026#34;. This flag oversides -k/--kmer, -m/--masks, -s/--rand-seed, etc. *1. -k/--kmer, ► K-mer size (maximum: 32, default: 31). ■ Bigger values improve the search specificity and do not increase the index size. *2. -m/--masks, ► Number of LexicHash masks (default: 20000). ■ Bigger values improve the search sensitivity slightly, increase the index size, and slow down the search (seed matching) speed. --- Seeds data (k-mer-value data) --- *1. --seed-max-desert ► Maximum length of distances between seeds (default: 100). The default value of 100 guarantees queries \u0026gt;=200 bp would match at least two seeds. ► Large regions with no seeds are called sketching deserts. Deserts with seed distance larger than this value will be filled by choosing k-mers roughly every --seed-in-desert-dist (50 by default) bases. ■ Big values decrease the search sensitivity for distant targets, speed up the indexing speed, decrease the indexing memory occupation and decrease the index size. While the alignment speed is almost not affected. 2. -c/--chunks, ► Number of seed file chunks (maximum: 128, default: value of -j/--threads). ► Bigger values accelerate the search speed at the cost of a high disk reading load. The maximum number should not exceed the maximum number of open files set by the operating systems. ► Make sure the value of \u0026#39;-j/--threads\u0026#39; in \u0026#39;lexicmap search\u0026#39; is \u0026gt;= this value. *3. -J/--seed-data-threads ► Number of threads for writing seed data and merging seed chunks from all batches (maximum: -c/--chunks, default: 8). ■ The actual value is min(--seed-data-threads, max(1, --max-open-files/($batches_1_round + 2))), where $batches_1_round = min(int($input_files / --batch-size), --max-open-files). ■ Bigger values increase indexing speed at the cost of slightly higher memory occupation. 4. --partitions, ► Number of partitions for indexing each seed file (default: 4096). ► Bigger values bring a little higher memory occupation. ► After indexing, \u0026#34;lexicmap utils reindex-seeds\u0026#34; can be used to reindex the seeds data with another value of this flag. *5. --max-open-files, ► Maximum number of open files (default: 1024). ► It\u0026#39;s only used in merging indexes of multiple genome batches. If there are \u0026gt;100 batches, ($input_files / --batch-size), please increase this value and set a bigger \u0026#34;ulimit -n\u0026#34; in shell. Usage: lexicmap index [flags] [-k \u0026lt;k\u0026gt;] [-m \u0026lt;masks\u0026gt;] { -I \u0026lt;seqs dir\u0026gt; | -X \u0026lt;file list\u0026gt;} -O \u0026lt;out dir\u0026gt; Flags: -b, --batch-size int ► Maximum number of genomes in each batch (maximum value: 131072) (default 5000) -G, --big-genomes string ► Out file of skipped files with $total_bases + ($num_contigs - 1) * $contig_interval \u0026gt;= -g/--max-genome. The second column is one of the skip types: no_valid_seqs, too_large_genome, too_many_seqs. -c, --chunks int ► Number of chunks for storing seeds (k-mer-value data) files. Max: 128. Default: the value of -j/--threads. (default 16) --contig-interval int ► Length of interval (N\u0026#39;s) between contigs in a genome. It can\u0026#39;t be too small (\u0026lt;1000) or some alignments might be fragmented (default 1000) --debug ► Print debug information. -r, --file-regexp string ► Regular expression for matching sequence files in -I/--in-dir, case ignored. Attention: use double quotation marks for patterns containing commas, e.g., -p \u0026#39;\u0026#34;A{2,}\u0026#34;\u0026#39;. (default \u0026#34;\\\\.(f[aq](st[aq])?|fna)(\\\\.gz|\\\\.xz|\\\\.zst|\\\\.bz2)?$\u0026#34;) --force ► Overwrite existing output directory. -h, --help help for index -I, --in-dir string ► Input directory containing FASTA/Q files. Directory and file symlinks are followed. -k, --kmer int ► Maximum k-mer size. K needs to be \u0026lt;= 32. (default 31) -M, --mask-file string ► File of custom masks. This flag oversides -k/--kmer, -m/--masks, -s/--rand-seed etc. -m, --masks int ► Number of LexicHash masks. (default 20000) -g, --max-genome int ► Maximum genome size. Genomes with any single contig larger than the threshold will be skipped, while fragmented (with many contigs) genomes larger than the threshold will be split into chunks and alignments from these chunks will be merged in \u0026#34;lexicmap search\u0026#34;. The value needs to be smaller than the maximum supported genome size: 268435456. (default 15000000) --max-open-files int ► Maximum opened files, used in merging indexes. If there are \u0026gt;100 batches, please increase this value and set a bigger \u0026#34;ulimit -n\u0026#34; in shell. (default 1024) -l, --min-seq-len int ► Maximum sequence length to index. The value would be k for values \u0026lt;= 0. (default -1) --no-desert-filling ► Disable sketching desert filling (only for debug). -O, --out-dir string ► Output LexicMap index directory. --partitions int ► Number of partitions for indexing seeds (k-mer-value data) files. The value needs to be the power of 4. (default 4096) -s, --rand-seed int ► Rand seed for generating random masks. (default 1) -N, --ref-name-regexp string ► Regular expression (must contains \u0026#34;(\u0026#34; and \u0026#34;)\u0026#34;) for extracting the reference name from the filename. Attention: use double quotation marks for patterns containing commas, e.g., -p \u0026#39;\u0026#34;A{2,}\u0026#34;\u0026#39;. (default \u0026#34;(?i)(.+)\\\\.(f[aq](st[aq])?|fna)(\\\\.gz|\\\\.xz|\\\\.zst|\\\\.bz2)?$\u0026#34;) --save-seed-pos ► Save seed positions, which can be inspected with \u0026#34;lexicmap utils seed-pos\u0026#34;. -J, --seed-data-threads int ► Number of threads for writing seed data and merging seed chunks from all batches, the value should be in range of [1, -c/--chunks]. If there are \u0026gt;100 batches, please also increase the value of --max-open-files and set a bigger \u0026#34;ulimit -n\u0026#34; in shell. (default 8) -d, --seed-in-desert-dist int ► Distance of k-mers to fill deserts. (default 50) -D, --seed-max-desert int ► Maximum length of sketching deserts, or maximum seed distance. Deserts with seed distance larger than this value will be filled by choosing k-mers roughly every --seed-in-desert-dist bases. (default 100) -B, --seq-name-filter strings ► List of regular expressions for filtering out sequences by contents in FASTA/Q header/name, case ignored. -S, --skip-file-check ► Skip input file checking when given files or a file list. Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples See Building an index "},{"id":3,"href":"/LexicMap/tutorials/misc/index-genbank/","title":"Indexing GenBank+RefSeq","parent":"More","content":"Make sure you have enough disk space, \u0026gt;10 TB is preferred.\nTools:\nhttps://github.com/pirovc/genome_updater, for downloading genomes https://github.com/shenwei356/seqkit, for checking sequence files https://github.com/shenwei356/rush, for running jobs Data:\ntime genome_updater.sh -d \u0026quot;refseq,genbank\u0026quot; -g \u0026quot;archaea,bacteria\u0026quot; \\ -f \u0026quot;genomic.fna.gz\u0026quot; -o \u0026quot;genbank\u0026quot; -M \u0026quot;ncbi\u0026quot; -t 12 -m -L curl cd genbank/2024-02-15_11-00-51/ # ----------------- check the file integrity ----------------- genomes=files # corrupted files # find $genomes -name \u0026quot;*.gz\u0026quot; \\ fd \u0026quot;.gz$\u0026quot; $genomes \\ | rush --eta 'seqkit seq -w 0 {} \u0026gt; /dev/null; if [ $? -ne 0 ]; then echo {}; fi' \\ \u0026gt; failed.txt # empty files find $genomes -name \u0026quot;*.gz\u0026quot; -size 0 \u0026gt;\u0026gt; failed.txt # delete these files cat failed.txt | rush '/bin/rm {}' # redownload them: # run the genome_updater command again, with the flag -i Indexing. On a 48-CPU machine, time: 56 h, ram: 181 GB, index size: 4.96 TiB. If you don\u0026rsquo;t have enough memory, please decrease the value of -b.\nlexicmap index \\ -I files/ \\ --ref-name-regexp '^(\\w{3}_\\d{9}\\.\\d+)' \\ -O genbank_refseq.lmi --log genbank_refseq.lmi.log \\ -b 25000 # dirsize genbank_refseq.lmi genbank_refseq.lmi: 4.96 TiB (5,454,659,703,138) 2.79 TiB seeds 2.17 TiB genomes 55.81 MiB genomes.map.bin 156.28 KiB masks.bin 3.59 KiB genomes.chunks.bin 619 B info.toml ","description":"Make sure you have enough disk space, \u0026gt;10 TB is preferred.\nTools:\nhttps://github.com/pirovc/genome_updater, for downloading genomes https://github.com/shenwei356/seqkit, for checking sequence files https://github.com/shenwei356/rush, for running jobs Data:\ntime genome_updater.sh -d \u0026quot;refseq,genbank\u0026quot; -g \u0026quot;archaea,bacteria\u0026quot; \\ -f \u0026quot;genomic.fna.gz\u0026quot; -o \u0026quot;genbank\u0026quot; -M \u0026quot;ncbi\u0026quot; -t 12 -m -L curl cd genbank/2024-02-15_11-00-51/ # ----------------- check the file integrity ----------------- genomes=files # corrupted files # find $genomes -name \u0026quot;*.gz\u0026quot; \\ fd \u0026quot;.gz$\u0026quot; $genomes \\ | rush --eta 'seqkit seq -w 0 {} \u0026gt; /dev/null; if [ $? -ne 0 ]; then echo {}; fi' \\ \u0026gt; failed.txt # empty files find $genomes -name \u0026quot;*.gz\u0026quot; -size 0 \u0026gt;\u0026gt; failed.txt # delete these files cat failed.txt | rush '/bin/rm {}' # redownload them: # run the genome_updater command again, with the flag -i Indexing. On a 48-CPU machine, time: 56 h, ram: 181 GB, index size: 4.96 TiB. If you don\u0026rsquo;t have enough memory, please decrease the value of -b.\n"},{"id":4,"href":"/LexicMap/introduction/","title":"Introduction","parent":"","content":" LexicMap is a nucleotide sequence alignment tool for efficiently querying gene, plasmid, viral, or long-read sequences (\u0026gt;100 bp) against up to millions of prokaryotic genomes.\nFor the latest features and improvements, please download the pre-release binaries.\nPreprint:\nWei Shen and Zamin Iqbal. (2024) LexicMap: efficient sequence alignment against millions of prokaryotic genomes. bioRxiv. https://doi.org/10.1101/2024.08.30.610459\nTable of contents Features Introduction Quick start Performance Installation Algorithm overview Citation Limitations Terminology differences Support License Related projects Features LexicMap is scalable to up to millions of prokaryotic genomes. The sensitivity of LexicMap is comparable with Blastn. The alignment is fast and memory-efficient. LexicMap is easy to install, we provide binary files with no dependencies for Linux, Windows, MacOS (x86 and arm CPUs). LexicMap is easy to use (tutorials and usages). Both tabular and Blast-style output formats are available. Besides, we provide several commands to explore the index data and extract indexed subsequences. Introduction Motivation: Alignment against a database of genomes is a fundamental operation in bioinformatics, popularised by BLAST. However, given the increasing rate at which genomes are sequenced, existing tools struggle to scale.\nExisting full alignment tools face challenges of high memory consumption and slow speeds. Alignment-free large-scale sequence searching tools only return the matched genomes, without the vital positional information for downstream analysis. Mapping tools, or those utilizing compressed full-text indexes, return only the most similar matches. Prefilter+Align strategies have the sensitivity issue in the prefiltering step. Methods: (algorithm overview)\nA rewritten and improved version of the sequence sketching method LexicHash is adopted to compute alignment seeds accurately and efficiently. We solved the sketching deserts problem of LexicHash seeds to provide a window guarantee. We added the support of suffix matching of seeds, making seeds much more tolerant to mutations. Any 31-bp seed with a common ≥15 bp prefix or suffix can be matched. A hierarchical index enables fast and low-memory variable-length seed matching (prefix + suffix matching). A pseudo alignment algorithm is used to find similar sequence regions from chaining results for alignment. A reimplemented Wavefront alignment algorithm is used for base-level alignment. Results:\nLexicMap enables efficient indexing and searching of both RefSeq+GenBank and the AllTheBacteria datasets (2.3 and 1.9 million prokaryotic assemblies respectively).\nWhen searching in all 2,340,672 Genbank+Refseq prokaryotic genomes, Blastn is unable to run with this dataset on common servers as it requires \u0026gt;2000 GB RAM. (see performance).\nWith LexicMap v0.7.0 (48 CPUs),\nQuery Genome hits Genome hits(high-similarity) Genome hits(medium-similarity) Genome hits(low-similarity) Time RAM A 1.3-kb marker gene 41,718 11,746 115 29,857 3m:06s 3.97 GB A 1.5-kb 16S rRNA 1,955,167 245,884 501,691 1,207,592 32m:59s 11.09 GB A 52.8-kb plasmid 560,330 96 15,370 544,864 52m:22s 14.48 GB 1003 AMR genes 30,967,882 7,636,386 4,858,063 18,473,433 15h:52m:08s 24.86 GB Notes:\nDefault paramters are used, for returning all possible matches. Only the best alignment of a genome is used to evaluate alignment similarity: high-similarity: (a) qcov \u0026gt;= 90% (genes) or 70% (plasmids), (b) pident\u0026gt;=90%. medium-similarity: (a) not belong to high-similarity, (b) qcov \u0026gt;= 50% (genes) or 30% (plasmids), (c) pident\u0026gt;=80%. low-similarity: left. The search time varies in different computing environments and mainly depends on the I/O speed. Quick start Building an index (see the tutorial of building an index).\n# From a directory with multiple genome files lexicmap index -I genomes/ -O db.lmi # From a file list with one file per line lexicmap index -S -X files.txt -O db.lmi Querying (see the tutorial of searching).\n# For short queries like genes or long reads, returning top N hits. lexicmap search -d db.lmi query.fasta -o query.fasta.lexicmap.tsv \\ --min-qcov-per-hsp 70 --min-qcov-per-genome 70 --top-n-genomes 10000 # For longer queries like plasmids, returning all hits. lexicmap search -d db.lmi query.fasta -o query.fasta.lexicmap.tsv \\ --min-qcov-per-hsp 0 --min-qcov-per-genome 0 --top-n-genomes 0 Sample output (queries are a few Nanopore Q20 reads). See output format details.\nquery qlen hits sgenome sseqid qcovGnm cls hsp qcovHSP alenHSP pident gaps qstart qend sstart send sstr slen evalue bitscore ------------------ ---- ---- --------------- ----------------- ------- --- --- ------- ------- ------ ---- ------ ---- ------- ------- ---- ------- --------- -------- ERR5396170.1000004 190 1 GCF_000227465.1 NC_016047.1 84.211 1 1 84.211 165 89.091 5 14 173 4189372 4189536 - 4207222 1.93e-63 253 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 1 1 99.623 801 97.628 9 4 796 1138907 1139706 + 1887974 0.00e+00 1431 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 2 2 99.623 801 97.628 9 4 796 32607 33406 + 1887974 0.00e+00 1431 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 3 3 99.623 801 97.628 9 4 796 134468 135267 - 1887974 0.00e+00 1431 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 4 4 99.623 801 97.503 9 4 796 1768896 1769695 + 1887974 0.00e+00 1427 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 5 5 99.623 801 97.378 9 4 796 242012 242811 - 1887974 0.00e+00 1422 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 6 6 99.623 801 96.879 12 4 796 154380 155176 - 1887974 0.00e+00 1431 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 7 7 57.915 469 95.736 9 4 464 1280313 1280780 + 1887974 3.71e-236 829 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 8 8 42.839 341 99.120 0 456 796 1282477 1282817 + 1887974 6.91e-168 601 ERR5396170.1000006 796 3 GCF_009663775.1 NZ_RDBR01000008.1 99.623 1 1 99.623 801 93.383 9 4 796 21391 22190 - 52610 0.00e+00 1278 ERR5396170.1000006 796 3 GCF_003344625.1 NZ_QPKJ02000188.1 97.362 1 1 87.437 700 98.143 5 22 717 1 699 - 826 0.00e+00 1249 ERR5396170.1000006 796 3 GCF_003344625.1 NZ_QPKJ02000423.1 97.362 2 2 27.889 222 99.550 0 575 796 1 222 + 510 3.47e-106 396 ERR5396170.1000000 698 2 GCF_001457615.1 NZ_LN831024.1 92.264 1 1 92.264 656 96.341 13 53 696 4452083 4452737 + 6316979 0.00e+00 1169 ERR5396170.1000000 698 2 GCF_000949385.2 NZ_JYKO02000001.1 91.977 1 1 91.977 654 78.135 13 55 696 5638788 5639440 - 5912440 2.68e-176 630 ERR5396170.1000001 2505 3 GCF_000307025.1 NC_018584.1 67.066 1 1 67.066 1690 97.633 16 47 1726 1905511 1907194 - 2951805 0.00e+00 2985 ERR5396170.1000001 2505 3 GCF_900187225.1 NZ_LT906436.1 65.070 1 1 65.070 1641 93.723 20 95 1724 1869503 1871134 - 2864663 0.00e+00 2626 ERR5396170.1000001 2505 3 GCF_013394085.1 NZ_CP040910.1 30.858 1 1 30.858 780 97.692 9 1726 2498 183873 184650 + 1887974 0.00e+00 1384 ERR5396170.1000001 2505 3 GCF_013394085.1 NZ_CP040910.1 30.858 2 2 5.030 127 87.402 1 2233 2358 1236170 1236296 + 1887974 1.73e-37 167 ERR5396170.1000001 2505 3 GCF_013394085.1 NZ_CP040910.1 30.858 3 3 5.150 130 80.769 12 2233 2361 930381 930499 - 1887974 6.61e-43 185 ERR5396170.1000001 2505 3 GCF_013394085.1 NZ_CP040910.1 30.858 4 4 3.713 93 93.548 0 2257 2349 1104581 1104673 - 1887974 5.09e-30 141 CIGAR string, aligned query and subject sequences can be outputted as extra columns via the flag -a/--all.\n# Extracting similar sequences for a query gene. # search matches with query coverage \u0026gt;= 90% lexicmap search -d gtdb_complete.lmi/ b.gene_E_faecalis_SecY.fasta -o results.tsv \\ --min-qcov-per-hsp 90 --all # extract matched sequences as FASTA format sed 1d results.tsv | awk -F\u0026#39;\\t\u0026#39; \u0026#39;{print \u0026#34;\u0026gt;\u0026#34;$5\u0026#34;:\u0026#34;$15\u0026#34;-\u0026#34;$16\u0026#34;:\u0026#34;$17\u0026#34;\\n\u0026#34;$23;}\u0026#39; \\ | seqkit seq -g \u0026gt; results.fasta seqkit head -n 1 results.fasta | head -n 3 \u0026gt;NZ_JALSCK010000007.1:39224-40522:- TTGTTCAAGCTATTAAAGAACGCCTTTAAAGTCAAAGACATTAGATCAAAAATCTTATTT ACAGTTTTAATCTTGTTTGTATTTCGCCTAGGTGCGCACATTACTGTGCCCGGGGTGAAT Export blast-style format:\n# here, we only align \u0026lt;=200 bp queries and show one low-similarity result. $ seqkit seq -g -M 200 q.long-reads.fasta.gz \\ | lexicmap search -d demo.lmi/ -a \\ | csvtk filter2 -t -f \u0026#39;$pident \u0026gt;80 \u0026amp;\u0026amp; $pident \u0026lt; 90\u0026#39; \\ | csvtk head -t -n 1 \\ | lexicmap utils 2blast --kv-file-genome ass2species.map Query = GCF_003697165.2_r40 Length = 186 [Subject genome #1/2] = GCF_002950215.1 Shigella flexneri Query coverage per genome = 93.548% \u0026gt;NZ_CP026788.1 Length = 4659463 HSP cluster #1, HSP #1 Score = 279 bits, Expect = 9.66e-75 Query coverage per seq = 93.548%, Aligned length = 177, Identities = 88.701%, Gaps = 6 Query range = 13-186, Subject range = 1124816-1124989, Strand = Plus/Plus Query 13 CGGAAACTGAAACA-CCAGATTCTACGATGATTATGATGATTTA-TGCTTTCTTTACTAA 70 |||||||||||||| |||||||||| | |||||||||||||||| |||||||||| |||| Sbjct 1124816 CGGAAACTGAAACAACCAGATTCTATGTTGATTATGATGATTTAATGCTTTCTTTGCTAA 1124875 Query 71 AAAGTAAGCGGCCAAAAAAATGAT-AACACCTGTAATGAGTATCAGAAAAGACACGGTAA 129 || |||||||||||||||||| ||||||||||||||||||||||||||||||||||| Sbjct 1124876 AA--GCAGCGGCCAAAAAAATGATTAACACCTGTAATGAGTATCAGAAAAGACACGGTAA 1124933 Query 130 GAAAACACTCTTTTGGATACCTAGAGTCTGATAAGCGATTATTCTCTCTATGTTACT 186 || ||||||||| ||||| |||||||||||||||||||||||| |||| ||| Sbjct 1124934 AAAGACACTCTTTGAAGTACCTGAAGTCTGATAAGCGATTATTCTCTCCATGT-ACT 1124989 Learn more: demo, tutorials, or usages.\nPerformance See the paper.\nInstallation LexicMap is implemented in Go programming language, executable binary files for most popular operating systems are freely available in release page.\nOr install with conda or pixi:\nconda install -c bioconda lexicmap We also provide pre-release binaries, with new features and improvements.\nAlgorithm overview Citation Wei Shen and Zamin Iqbal. (2024) LexicMap: efficient sequence alignment against millions of prokaryotic genomes. bioRxiv. https://doi.org/10.1101/2024.08.30.610459\nLimitations The queries need to be longer than 100 bp, though some shorter one can also be aligned. LexicMap is slow for \u0026gt;1Mb queries, and the alignment might be fragmented. LexicMap is slow for batch searching with more than hundreds of queries. However, there are some ways to improve the search speed of lexicmap search, such as keeping the top N genome matches via -n/--top-n-genomes or storing the index on solid state drives (SSDs). Terminology differences In the LexicMap source code and command line options, the term \u0026ldquo;mask\u0026rdquo; is used, following the terminology in the LexicHash paper. In the LexicMap manuscript, however, we use \u0026ldquo;probe\u0026rdquo; as it is easier to understand. Because these masks, which consist of thousands of k-mers and capture k-mers from sequences through prefix matching, function similarly to DNA probes in molecular biology. Support Please open an issue to report bugs, propose new functions or ask for help.\nLicense MIT License\nRelated projects High-performance LexicHash computation in Go. Wavefront alignment algorithm (WFA) in Golang. ","description":" LexicMap is a nucleotide sequence alignment tool for efficiently querying gene, plasmid, viral, or long-read sequences (\u0026gt;100 bp) against up to millions of prokaryotic genomes.\nFor the latest features and improvements, please download the pre-release binaries.\nPreprint:\nWei Shen and Zamin Iqbal. (2024) LexicMap: efficient sequence alignment against millions of prokaryotic genomes. bioRxiv. https://doi.org/10.1101/2024.08.30.610459\nTable of contents Features Introduction Quick start Performance Installation Algorithm overview Citation Limitations Terminology differences Support License Related projects Features LexicMap is scalable to up to millions of prokaryotic genomes. The sensitivity of LexicMap is comparable with Blastn. The alignment is fast and memory-efficient. LexicMap is easy to install, we provide binary files with no dependencies for Linux, Windows, MacOS (x86 and arm CPUs). LexicMap is easy to use (tutorials and usages). Both tabular and Blast-style output formats are available. Besides, we provide several commands to explore the index data and extract indexed subsequences. Introduction Motivation: Alignment against a database of genomes is a fundamental operation in bioinformatics, popularised by BLAST. However, given the increasing rate at which genomes are sequenced, existing tools struggle to scale.\n"},{"id":5,"href":"/LexicMap/usage/utils/kmers/","title":"kmers","parent":"utils","content":"$ lexicmap utils kmers -h View k-mers captured by the masks Attention: 1. Mask index (column mask) is 1-based. 2. Prefix means the length of shared prefix between a k-mer and the mask. 3. K-mer positions (column pos) are 1-based. For reference genomes with multiple sequences, the sequences were concatenated to a single sequence with intervals of N\u0026#39;s. 4. Reversed means if the k-mer is reversed for suffix matching. Usage: lexicmap utils kmers [flags] -d \u0026lt;index path\u0026gt; [-m \u0026lt;mask index\u0026gt;] [-o out.tsv.gz] Flags: -h, --help help for kmers -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. -m, --mask int ► View k-mers captured by Xth mask. (0 for all) (default 1) -f, --only-forward ► Only output forward k-mers. -o, --out-file string ► Out file, supports and recommends a \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples The default output is captured k-mers of the first mask.\n$ lexicmap utils kmers --quiet -d demo.lmi/ | head -n 20 | csvtk pretty -t mask kmer prefix number ref pos strand reversed ---- ------------------------------- ------ ------ --------------- ------- ------ -------- 1 AAAAAAAAACGAAAAAGATTTTCCCTCATAC 7 1 GCF_000392875.1 2088530 + yes 1 AAAAAAAAACGCTTCTACATCGAGCAGCGAG 7 1 GCF_001457655.1 941619 + yes 1 AAAAAAAAACGTATCCCTCTTTATTACTTAT 7 1 GCF_000006945.2 3392260 - yes 1 AAAAAAAAAGATTTGATTTTTTTCATTAATA 7 1 GCF_000392875.1 766998 - yes 1 AAAAAAAAATCTATTTTAAAACCTAATCACG 7 1 GCF_000392875.1 2201506 + yes 1 AAAAAAAAATGTCACAACAGCCCAACCTCCA 7 1 GCF_000392875.1 860216 + yes 1 AAAAAAAACAAAAACTAGTTCGAGTGCCGAA 7 1 GCF_000006945.2 1587885 - yes 1 AAAAAAAACCATATTATGTCCGATCCTCACA 7 1 GCF_000392875.1 1060650 + yes 1 AAAAAAAACGAAAAACGGTAACACGGGAATT 7 1 GCF_001544255.1 1605298 + yes 1 AAAAAAAACGACGCAGAAAACGACATTGCGA 7 1 GCF_003697165.2 564733 + yes 1 AAAAAAAACGACTCCAGAGAGATCATCGTAT 7 1 GCF_000392875.1 1279686 + yes 1 AAAAAAAACGAGCGATTGGTTGCATTAAGGA 7 1 GCF_002949675.1 3914985 - yes 1 AAAAAAAACGAGCGCTCGGTTGCATTAAGGA 7 2 GCF_002949675.1 2061956 - yes 1 AAAAAAAACGAGCGCTCGGTTGCATTAAGGA 7 2 GCF_003697165.2 1514669 - yes 1 AAAAAAAACGCAACTTAAACAGTAAAACACG 7 1 GCF_002950215.1 1938205 + yes 1 AAAAAAAACGGGACGCGTAGTGCTGTGGTCT 7 1 GCF_000742135.1 2728620 - yes 1 AAAAAAAACGTAAATTTTTAAGATTGCGTCG 7 1 GCF_001457655.1 1547239 - yes 1 AAAAAAAACGTTAGAGAAAGCATCTAACACA 7 1 GCF_001027105.1 660296 + yes 1 AAAAAAAACGTTTTATCACTAATTTTCAGTT 7 1 GCF_000392875.1 1590621 - yes Only forward k-mers.\n$ lexicmap utils kmers --quiet -d demo.lmi/ -f | head -n 20 | csvtk pretty -t mask kmer prefix number ref pos strand reversed ---- ------------------------------- ------ ------ --------------- ------- ------ -------- 1 AAAAAAATAAAAACTTAGTTGTCCCATAACA 8 1 GCF_000392875.1 1044207 - no 1 AAAAAAATAAATCTGCGATGGCTGTTGATGG 8 1 GCF_002950215.1 462416 + no 1 AAAAAAATAACGTTGGCGATTACGATGCCAA 8 1 GCF_000392875.1 1422018 + no 1 AAAAAAATAACTCAATGAGGTTATGGGCATG 8 1 GCF_000742135.1 4160317 - no 1 AAAAAAATAACTGCTTTACTCTTTGCTCTTT 8 1 GCF_009759685.1 2134145 + no 1 AAAAAAATAAGAACACAAAAAAGGTATCTAG 8 1 GCF_001544255.1 1050935 + no 1 AAAAAAATAAGAAGGTAGCACCAATAACTTT 8 1 GCF_900638025.1 137037 - no 1 AAAAAAATAAGCTGGGCCGTTTGGGGAACGA 8 1 GCF_000742135.1 989338 - no 1 AAAAAAATAAGGGGAAATTATGGCAGGTAAT 8 1 GCF_001457655.1 883695 - no 1 AAAAAAATAAGTGAAAATCTATTTTCTGAAA 8 1 GCF_000392875.1 2823442 - no 1 AAAAAAATAATATTGTCCATTCTCCTAGCAA 8 1 GCF_001544255.1 173045 - no 1 AAAAAAATAATCAAAGGCCGGGGATTATACG 8 1 GCF_003697165.2 733341 - no 1 AAAAAAATACCCTGCGTGATGATGCGAGGTG 8 1 GCF_002950215.1 1422485 - no 1 AAAAAAATACTTGCCTTCGGGCTTATCTCAG 8 1 GCF_003697165.2 2823100 + no 1 AAAAAAATACTTGTTTGATTCTGTATTACGT 8 1 GCF_000392875.1 493472 + no 1 AAAAAAATAGAAAATGAGTCAACACCACTAT 8 1 GCF_006742205.1 1365300 + no 1 AAAAAAATAGAATTATATCGTGAACGTTTTG 8 1 GCF_009759685.1 2234982 + no 1 AAAAAAATAGAGGATTAAATGCTAATTCATA 8 1 GCF_001457655.1 671915 + no 1 AAAAAAATAGTATAAATCCGCCATATAAAAT 8 1 GCF_001457655.1 1222761 - no Specify the mask.\n$ lexicmap utils kmers --quiet -d demo.lmi/ --mask 12345 | head -n 20 | csvtk pretty -t mask kmer prefix number ref pos strand reversed ----- ------------------------------- ------ ------ --------------- ------- ------ -------- 12345 GCTGCACAAAGTACGATTACGATGCAAGCCC 8 1 GCF_002949675.1 716651 + no 12345 GCTGCACAACAAACGATTGTTGGTGAAATTT 8 1 GCF_000392875.1 836578 - no 12345 GCTGCACAACAACATGATAGTGTGAAATTAG 8 1 GCF_001027105.1 1150856 + no 12345 GCTGCACAACAGGCTGCGGCTGGTGTTGCGG 8 1 GCF_000742135.1 4128289 - no 12345 GCTGCACAACCAGGCAGAAAAAATAATGGGA 8 1 GCF_002950215.1 3009005 - no 12345 GCTGCACAACCTTTCCACAAGCCGTAAAACC 8 1 GCF_000006945.2 4306623 - no 12345 GCTGCACAACGATTAGAAAAAATGGGGTACG 8 1 GCF_001544255.1 2041481 - no 12345 GCTGCACAACTATCCCAATGCCGAGGTGGAA 8 1 GCF_000017205.1 5101754 + no 12345 GCTGCACAAGCACCCGGCCGTGGCCCTGGCG 8 1 GCF_000017205.1 1257468 + no 12345 GCTGCACAAGCGCTCGGTTTAGAGCAAACAC 8 1 GCF_009759685.1 1232954 - no 12345 GCTGCACAAGGGGCCACTTTCGTACATCGTC 8 1 GCF_000742135.1 3888020 + yes 12345 GCTGCACAAGTACCTGCTGGCCTACGCCTCG 8 1 GCF_000017205.1 1166094 + no 12345 GCTGCACAAGTTGCAAAACAGCTGATTAAGG 8 1 GCF_000392875.1 908172 + no 12345 GCTGCACAATATCGATTTGAACATTGCTCAG 8 1 GCF_003697165.2 3212441 + no 12345 GCTGCACAATATTTCATAATGACTTACGGCA 8 1 GCF_002950215.1 3443237 + no 12345 GCTGCACAATCCGCTGGGCTGGGTGCTCAAC 8 1 GCF_000742135.1 1083211 - no 12345 GCTGCACAATCGCCAGCCCCAGCCCTGTGCC 8 1 GCF_000006945.2 3658390 + no 12345 GCTGCACAATTACCACGTGAATTATTTGAAG 8 1 GCF_900638025.1 304434 - no 12345 GCTGCACAATTGCCAGCCCTAATCCCGTGCC 8 1 GCF_002950215.1 2671971 + no \u0026ldquo;reversed\u0026rdquo; means means if the k-mer is reversed for suffix matching. E.g., GCTGCACAAGGGGCCACTTTCGTACATCGTC is reversed, so you need to reverse it before searching in the genome.\n$ seqkit locate -p $(echo GCTGCACAAGGGGCCACTTTCGTACATCGTC | rev) refs/GCF_000742135.1.fa.gz -M | csvtk pretty -t seqID patternName pattern strand start end ------------- ------------------------------- ------------------------------- ------ ------- ------- NZ_KN046818.1 CTGCTACATGCTTTCACCGGGGAACACGTCG CTGCTACATGCTTTCACCGGGGAACACGTCG + 3888020 3888050 For all masks. The result might be very big, therefore, writing to gzip format is recommended.\n$ lexicmap utils kmers -d demo.lmi/ --mask 0 -o kmers.tsv.gz $ zcat kmers.tsv.gz | csvtk freq -t -f mask -nr | head -n 10 mask frequency 8206 700 16230 636 4974 625 14979 620 11723 619 12043 593 12 589 18 589 17491 584 a faster way\nseq 1 $(lexicmap utils masks -d demo.lmi/ --quiet | wc -l) \\ | rush --eta 'echo -e {}\u0026quot;\\t\u0026quot;$(lexicmap utils kmers -d demo.lmi/ -m {} -f --quiet | csvtk nrow)' \\ | csvtk add-header -t -n mask,seeds \\ | csvtk sort -t -k seeds:nr \\ | head -n 10 Lengths of shared prefixes between probes and captured k-mers.\nzcat kmers.tsv.gz \\ | csvtk grep -t -f reversed -p no \\ | csvtk plot hist -t -f prefix -o prefix.hist.png \\ --xlab \u0026quot;length of common prefixes between captured k-mers and masks\u0026quot; The output (TSV format) is formatted with csvtk pretty.\n","description":"$ lexicmap utils kmers -h View k-mers captured by the masks Attention: 1. Mask index (column mask) is 1-based. 2. Prefix means the length of shared prefix between a k-mer and the mask. 3. K-mer positions (column pos) are 1-based. For reference genomes with multiple sequences, the sequences were concatenated to a single sequence with intervals of N\u0026#39;s. 4. Reversed means if the k-mer is reversed for suffix matching. Usage: lexicmap utils kmers [flags] -d \u0026lt;index path\u0026gt; [-m \u0026lt;mask index\u0026gt;] [-o out.tsv.gz] Flags: -h, --help help for kmers -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. -m, --mask int ► View k-mers captured by Xth mask. (0 for all) (default 1) -f, --only-forward ► Only output forward k-mers. -o, --out-file string ► Out file, supports and recommends a \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples The default output is captured k-mers of the first mask.\n"},{"id":6,"href":"/LexicMap/tutorials/search/","title":"Step 2. Searching","parent":"Tutorials","content":" Table of contents Table of contents TL;DR Input Hardware requirements Algorithm Parameters Improving searching speed Searching with plasmids or other longer queries Steps Output Alignment result relationship Output format Examples Summarizing results TL;DR Build a LexicMap index.\nRun:\nFor short queries like genes or long reads, returning top N hits.\nlexicmap search -d db.lmi query.fasta -o query.fasta.lexicmap.tsv \\ --min-qcov-per-hsp 70 --min-qcov-per-genome 70 --top-n-genomes 10000 For longer queries like plasmids, returning all hits.\nlexicmap search -d db.lmi query.fasta -o query.fasta.lexicmap.tsv \\ --min-qcov-per-hsp 0 --min-qcov-per-genome 0 --top-n-genomes 0 Input Note Query length\nLexicMap is mainly designed for sequence alignment with a small number of queries (gene/plasmid/virus/phage sequences) longer than 100 bp by default. Input should be (gzipped) FASTA or FASTQ records from files or STDIN.\nHardware requirements See benchmark of index building.\nLexicMap is designed to provide fast and low-memory sequence alignment against millions of prokaryotic genomes.\nCPU: No specific requirements on CPU type and instruction sets. Both x86 and ARM chips are supported. More is better as LexicMap is a CPU-intensive software. It uses all CPUs by default (-j/--threads). RAM More RAM (\u0026gt; 16 GB) is preferred. The memory usage in searching is mainly related to: The number and length of query sequences. The number of matched genomes and sequences. Similarities between query and target sequences. The number of threads. It uses all CPUs by default (-j/--threads). Disk SSD disks are preferred to store the index size, while HDD disks are also fast enough. No temporary files are generated during searching. Algorithm Click to show details. ... Masking: Query sequence is masked by the masks of the index. In other words, each mask captures the most similar k-mer which shares the longest prefix with the mask, and stores its position and strand information. Seeding: For each mask, the captured k-mer is used to search seeds (captured k-mers in reference genomes) sharing prefixes or suffixes of at least p bases. Prefix matching Setting the search range: Since the seeded k-mers are stored in lexicographic order, the k-mer matching turns into a range query. For example, for a query CATGCT requiring matching at least 4-bp prefix is equal to extract k-mers ranging from CATGAA, CATGAC, CATGAG, \u0026hellip;, to CATGTT. Retrieving search start point: The index file of each seed data file stores some k-mers\u0026rsquo; offsets in the data file, and the index is loaded in RAM. Retrieving seed data: Seed k-mers are read from the file and checked one by one, and k-mers in the search range are returned, along with the k-mer information (genome batch, genome number, location, and strand). Suffix matching Reversing the query k-mer and performing prefix matching, returning seeds of reversed k-mers (see indexing algorithm). Chaining: Seeding results, i.e., anchors (matched k-mers from the query and subject sequence), are summarized by genome, and deduplicated. Performing chaining (see the paper). Alignment for each chain. Extending the anchor region. for extracting sequences from the query and reference genome. For example, extending 1 kb in upstream and downstream of anchor region. Performing pseudo-alignment with extended query and subject sequences, for find similar regions. For these similar regions that accross more than one reference sequences, splitting them into multiple ones. Fast alignment of query and subject sequence regions with our implementation of Wavefront alignment algorithm. Filtering alignments based on user options. Parameters Flags in bold text are important and frequently used.\nGeneral Flag Value Function Comment -j/--threads Default: all available cpus Number of CPU cores to use. The value should be \u0026gt;= the number of seed chunk files (“chunks” in info.toml, set by -c/--chunks in lexicmap index). -w/--load-whole-seeds Load the whole seed data into memory for faster search Use this if the index is not big and many queries are needed to search. -n/--top-n-genomes Default 0, 0 for all Keep top N genome matches for a query in the chaining phase Value 1 is not recommended as the best chaining result does not always bring the best alignment, so it better be \u0026gt;= 100. The final number of genome hits might be smaller than this number as some chaining results might fail to pass the criteria in the alignment step. -a/--all Output more columns, e.g., matched sequences. Use this if you want to output blast-style format with \u0026ldquo;lexicmap utils 2blast\u0026rdquo; -J/--max-query-conc Default 12, 0 for all Maximum number of concurrent queries Bigger values do not improve the batch searching speed and consume much memory. --max-open-files Default: 1024 Maximum number of open files It mainly affects candidate subsequence extraction. Increase this value if you have hundreds of genome batches or have multiple queries, and do not forgot to set a bigger ulimit -n in shell if the value is \u0026gt; 1024. Chaining Flag Value Function Comment -p, --seed-min-prefix Default 15 Minimum (prefix) length of matched seeds. Smaller values produce more results at the cost of slow speed. -P, --seed-min-single-prefix Default 17 Minimum (prefix) length of matched seeds if there\u0026rsquo;s only one pair of seeds matched. Smaller values produce more results at the cost of slow speed. --seed-max-dist Default 1000 Max distance between seeds in seed chaining. It should be \u0026lt;= contig interval length in database. --seed-max-gap Default 50 Max gap in seed chaining. Alignment Flag Value Function Comment -Q/--min-qcov-per-genome Default 0 Minimum query coverage (percentage) per genome. -q/--min-qcov-per-hsp Default 0 Minimum query coverage (percentage) per HSP. -l/--align-min-match-len Default 50 Minimum aligned length in a HSP segment. -i/--align-min-match-pident Default 70 Minimum base identity (percentage) in a HSP segment. --align-band Default 100 Band size in backtracking the score matrix. --align-ext-len Default 1000 Extend length of upstream and downstream of seed regions, for extracting query and target sequences for alignment. It should be \u0026lt;= contig interval length in database. --align-max-gap Default 20 Maximum gap in a HSP segment. Improving searching speed LexicMap\u0026rsquo;s searching speed is related to many factors:\nThe number of similar sequences in the index/database. More genome hits cost more time, e.g., 16S rRNA gene. The I/O performance and load. LexicMap is I/O bound, because seeds matching (sequential reading) and extracting candidate subsequences for alignment (random access) require a large number of file readings in parallel. Similarity between query and subject sequences. Alignment of diverse sequences is slightly slower than that of highly similar sequences. The length of query sequence. Longer queries run with more time. CPU frequency and the number of threads. Faster CPUs and more threads cost less time. Here are some tips to improve the search speed.\nStoring the index on SSD (It would be very fast!) Returning less results Bigger -p/--seed-min-prefix (default 15) and -P/--seed-min-single-prefix (default 17), e.g., -p 17 -P 19, increase the search speed at the cost of decreased sensitivity for distant matches (similarity \u0026lt; 90%) or short queries. Don\u0026rsquo;t worry if you only search highly similar matches or long queries. Setting -n/--top-n-genomes to keep top N genome matches for a query (0 for all) in chaining phase. For queries with a large number of genome hits, a resonable value such as 1000 would significantly reduce the computation time. Note that: alignment result filtering is performed in the final phase, so stricter filtering criteria, including -q/--min-qcov-per-hsp, -Q/--min-qcov-per-genome, and -i/--align-min-match-pident, do not significantly accelerate the search speed. Hence, you can search with default parameters and then filter the result with tools such as csvtk. Increasing the concurrency number Make sure that the value of -j/--threads (default: all available CPUs) is ≥ than the number of seed chunk file (default: all available CPUs in the indexing step), which can be found in info.toml file, e.g, # Seeds (k-mer-value data) files chunks = 48 Increasing the value of --max-open-files (default 1024). You might also need to change the open files limit. (If you have many queries) Increase the value of -J/--max-query-conc (default 12), it will increase the memory. Loading the entire seed data into memoy (If you have many queries and the index is not very big. It\u0026rsquo;s unnecessary if the index is stored on SSD) Setting -w/--load-whole-seeds to load the whole seed data into memory for faster seed matching. For example, for ~85,000 GTDB representative genomes, the memory would be ~260 GB with default parameters. Searching with plasmids or other longer queries For long queries, such as plasmids, a few parameters can be adjusted for better performance.\nBigger -p/--seed-min-prefix (default 15) and -P/--seed-min-single-prefix (default 17), e.g., -p 19 -P 21. The search sensitivity will not be affected for long queries or high similarity subjects. Bigger -l/--align-min-match-len (default 50), such as 1000, because small matches are less informative. When searching with plasmids, it\u0026rsquo;s recommended to use a strict criterion of -Q/--min-qcov-per-genome (qcovGnm, default 0), such as 90, and further filter results with a loose criterion of -q/--min-qcov-per-hsp (qcovHSP, default 0) after searching, such as 50/60/70. The reasons are:\nPlasmids are circular, while they are stored linearly. The different starting positions in query and subject sequences would result in two alignment segments (small qcovHSP). Assemblies can be fragmented, with many contigs, especially these assembled from short reads. Therefore, a plasmid might be aligned to multiple contigs with small qcovHSP. Steps For short queries like genes or long reads, returning top N hits.\nlexicmap search -d db.lmi query.fasta -o query.fasta.lexicmap.tsv \\ --min-match-pident 70 \\ --min-qcov-per-hsp 70 \\ --min-qcov-per-genome 70 \\ --top-n-genomes 10000 For longer queries like plasmids, returning all hits.\nlexicmap search -d db.lmi query.fasta -o query.fasta.lexicmap.tsv \\ --min-match-pident 70 \\ --min-qcov-per-hsp 0 \\ --min-qcov-per-genome 0 \\ --top-n-genomes 0 Click to show the log of a demo run. ... $ lexicmap search -d demo.lmi/ q.gene.fasta -o q.gene.fasta.lexicmap.tsv --debug 09:56:48.464 [INFO] LexicMap v0.7.0 09:56:48.464 [INFO] https://github.com/shenwei356/LexicMap 09:56:48.464 [INFO] 09:56:48.464 [INFO] checking input files ... 09:56:48.464 [INFO] 1 input file given: q.gene.fasta 09:56:48.464 [INFO] 09:56:48.464 [INFO] loading index: demo.lmi/ 09:56:48.464 [INFO] reading masks... 09:56:48.467 [INFO] reading indexes of seeds (k-mer-value) data... 09:56:49.434 [INFO] creating reader pools for 1 genome batches, each with 16 readers... 09:56:49.434 [INFO] index loaded in 969.583422ms 09:56:49.434 [INFO] 09:56:49.434 [INFO] searching with 16 threads... 09:56:49.435 [DEBU] NC_000913.3:4166659-4168200 (1542 bp): start to search 09:56:49.440 [DEBU] NC_000913.3:4166659-4168200 (1542 bp): finished seed-matching (15 genome hits) in 5.354981ms 09:56:49.441 [DEBU] NC_000913.3:4166659-4168200 (1542 bp): finished chaining (15 genome hits) in 1.045575ms checked genomes: 15 / 15 [======================================] ETA: 0s. done 09:56:49.473 [DEBU] NC_000913.3:4166659-4168200 (1542 bp): finished alignment (15 genome hits) in 32.005224ms 09:56:49.473 [DEBU] NC_000913.3:4166659-4168200 (1542 bp): finished sorting alignment results (15 genome hits) in 13.758µs 09:56:49.473 [INFO] 09:56:49.473 [INFO] processed queries: 1, speed: 1512.560 queries per minute 09:56:49.473 [INFO] 100.0000% (1/1) queries matched 09:56:49.473 [INFO] done searching 09:56:49.473 [INFO] search results saved to: q.gene.fasta.lexicmap.tsv 09:56:49.474 [INFO] 09:56:49.474 [INFO] elapsed time: 1.009536088s 09:56:49.474 [INFO] Extracting similar sequences for a query gene.\n# search matches with query coverage \u0026gt;= 90% lexicmap search -d gtdb_complete.lmi/ b.gene_E_faecalis_SecY.fasta --min-qcov-per-hsp 90 --all -o results.tsv # extract matched sequences as FASTA format sed 1d results.tsv | awk -F\u0026#39;\\t\u0026#39; \u0026#39;{print \u0026#34;\u0026gt;\u0026#34;$5\u0026#34;:\u0026#34;$15\u0026#34;-\u0026#34;$16\u0026#34;:\u0026#34;$17\u0026#34;\\n\u0026#34;$23;}\u0026#39; | seqkit seq -g \u0026gt; results.fasta seqkit head -n 1 results.fasta | head -n 3 \u0026gt;NZ_JALSCK010000007.1:39224-40522:- TTGTTCAAGCTATTAAAGAACGCCTTTAAAGTCAAAGACATTAGATCAAAAATCTTATTT ACAGTTTTAATCTTGTTTGTATTTCGCCTAGGTGCGCACATTACTGTGCCCGGGGTGAAT Exporting blast-like alignment text.\nFrom file:\nlexicmap utils 2blast results.tsv -o results.txt Add genome annotation\nlexicmap utils 2blast results.tsv -o results.txt --kv-file-genome ass2species.map From stdin:\n# here, we only align \u0026lt;=200 bp queries and show one low-similarity result. $ seqkit seq -g -M 200 q.long-reads.fasta.gz \\ | lexicmap search -d demo.lmi/ -a \\ | csvtk filter2 -t -f \u0026#39;$pident \u0026gt;80 \u0026amp;\u0026amp; $pident \u0026lt; 90\u0026#39; \\ | csvtk head -t -n 1 \\ | lexicmap utils 2blast --kv-file-genome ass2species.map Query = GCF_003697165.2_r40 Length = 186 [Subject genome #1/2] = GCF_002950215.1 Shigella flexneri Query coverage per genome = 93.548% \u0026gt;NZ_CP026788.1 Length = 4659463 HSP cluster #1, HSP #1 Score = 279 bits, Expect = 9.66e-75 Query coverage per seq = 93.548%, Aligned length = 177, Identities = 88.701%, Gaps = 6 Query range = 13-186, Subject range = 1124816-1124989, Strand = Plus/Plus Query 13 CGGAAACTGAAACA-CCAGATTCTACGATGATTATGATGATTTA-TGCTTTCTTTACTAA 70 |||||||||||||| |||||||||| | |||||||||||||||| |||||||||| |||| Sbjct 1124816 CGGAAACTGAAACAACCAGATTCTATGTTGATTATGATGATTTAATGCTTTCTTTGCTAA 1124875 Query 71 AAAGTAAGCGGCCAAAAAAATGAT-AACACCTGTAATGAGTATCAGAAAAGACACGGTAA 129 || |||||||||||||||||| ||||||||||||||||||||||||||||||||||| Sbjct 1124876 AA--GCAGCGGCCAAAAAAATGATTAACACCTGTAATGAGTATCAGAAAAGACACGGTAA 1124933 Query 130 GAAAACACTCTTTTGGATACCTAGAGTCTGATAAGCGATTATTCTCTCTATGTTACT 186 || ||||||||| ||||| |||||||||||||||||||||||| |||| ||| Sbjct 1124934 AAAGACACTCTTTGAAGTACCTGAAGTCTGATAAGCGATTATTCTCTCCATGT-ACT 1124989 Output Alignment result relationship Query ├── Subject genome ├── Subject sequence ├── HSP cluster (a cluster of neighboring HSPs) ├── High-Scoring segment Pair (HSP) Here, the defination of HSP is similar with that in BLAST. Actually there are small gaps in HSPs.\nA High-scoring Segment Pair (HSP) is a local alignment with no gaps that achieves one of the highest alignment scores in a given search. https://www.ncbi.nlm.nih.gov/books/NBK62051/\nOutput format Tab-delimited format with 20+ columns, with 1-based positions.\n1. query, Query sequence ID. 2. qlen, Query sequence length. 3. hits, Number of subject genomes. 4. sgenome, Subject genome ID. 5. sseqid, Subject sequence ID. 6. qcovGnm, Query coverage (percentage) per genome: $(aligned bases in the genome)/$qlen. 7. cls, Nth HSP cluster in the genome. (just for improving readability) It's useful to show if multiple adjacent HSPs are collinear. 8. hsp, Nth HSP in the genome. (just for improving readability) 9. qcovHSP Query coverage (percentage) per HSP: $(aligned bases in a HSP)/$qlen. 10. alenHSP, Aligned length in the current HSP. 11. pident, Percentage of identical matches in the current HSP. 12. gaps, Gaps in the current HSP. 13. qstart, Start of alignment in query sequence. 14. qend, End of alignment in query sequence. 15. sstart, Start of alignment in subject sequence. 16. send, End of alignment in subject sequence. 17. sstr, Subject strand. 18. slen, Subject sequence length. 19. evalue, Expect value. 20. bitscore, Bit score. 21. cigar, CIGAR string of the alignment. (optional with -a/--all) 22. qseq, Aligned part of query sequence. (optional with -a/--all) 23. sseq, Aligned part of subject sequence. (optional with -a/--all) 24. align, Alignment text (\u0026quot;|\u0026quot; and \u0026quot; \u0026quot;) between qseq and sseq. (optional with -a/--all) Result ordering:\nFor a HSP cluster, SimilarityScore = max(bit_score * pident).\nWithin each HSP cluster, HSPs are sorted by sstart. Within each subject genome, HSP clusters are sorted in descending order by SimilarityScore. Results of multiple subject genomes are sorted by the highest SimilarityScore of HSP clusters. Examples A single-copy gene (SecY) query qlen hits sgenome sseqid qcovGnm cls hsp qcovHSP alenHSP pident gaps qstart qend sstart send sstr slen evalue bitscore ---------------------------------------- ---- ---- --------------- -------------------- ------- --- --- ------- ------- ------- ---- ------ ---- ------- ------- ---- ------- -------- -------- lcl|NZ_CP064374.1_cds_WP_002359350.1_906 1299 6255 GCF_017641985.1 NZ_SIYB01000008.1 100.000 1 1 100.000 1299 100.000 0 1 1299 38843 40141 - 140750 0.00e+00 2343 lcl|NZ_CP064374.1_cds_WP_002359350.1_906 1299 6255 GCF_020405635.1 NZ_JAIZEZ010000006.1 100.000 1 1 100.000 1299 100.000 0 1 1299 217200 218498 + 257915 0.00e+00 2343 lcl|NZ_CP064374.1_cds_WP_002359350.1_906 1299 6255 GCF_902163655.1 NZ_CABHAB010000005.1 100.000 1 1 100.000 1299 100.000 0 1 1299 39259 40557 - 173125 0.00e+00 2343 lcl|NZ_CP064374.1_cds_WP_002359350.1_906 1299 6255 GCF_020881975.1 NZ_CP086411.1 100.000 1 1 100.000 1299 100.000 0 1 1299 212962 214260 + 2995874 0.00e+00 2343 lcl|NZ_CP064374.1_cds_WP_002359350.1_906 1299 6255 GCF_900148695.1 NZ_FRXS01000009.1 100.000 1 1 100.000 1299 100.000 0 1 1299 39230 40528 - 96692 0.00e+00 2343 lcl|NZ_CP064374.1_cds_WP_002359350.1_906 1299 6255 GCF_009735055.1 NZ_WMGL01000019.1 100.000 1 1 100.000 1299 100.000 0 1 1299 38954 40252 - 58628 0.00e+00 2343 lcl|NZ_CP064374.1_cds_WP_002359350.1_906 1299 6255 GCA_021838685.1 JAKCDA010000012.1 100.000 1 1 100.000 1299 100.000 0 1 1299 44127 45425 + 84305 0.00e+00 2343 lcl|NZ_CP064374.1_cds_WP_002359350.1_906 1299 6255 GCF_000742975.1 NZ_CP008816.1 100.000 1 1 100.000 1299 100.000 0 1 1299 2311184 2312482 + 2939973 0.00e+00 2343 lcl|NZ_CP064374.1_cds_WP_002359350.1_906 1299 6255 GCF_925298485.1 NZ_CAKMCI010000007.1 100.000 1 1 100.000 1299 100.000 0 1 1299 56108 57406 + 96359 0.00e+00 2343 lcl|NZ_CP064374.1_cds_WP_002359350.1_906 1299 6255 GCF_021120765.1 NZ_JADPWI010000009.1 100.000 1 1 100.000 1299 100.000 0 1 1299 38881 40179 - 84306 0.00e+00 2343 A 16S rRNA gene query qlen hits sgenome sseqid qcovGnm cls hsp qcovHSP alenHSP pident gaps qstart qend sstart send sstr slen evalue bitscore --------------------------- ---- ------ --------------- ----------------- ------- --- --- ------- ------- ------- ---- ------ ---- ------- ------- ---- ------- -------- -------- NC_000913.3:4166659-4168200 1542 306060 GCF_000468515.1 NC_022364.1 100.000 1 1 100.000 1542 100.000 0 1 1542 224243 225784 + 4835601 0.00e+00 2782 NC_000913.3:4166659-4168200 1542 306060 GCF_000468515.1 NC_022364.1 100.000 2 2 100.000 1542 100.000 0 1 1542 2804586 2806127 - 4835601 0.00e+00 2782 NC_000913.3:4166659-4168200 1542 306060 GCF_000468515.1 NC_022364.1 100.000 3 3 100.000 1542 100.000 0 1 1542 4350745 4352286 + 4835601 0.00e+00 2782 NC_000913.3:4166659-4168200 1542 306060 GCF_000468515.1 NC_022364.1 100.000 4 4 100.000 1542 99.676 0 1 1542 4391290 4392831 + 4835601 0.00e+00 2758 NC_000913.3:4166659-4168200 1542 306060 GCF_000468515.1 NC_022364.1 100.000 5 5 100.000 1542 99.611 0 1 1542 4083001 4084542 + 4835601 0.00e+00 2755 NC_000913.3:4166659-4168200 1542 306060 GCF_000468515.1 NC_022364.1 100.000 6 6 100.000 1542 99.481 0 1 1542 4177970 4179511 + 4835601 0.00e+00 2746 NC_000913.3:4166659-4168200 1542 306060 GCF_000468515.1 NC_022364.1 100.000 7 7 100.000 1542 99.157 0 1 1542 3548937 3550478 - 4835601 0.00e+00 2722 NC_000913.3:4166659-4168200 1542 306060 GCA_020564915.1 JAJBZO010000001.1 100.000 1 1 100.000 1542 100.000 0 1 1542 507976 509517 + 4637373 0.00e+00 2782 NC_000913.3:4166659-4168200 1542 306060 GCA_020564915.1 JAJBZO010000001.1 100.000 2 2 100.000 1542 100.000 0 1 1542 1180104 1181645 + 4637373 0.00e+00 2782 NC_000913.3:4166659-4168200 1542 306060 GCA_020564915.1 JAJBZO010000001.1 100.000 3 3 100.000 1542 100.000 0 1 1542 3674442 3675983 - 4637373 0.00e+00 2782 A plasmid query qlen hits sgenome sseqid qcovGnm cls hsp qcovHSP alenHSP pident gaps qstart qend sstart send sstr slen evalue bitscore ---------- ----- ----- --------------- -------------------- ------- --- --- ------- ------- ------- ---- ------ ----- ------- ------- ---- ------- --------- -------- CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000005.1 100.000 1 1 77.157 40762 99.995 0 12069 52830 5194 45955 + 51479 0.00e+00 73501 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000005.1 100.000 2 2 10.456 5524 100.000 0 1 5524 45956 51479 + 51479 0.00e+00 9963 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000005.1 100.000 3 3 9.860 5209 100.000 0 5525 10733 1 5209 + 51479 0.00e+00 9395 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000005.1 100.000 4 4 1.562 827 99.758 2 9044 9868 16840 17666 + 51479 0.00e+00 1496 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000005.1 100.000 5 5 1.565 827 99.758 2 23715 24541 3520 4344 + 51479 0.00e+00 1496 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000005.1 100.000 6 6 0.208 110 98.182 0 29827 29936 29056 29165 - 51479 6.76e-44 190 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000002.1 100.000 7 7 0.661 349 74.212 0 10092 10440 15029 15377 + 203534 1.04e-53 224 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000002.1 100.000 7 8 2.531 1337 94.091 0 10733 12069 14193 15529 + 203534 0.00e+00 2055 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000002.1 100.000 8 9 1.554 821 99.878 0 9049 9869 80484 81304 - 203534 0.00e+00 1476 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000002.1 100.000 9 10 1.552 820 99.878 0 23722 24541 80485 81304 - 203534 0.00e+00 1474 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000002.1 100.000 10 11 1.105 584 99.829 0 7767 8350 84382 84965 + 203534 1.41e-301 1049 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000002.1 100.000 10 12 0.320 169 100.000 0 9133 9301 83857 84025 + 203534 1.87e-78 306 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000002.1 100.000 11 13 0.439 232 79.310 0 23403 23634 84597 84828 + 203534 2.26e-47 203 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000002.1 100.000 11 14 0.996 526 100.000 0 23806 24331 83857 84382 + 203534 9.16e-272 949 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000002.1 100.000 12 15 0.509 269 99.628 0 8082 8350 84697 84965 + 203534 6.55e-131 480 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000002.1 100.000 12 16 0.996 526 100.000 0 9133 9658 83857 84382 + 203534 9.16e-272 949 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000002.1 100.000 13 17 0.502 265 100.000 0 19788 20052 88528 88792 + 203534 2.25e-130 479 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000002.1 100.000 14 18 0.409 224 71.429 8 8827 9042 45434 45657 + 203534 5.28e-36 165 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000001.1 100.000 15 19 1.554 821 100.000 0 9049 9869 2597473 2598293 + 5332228 0.00e+00 1481 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000001.1 100.000 16 20 1.554 821 100.000 0 23721 24541 231535 232355 + 5332228 0.00e+00 1481 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000001.1 100.000 17 21 1.554 821 100.000 0 23721 24541 2597472 2598292 + 5332228 0.00e+00 1481 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000001.1 100.000 18 22 1.552 820 100.000 0 9049 9868 231536 232355 + 5332228 0.00e+00 1480 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000001.1 100.000 19 23 0.502 265 100.000 0 19788 20052 4258498 4258762 + 5332228 2.25e-130 479 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000003.1 100.000 20 24 0.507 268 99.627 0 19785 20052 58030 58297 - 141533 2.28e-130 479 CP115019.1 52830 65311 GCF_021502915.1 NZ_JAJAAP010000003.1 100.000 21 25 0.424 224 100.000 0 19788 20011 109732 109955 + 141533 3.45e-108 405 CP115019.1 52830 65311 GCF_016803855.1 NZ_CP048009.1 98.158 1 1 77.157 40762 99.995 0 12069 52830 7768 48529 - 51479 0.00e+00 73501 CP115019.1 52830 65311 GCF_016803855.1 NZ_CP048009.1 98.158 2 2 14.702 7767 100.000 0 1 7767 1 7767 - 51479 0.00e+00 14008 CP115019.1 52830 65311 GCF_016803855.1 NZ_CP048009.1 98.158 3 3 5.614 2966 100.000 0 7768 10733 48514 51479 - 51479 0.00e+00 5350 CP115019.1 52830 65311 GCF_016803855.1 NZ_CP048009.1 98.158 4 4 1.565 827 99.758 2 23715 24541 49379 50203 - 51479 0.00e+00 1496 A prophage query qlen hits sgenome sseqid qcovGnm cls hsp qcovHSP alenHSP pident gaps qstart qend sstart send sstr slen evalue bitscore species ----------- ----- ---- --------------- ------------- ------- --- --- ------- ------- ------ ---- ------ ----- ------- ------- ---- ------- --------- -------- -------------------- NC_001895.1 33593 2 GCF_003697165.2 NZ_CP033092.2 77.588 1 1 27.890 9371 97.716 2 1 9369 1864411 1873781 + 4903501 0.00e+00 15953 Escherichia coli NC_001895.1 33593 2 GCF_003697165.2 NZ_CP033092.2 77.588 1 2 0.301 101 98.020 0 10308 10408 1873846 1873946 + 4903501 1.72e-43 174 Escherichia coli NC_001895.1 33593 2 GCF_003697165.2 NZ_CP033092.2 77.588 2 3 20.665 6942 96.528 4 17441 24382 1882011 1888948 + 4903501 0.00e+00 11459 Escherichia coli NC_001895.1 33593 2 GCF_003697165.2 NZ_CP033092.2 77.588 3 4 17.685 5941 97.980 0 24355 30295 1853098 1859038 + 4903501 0.00e+00 10174 Escherichia coli NC_001895.1 33593 2 GCF_003697165.2 NZ_CP033092.2 77.588 4 5 8.993 3021 91.526 0 10308 13328 1873846 1876866 + 4903501 0.00e+00 4295 Escherichia coli NC_001895.1 33593 2 GCF_003697165.2 NZ_CP033092.2 77.588 5 6 2.438 820 84.390 1 14540 15358 1878798 1879617 + 4903501 1.29e-264 911 Escherichia coli NC_001895.1 33593 2 GCF_002949675.1 NZ_CP026774.1 0.976 1 1 0.976 331 85.801 3 13919 14246 3704319 3704649 - 4395762 6.35e-112 403 Shigella dysenteriae Long reads Queries are a few Nanopore Q20 reads from a mock metagenomic community.\nquery qlen hits sgenome sseqid qcovGnm cls hsp qcovHSP alenHSP pident gaps qstart qend sstart send sstr slen evalue bitscore ------------------ ---- ---- --------------- ----------------- ------- --- --- ------- ------- ------ ---- ------ ---- ------- ------- ---- ------- --------- -------- ERR5396170.1000004 190 1 GCF_000227465.1 NC_016047.1 84.211 1 1 84.211 165 89.091 5 14 173 4189372 4189536 - 4207222 1.93e-63 253 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 1 1 99.623 801 97.628 9 4 796 1138907 1139706 + 1887974 0.00e+00 1431 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 2 2 99.623 801 97.628 9 4 796 32607 33406 + 1887974 0.00e+00 1431 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 3 3 99.623 801 97.628 9 4 796 134468 135267 - 1887974 0.00e+00 1431 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 4 4 99.623 801 97.503 9 4 796 1768896 1769695 + 1887974 0.00e+00 1427 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 5 5 99.623 801 97.378 9 4 796 242012 242811 - 1887974 0.00e+00 1422 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 6 6 99.623 801 96.879 12 4 796 154380 155176 - 1887974 0.00e+00 1431 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 7 7 57.915 469 95.736 9 4 464 1280313 1280780 + 1887974 3.71e-236 829 ERR5396170.1000006 796 3 GCF_013394085.1 NZ_CP040910.1 99.623 8 8 42.839 341 99.120 0 456 796 1282477 1282817 + 1887974 6.91e-168 601 ERR5396170.1000006 796 3 GCF_009663775.1 NZ_RDBR01000008.1 99.623 1 1 99.623 801 93.383 9 4 796 21391 22190 - 52610 0.00e+00 1278 ERR5396170.1000006 796 3 GCF_003344625.1 NZ_QPKJ02000188.1 97.362 1 1 87.437 700 98.143 5 22 717 1 699 - 826 0.00e+00 1249 ERR5396170.1000006 796 3 GCF_003344625.1 NZ_QPKJ02000423.1 97.362 2 2 27.889 222 99.550 0 575 796 1 222 + 510 3.47e-106 396 ERR5396170.1000000 698 2 GCF_001457615.1 NZ_LN831024.1 92.264 1 1 92.264 656 96.341 13 53 696 4452083 4452737 + 6316979 0.00e+00 1169 ERR5396170.1000000 698 2 GCF_000949385.2 NZ_JYKO02000001.1 91.977 1 1 91.977 654 78.135 13 55 696 5638788 5639440 - 5912440 2.68e-176 630 ERR5396170.1000001 2505 3 GCF_000307025.1 NC_018584.1 67.066 1 1 67.066 1690 97.633 16 47 1726 1905511 1907194 - 2951805 0.00e+00 2985 ERR5396170.1000001 2505 3 GCF_900187225.1 NZ_LT906436.1 65.070 1 1 65.070 1641 93.723 20 95 1724 1869503 1871134 - 2864663 0.00e+00 2626 ERR5396170.1000001 2505 3 GCF_013394085.1 NZ_CP040910.1 30.858 1 1 30.858 780 97.692 9 1726 2498 183873 184650 + 1887974 0.00e+00 1384 ERR5396170.1000001 2505 3 GCF_013394085.1 NZ_CP040910.1 30.858 2 2 5.030 127 87.402 1 2233 2358 1236170 1236296 + 1887974 1.73e-37 167 ERR5396170.1000001 2505 3 GCF_013394085.1 NZ_CP040910.1 30.858 3 3 5.150 130 80.769 12 2233 2361 930381 930499 - 1887974 6.61e-43 185 ERR5396170.1000001 2505 3 GCF_013394085.1 NZ_CP040910.1 30.858 4 4 3.713 93 93.548 0 2257 2349 1104581 1104673 - 1887974 5.09e-30 141 Search results (TSV format) above are formatted with csvtk pretty.\nSummarizing results If you would like to summarize alignment results, e.g., the number of species, here\u0026rsquo;s the method.\nPrepare a two-column tab-delimited file for mapping reference (genome) or sequence IDs to any information (such as species name).\n# for GTDB/GenBank/RefSeq genomes downloaded with genome_updater cut -f 1,8 assembly_summary.txt \u0026gt; ass2species.tsv head -n 3 ass2species.tsv GCF_002287175.1 Methanobacterium bryantii GCF_000762265.1 Methanobacterium formicicum GCF_029601605.1 Methanobacterium formicicum Add information to the alignment results with csvtk or other tools.\n# add species cat b.gene_E_coli_16S.fasta.lexicmap.tsv \\ | csvtk mutate -t --after slen -n species -f sgenome \\ | csvtk replace -t -f species -p \u0026quot;(.+)\u0026quot; -r \u0026quot;{kv}\u0026quot; -k ass2species.tsv \\ \u0026gt; result.with_species.tsv # filter results with query coverage \u0026gt;= 80 and count the species cat result.with_species.tsv \\ | csvtk uniq -t -f sgenome \\ | csvtk filter2 -t -f \u0026quot;\\$qcovHSP \u0026gt;= 80\u0026quot; \\ | csvtk freq -t -f species -nr \\ \u0026gt; result.with_species.tsv.stats.tsv csvtk head -t -n 5 result.with_species.tsv.stats.tsv \\ | csvtk pretty -t species frequency ------------------------ --------- Salmonella enterica 135065 Escherichia coli 128071 Streptococcus pneumoniae 51971 Staphylococcus aureus 44215 Pseudomonas aeruginosa 34254 ","description":" Table of contents Table of contents TL;DR Input Hardware requirements Algorithm Parameters Improving searching speed Searching with plasmids or other longer queries Steps Output Alignment result relationship Output format Examples Summarizing results TL;DR Build a LexicMap index.\n"},{"id":7,"href":"/LexicMap/tutorials/misc/index-allthebacteria/","title":"Indexing AllTheBacteria","parent":"More","content":" Table of contents Table of contents Searching with the pre-built index on AWS Run on EC2 Only download it and run locally Steps for v0.2 and later versions hosted at OSF Steps for v0.2 hosted at EBI ftp Searching with the pre-built index on AWS Run on EC2 Launch an EC2 instance in Europe London region (eu-west-2) where the index is located.\nOS: Amazon Linux 2023 64-bit (Arm) Instance type (You might need to increase the limit of CPUs): c7g.8xlarge (32 vCPU, 64 GiB memory, 15 Gigabit, 1.3738 USD per Hour) c6gn.12xlarge (48 vCPU, 96 GiB memory, 75 Gigabit, 2.46 USD per Hour) (recommended) Storage: 20 GiB General purpose (gp3), only for storing queries and results. Connect to the instance via online console or a ssh client.\nMount the LexicMap index with mount-s3 (it\u0026rsquo;s fast but still slower than local disks):\n# install mount-s3. You might need to replace arm64 with x86_64 for other architectures wget https://s3.amazonaws.com/mountpoint-s3-release/latest/arm64/mount-s3.rpm sudo yum install -y ./mount-s3.rpm rm ./mount-s3.rpm # mount # --log-directory log --debug --log-metrics mkdir -p atb.lmi log UNSTABLE_MOUNTPOINT_MAX_PREFETCH_WINDOW_SIZE=65536 \\ mount-s3 --read-only --prefix 202408/ allthebacteria-lexicmap atb.lmi --no-sign-request Install LexicMap.\n# Binary's path depends on the architecture of the CPUs: amd64 or arm64 # Please check the latest version here: https://github.com/shenwei356/LexicMap/releases # or the pre-release here: https://github.com/shenwei356/LexicMap/issues/10 wget https://github.com/shenwei356/LexicMap/releases/download/v0.7.0/lexicmap_linux_arm64.tar.gz mkdir -p bin tar -zxvf lexicmap_linux_arm64.tar.gz -C bin rm lexicmap_linux_arm64.tar.gz Upload queries.\nwget https://github.com/shenwei356/LexicMap/raw/refs/heads/main/demo/bench/b.gene_E_faecalis_SecY.fasta Run LexicMap.\n# create and enter a screen session screen -S lexicmap # run # it takes 20 minutes with c7g.8xlarge, 12.5 minutes with c6gn.12xlarge # b.gene_E_coli_16S.fasta takes 1h54m with c6gn.12xlarge. lexicmap search -d atb.lmi b.gene_E_faecalis_SecY.fasta -o t.txt --debug Unmount the index.\nsudo umount atb.lmi Only download it and run locally Install awscli by\nconda install -c conda-forge awscli Test access\naws s3 ls s3://allthebacteria-lexicmap/202408/ --no-sign-request # output PRE genomes/ PRE seeds/ 2025-04-08 16:39:17 62488 genomes.chunks.bin 2025-04-08 16:39:17 54209660 genomes.map.bin 2025-04-08 22:32:35 619 info.toml 2025-04-08 22:32:36 160032 masks.bin Download the index (it\u0026rsquo;s 5.24 TiB!!!).\naws s3 cp s3://allthebacteria-lexicmap/202408/ atb.lmi --recursive --no-sign-request # dirsize atb.lmi atb.lmi: 5.24 TiB (5,758,875,365,595) 2.87 TiB seeds 2.37 TiB genomes 51.70 MiB genomes.map.bin 156.28 KiB masks.bin 61.02 KiB genomes.chunks.bin 619 B info.toml Steps for v0.2 and later versions hosted at OSF Make sure you have enough disk space, at least 8 TB, \u0026gt;10 TB is preferred.\nTools:\nhttps://github.com/shenwei356/rush, for running jobs Info:\nAllTheBacteria, All WGS isolate bacterial INSDC data to June 2023 uniformly assembled, QC-ed, annotated, searchable. Preprint: AllTheBacteria - all bacterial genomes assembled, available and searchable Data on OSF: https://osf.io/xv7q9/ After v0.2, AllTheBacteria releases incremental datasets periodically, with all data stored at OSF.\nDownloading the list file of all assemblies in the latest version (v0.2 plus incremental versions).\nmkdir -p atb; cd atb; # attention, the URL might changes, please check it in the browser. wget https://osf.io/download/4yv85/ -O file_list.all.latest.tsv.gz If you only need to add assemblies from an incremental version. Please manually download the file list in the path AllTheBacteria/Assembly/OSF Storage/File_lists.\nDownloading assembly tarball files.\n# tarball file names and their URLs zcat file_list.all.latest.tsv.gz | awk 'NR\u0026gt;1 {print $3\u0026quot;\\t\u0026quot;$4}' | uniq \u0026gt; tar2url.tsv # download cat tar2url.tsv | rush --eta -j 2 -c -C download.rush 'wget -O {1} {2}' Decompressing all tarballs. The decompressed genomes are stored in plain text, so we use gzip (can be replaced with faster pigz ) to compress them to save disk space.\n# {^tar.xz} is for removing the suffix \u0026quot;tar.xz\u0026quot; ls *.tar.xz | rush --eta -c -C decompress.rush 'tar -Jxf {}; gzip -f {^.tar.xz}/*.fa' cd .. After that, the assemblies directory would have multiple subdirectories. When you give the directory to lexicmap index -I, it can recursively scan (plain or gz/xz/zstd-compressed) genome files. You can also give a file list with selected assemblies.\n$ tree atb | more atb ├── atb.assembly.r0.2.batch.1 │ ├── SAMD00013333.fa.gz │ ├── SAMD00049594.fa.gz │ ├── SAMD00195911.fa.gz │ ├── SAMD00195914.fa.gz Prepare a file list of assemblies.\nJust use find or fd (much faster).\n# find find atb/ -name \u0026quot;*.fa.gz\u0026quot; \u0026gt; files.txt # fd fd .fa.gz$ atb/ \u0026gt; files.txt What it looks like:\n$ head -n 2 files.txt atb/atb.assembly.r0.2.batch.1/SAMD00013333.fa.gz atb/atb.assembly.r0.2.batch.1/SAMD00049594.fa.gz (Optional) Only keep assemblies of high-quality. Please click this link to download the hq_set.sample_list.txt.gz file, or from this page.\nfind atb/ -name \u0026quot;*.fa.gz\u0026quot; | grep -w -f \u0026lt;(zcat hq_set.sample_list.txt.gz) \u0026gt; files.txt Creating a LexicMap index. (more details: https://bioinf.shenwei.me/LexicMap/tutorials/index/)\nlexicmap index -S -X files.txt -O atb.lmi -b 25000 --log atb.lmi.log # dirsize atb.lmi atb.lmi: 5.24 TiB (5,758,698,088,389) 2.87 TiB seeds 2.37 TiB genomes 51.70 MiB genomes.map.bin 156.28 KiB masks.bin 61.02 KiB genomes.chunks.bin 619 B info.toml It took 47h40m and 145GB RAM with 48 CPUs for 2.44m ATB genomes.\nSteps for v0.2 hosted at EBI ftp Downloading assemblies tarballs here (except these starting with unknown__) to a directory (like atb): https://ftp.ebi.ac.uk/pub/databases/AllTheBacteria/Releases/0.2/assembly/\nmkdir -p atb; cd atb; # assembly file list, 650 files in total wget https://bioinf.shenwei.me/LexicMap/AllTheBacteria-v0.2.url.txt # download # rush is used: https://github.com/shenwei356/rush # The download.rush file stores finished jobs, which will be skipped in a second run for resuming jobs. cat AllTheBacteria-v0.2.url.txt | rush --eta -j 2 -c -C download.rush 'wget {}' # list of high-quality samples wget https://ftp.ebi.ac.uk/pub/databases/AllTheBacteria/Releases/0.2/metadata/hq_set.sample_list.txt.gz Decompressing all tarballs. The decompressed genomes are stored in plain text, so we use gzip (can be replaced with faster pigz ) to compress them to save disk space.\n# {^asm.tar.xz} is for removing the suffix \u0026quot;asm.tar.xz\u0026quot; ls *.tar.xz | rush --eta -c -C decompress.rush 'tar -Jxf {}; gzip -f {^asm.tar.xz}/*.fa' cd .. After that, the assemblies directory would have multiple subdirectories. When you give the directory to lexicmap index -I, it can recursively scan (plain or gz/xz/zstd-compressed) genome files. You can also give a file list with selected assemblies.\n$ tree atb | more atb ├── achromobacter_xylosoxidans__01 │ ├── SAMD00013333.fa.gz │ ├── SAMD00049594.fa.gz │ ├── SAMD00195911.fa.gz │ ├── SAMD00195914.fa.gz # disk usage $ du -sh atb 2.9T atb $ du -sh atb --apparent-size 2.1T atb Creating a LexicMap index. (more details: https://bioinf.shenwei.me/LexicMap/tutorials/index/)\n# file paths of all samples find atb/ -name \u0026quot;*.fa.gz\u0026quot; \u0026gt; atb_all.txt # wc -l atb_all.txt # 1876015 atb_all.txt # file paths of high-quality samples grep -w -f \u0026lt;(zcat atb/hq_set.sample_list.txt.gz) atb_all.txt \u0026gt; atb_hq.txt # wc -l atb_hq.txt # 1858610 atb_hq.txt # index lexicmap index -S -X atb_hq.txt -O atb_hq.lmi -b 25000 --log atb_hq.lmi.log For 1,858,610 HQ genomes, on a 48-CPU machine, time: 48 h, ram: 85 GB, index size: 3.88 TB. If you don\u0026rsquo;t have enough memory, please decrease the value of -b.\n# disk usage $ du -sh atb_hq.lmi 4.6T atb_hq.lmi $ du -sh atb_hq.lmi --apparent-size 3.9T atb_hq.lmi $ dirsize atb_hq.lmi atb_hq.lmi: 3.88 TiB (4,261,437,129,065) 2.11 TiB seeds 1.77 TiB genomes 39.22 MiB genomes.map.bin 312.53 KiB masks.bin 332 B info.toml Note that, there\u0026rsquo;s a tmp directory atb_hq.lmi being created during indexing. In the tmp directory, the seed data would be bigger than the final size of seeds directory, however, the genome files are simply moved to the final index.\n","description":" Table of contents Table of contents Searching with the pre-built index on AWS Run on EC2 Only download it and run locally Steps for v0.2 and later versions hosted at OSF Steps for v0.2 hosted at EBI ftp Searching with the pre-built index on AWS Run on EC2 Launch an EC2 instance in Europe London region (eu-west-2) where the index is located.\n"},{"id":8,"href":"/LexicMap/usage/utils/genomes/","title":"genomes","parent":"utils","content":" Usage $ lexicmap utils genomes -h View genome IDs in the index Usage: lexicmap utils genomes [flags] Flags: -h, --help help for genomes -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. -o, --out-file string ► Out file, supports the \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 8) Examples $ lexicmap utils genomes -d demo.lmi/ GCF_000148585.2 GCF_001457655.1 GCF_900638025.1 GCF_001096185.1 GCF_006742205.1 GCF_001544255.1 GCF_000392875.1 GCF_001027105.1 GCF_009759685.1 GCF_002949675.1 GCF_002950215.1 GCF_000006945.2 GCF_003697165.2 GCF_000742135.1 GCF_000017205.1 ","description":" Usage $ lexicmap utils genomes -h View genome IDs in the index Usage: lexicmap utils genomes [flags] Flags: -h, --help help for genomes -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. -o, --out-file string ► Out file, supports the \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 8) Examples $ lexicmap utils genomes -d demo.lmi/ GCF_000148585.2 GCF_001457655.1 GCF_900638025.1 GCF_001096185.1 GCF_006742205.1 GCF_001544255.1 GCF_000392875.1 GCF_001027105.1 GCF_009759685.1 GCF_002949675.1 GCF_002950215.1 GCF_000006945.2 GCF_003697165.2 GCF_000742135.1 GCF_000017205.1 "},{"id":9,"href":"/LexicMap/tutorials/misc/index-globdb/","title":"Indexing GlobDB","parent":"More","content":"Info:\nGlobDB , a dereplicated dataset of the species reps of the GTDB, GEM, SPIRE and SMAG datasets a lot. https://x.com/daanspeth/status/1822964436950192218 Steps:\n# download data wget https://fileshare.lisc.univie.ac.at/globdb/globdb_r220/globdb_r220_genome_fasta.tar.gz tar -zxf globdb_r220_genome_fasta.tar.gz # file list find globdb_r220_genome_fasta/ -name \u0026quot;*.fa.gz\u0026quot; \u0026gt; files.txt # index with lexicmap # elapsed time: 3h:40m:38s # peak rss: 87.15 GB lexicmap index -S -X files.txt -O globdb_r220.lmi --log globdb_r220.lmi -g 50000000 ","description":"Info:\nGlobDB , a dereplicated dataset of the species reps of the GTDB, GEM, SPIRE and SMAG datasets a lot. https://x.com/daanspeth/status/1822964436950192218 Steps:\n# download data wget https://fileshare.lisc.univie.ac.at/globdb/globdb_r220/globdb_r220_genome_fasta.tar.gz tar -zxf globdb_r220_genome_fasta.tar.gz # file list find globdb_r220_genome_fasta/ -name \u0026quot;*.fa.gz\u0026quot; \u0026gt; files.txt # index with lexicmap # elapsed time: 3h:40m:38s # peak rss: 87.15 GB lexicmap index -S -X files.txt -O globdb_r220.lmi --log globdb_r220.lmi -g 50000000 "},{"id":10,"href":"/LexicMap/installation/","title":"Installation","parent":"","content":"LexicMap can be installed via conda, downloading executable binary files, or compiling from the source.\nBesides, it supports shell completion, which could help accelerate typing.\nConda/Pixi Install conda, then run\nconda install -c bioconda lexicmap Or use mamba, which is faster.\nconda install -c conda-forge mamba mamba install -c bioconda lexicmap Or use pixi, which is even faster.\npixi config channels add bioconda pixi add lexicmap Linux and MacOS (both x86 and arm CPUs) are supported.\nBinary files Linux Download the binary file.\nOS Arch File, 中国镜像 Linux 64-bit lexicmap_linux_amd64.tar.gz, 中国镜像 Linux arm64 lexicmap_linux_arm64.tar.gz, 中国镜像 Decompress it:\ntar -zxvf lexicmap_linux_amd64.tar.gz If you have the root privilege, simply copy it to /usr/local/bin:\nsudo cp lexicmap /usr/local/bin/ If you don\u0026rsquo;t have the root privilege, copy it to any directory in the environment variable PATH:\nmkdir -p $HOME/bin/; cp lexicmap $HOME/bin/ And optionally add the directory into the environment variable PATH if it\u0026rsquo;s not in.\n# bash echo export PATH=\\$PATH:\\$HOME/bin/ \u0026gt;\u0026gt; $HOME/.bashrc source $HOME/.bashrc # apply the configuration # zsh echo export PATH=\\$PATH:\\$HOME/bin/ \u0026gt;\u0026gt; $HOME/.zshrc source $HOME/.zshrc # apply the configuration MacOS Download the binary file.\nOS Arch File, 中国镜像 macOS 64-bit lexicmap_darwin_amd64.tar.gz, 中国镜像 macOS arm64 lexicmap_darwin_arm64.tar.gz, 中国镜像 Copy it to any directory in the environment variable PATH:\nmkdir -p $HOME/bin/; cp lexicmap $HOME/bin/ And optionally add the directory into the environment variable PATH if it\u0026rsquo;s not in.\n# bash echo export PATH=\\$PATH:\\$HOME/bin/ \u0026gt;\u0026gt; $HOME/.bashrc source $HOME/.bashrc # apply the configuration # zsh echo export PATH=\\$PATH:\\$HOME/bin/ \u0026gt;\u0026gt; $HOME/.zshrc source $HOME/.zshrc # apply the configuration FreeBSD Download the binary file. OS Arch File, 中国镜像 FreeBSD 64-bit lexicmap_freebsd_amd64.tar.gz, 中国镜像 Windows Download the binary file.\nOS Arch File, 中国镜像 Windows 64-bit lexicmap_windows_amd64.exe.tar.gz, 中国镜像 Decompress it.\nCopy lexicmap.exe to C:\\WINDOWS\\system32.\nOthers Please open an issue to request binaries for other platforms. Or compiling from the source. Compile from the source Install go (go 1.22 or later versions).\nwget https://go.dev/dl/go1.24.1.linux-amd64.tar.gz tar -zxf go1.24.1.linux-amd64.tar.gz -C $HOME/ # or # echo \u0026quot;export PATH=$PATH:$HOME/go/bin\u0026quot; \u0026gt;\u0026gt; ~/.bashrc # source ~/.bashrc export PATH=$PATH:$HOME/go/bin Compile LexicMap.\n# ------------- the latest stable version ------------- go install -v github.com/shenwei356/LexicMap@latest # The executable binary file is located in: # ~/go/bin/lexicmap # You can also move it to anywhere in the $PATH mkdir -p $HOME/bin cp ~/go/bin/lexicmap $HOME/bin/ # --------------- the development version -------------- git clone https://github.com/shenwei356/LexicMap cd LexicMap/lexicmap/ go build # The executable binary file is located in: # ./lexicmap # You can also move it to anywhere in the $PATH mkdir -p $HOME/bin cp ./lexicmap $HOME/bin/ Shell-completion Supported shell: bash|zsh|fish|powershell\nBash:\n# generate completion shell lexicmap autocompletion --shell bash # configure if never did. # install bash-completion if the \u0026quot;complete\u0026quot; command is not found. echo \u0026quot;for bcfile in ~/.bash_completion.d/* ; do source \\$bcfile; done\u0026quot; \u0026gt;\u0026gt; ~/.bash_completion echo \u0026quot;source ~/.bash_completion\u0026quot; \u0026gt;\u0026gt; ~/.bashrc Zsh:\n# generate completion shell lexicmap autocompletion --shell zsh --file ~/.zfunc/_kmcp # configure if never did echo 'fpath=( ~/.zfunc \u0026quot;${fpath[@]}\u0026quot; )' \u0026gt;\u0026gt; ~/.zshrc echo \u0026quot;autoload -U compinit; compinit\u0026quot; \u0026gt;\u0026gt; ~/.zshrc fish:\nlexicmap autocompletion --shell fish --file ~/.config/fish/completions/lexicmap.fish ","description":"LexicMap can be installed via conda, downloading executable binary files, or compiling from the source.\nBesides, it supports shell completion, which could help accelerate typing.\nConda/Pixi Install conda, then run\nconda install -c bioconda lexicmap Or use mamba, which is faster.\nconda install -c conda-forge mamba mamba install -c bioconda lexicmap Or use pixi, which is even faster.\n"},{"id":11,"href":"/LexicMap/usage/search/","title":"search","parent":"Usage","content":"$ lexicmap search -h Search sequences against an index Attention: 1. Input should be (gzipped) FASTA or FASTQ records from files or stdin. 2. For multiple queries, the order of queries in output might be different from the input. Tips: 1. When using -a/--all, the search result would be formatted to Blast-style format with \u0026#39;lexicmap utils 2blast\u0026#39;. And the search speed would be slightly slowed down. 2. Alignment result filtering is performed in the final phase, so stricter filtering criteria, including -q/--min-qcov-per-hsp, -Q/--min-qcov-per-genome, and -i/--align-min-match-pident, do not significantly accelerate the search speed. Hence, you can search with default parameters and then filter the result with tools like awk or csvtk. Alignment result relationship: Query ├── Subject genome ├── Subject sequence ├── HSP cluster (a cluster of neighboring HSPs) ├── High-Scoring segment Pair (HSP) Here, the defination of HSP is similar with that in BLAST. Actually there are small gaps in HSPs. \u0026gt; A High-scoring Segment Pair (HSP) is a local alignment with no gaps that achieves one of the \u0026gt; highest alignment scores in a given search. https://www.ncbi.nlm.nih.gov/books/NBK62051/ Output format: Tab-delimited format with 20+ columns, with 1-based positions. 1. query, Query sequence ID. 2. qlen, Query sequence length. 3. hits, Number of subject genomes. 4. sgenome, Subject genome ID. 5. sseqid, Subject sequence ID. 6. qcovGnm, Query coverage (percentage) per genome: $(aligned bases in the genome)/$qlen. 7. cls, Nth HSP cluster in the genome. (just for improving readability) It\u0026#39;s useful to show if multiple adjacent HSPs are collinear. 8. hsp, Nth HSP in the genome. (just for improving readability) 9. qcovHSP Query coverage (percentage) per HSP: $(aligned bases in a HSP)/$qlen. 10. alenHSP, Aligned length in the current HSP. 11. pident, Percentage of identical matches in the current HSP. 12. gaps, Gaps in the current HSP. 13. qstart, Start of alignment in query sequence. 14. qend, End of alignment in query sequence. 15. sstart, Start of alignment in subject sequence. 16. send, End of alignment in subject sequence. 17. sstr, Subject strand. 18. slen, Subject sequence length. 19. evalue, Expect value. 20. bitscore, Bit score. 21. cigar, CIGAR string of the alignment. (optional with -a/--all) 22. qseq, Aligned part of query sequence. (optional with -a/--all) 23. sseq, Aligned part of subject sequence. (optional with -a/--all) 24. align, Alignment text (\u0026#34;|\u0026#34; and \u0026#34; \u0026#34;) between qseq and sseq. (optional with -a/--all) Result ordering: For a HSP cluster, SimilarityScore = max(bitscore*pident) 1. Within each HSP cluster, HSPs are sorted by sstart. 2. Within each subject genome, HSP clusters are sorted in descending order by SimilarityScore. 3. Results of multiple subject genomes are sorted by the highest SimilarityScore of HSP clusters. Usage: lexicmap search [flags] -d \u0026lt;index path\u0026gt; [query.fasta.gz ...] [-o query.tsv.gz] Flags: --align-band int ► Band size in backtracking the score matrix (pseudo alignment phase). (default 100) --align-ext-len int ► Extend length of upstream and downstream of seed regions, for extracting query and target sequences for alignment. It should be \u0026lt;= contig interval length in database. (default 1000) --align-max-gap int ► Maximum gap in a HSP segment. (default 20) -l, --align-min-match-len int ► Minimum aligned length in a HSP segment. (default 50) -i, --align-min-match-pident float ► Minimum base identity (percentage) in a HSP segment. (default 70) -a, --all ► Output more columns, e.g., matched sequences. Use this if you want to output blast-style format with \u0026#34;lexicmap utils 2blast\u0026#34;. --debug ► Print debug information, including a progress bar. (recommended when searching with one query). -h, --help help for search -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. -w, --load-whole-seeds ► Load the whole seed data into memory for faster seed matching. It will consume a lot of RAM. -e, --max-evalue float ► Maximum evalue of a HSP segment. (default 10) --max-open-files int ► Maximum opened files. It mainly affects candidate subsequence extraction. Increase this value if you have hundreds of genome batches or have multiple queries, and do not forgot to set a bigger \u0026#34;ulimit -n\u0026#34; in shell if the value is \u0026gt; 1024. (default 1024) -J, --max-query-conc int ► Maximum number of concurrent queries. Bigger values do not improve the batch searching speed and consume much memory. (default 12) -Q, --min-qcov-per-genome float ► Minimum query coverage (percentage) per genome. -q, --min-qcov-per-hsp float ► Minimum query coverage (percentage) per HSP. -o, --out-file string ► Out file, supports a \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) --seed-max-dist int ► Minimum distance between seeds in seed chaining. It should be \u0026lt;= contig interval length in database. (default 1000) --seed-max-gap int ► Minimum gap in seed chaining. (default 50) -p, --seed-min-prefix int ► Minimum (prefix/suffix) length of matched seeds (anchors). (default 15) -P, --seed-min-single-prefix int ► Minimum (prefix/suffix) length of matched seeds (anchors) if there\u0026#39;s only one pair of seeds matched. (default 17) -n, --top-n-genomes int ► Keep top N genome matches for a query (0 for all) in chaining phase. Value 1 is not recommended as the best chaining result does not always bring the best alignment, so it better be \u0026gt;= 100. (default 0) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples See Searching ","description":"$ lexicmap search -h Search sequences against an index Attention: 1. Input should be (gzipped) FASTA or FASTQ records from files or stdin. 2. For multiple queries, the order of queries in output might be different from the input. Tips: 1. When using -a/--all, the search result would be formatted to Blast-style format with \u0026#39;lexicmap utils 2blast\u0026#39;. And the search speed would be slightly slowed down. 2. Alignment result filtering is performed in the final phase, so stricter filtering criteria, including -q/--min-qcov-per-hsp, -Q/--min-qcov-per-genome, and -i/--align-min-match-pident, do not significantly accelerate the search speed. Hence, you can search with default parameters and then filter the result with tools like awk or csvtk. Alignment result relationship: Query ├── Subject genome ├── Subject sequence ├── HSP cluster (a cluster of neighboring HSPs) ├── High-Scoring segment Pair (HSP) Here, the defination of HSP is similar with that in BLAST. Actually there are small gaps in HSPs. \u0026gt; A High-scoring Segment Pair (HSP) is a local alignment with no gaps that achieves one of the \u0026gt; highest alignment scores in a given search. https://www.ncbi.nlm.nih.gov/books/NBK62051/ Output format: Tab-delimited format with 20+ columns, with 1-based positions. 1. query, Query sequence ID. 2. qlen, Query sequence length. 3. hits, Number of subject genomes. 4. sgenome, Subject genome ID. 5. sseqid, Subject sequence ID. 6. qcovGnm, Query coverage (percentage) per genome: $(aligned bases in the genome)/$qlen. 7. cls, Nth HSP cluster in the genome. (just for improving readability) It\u0026#39;s useful to show if multiple adjacent HSPs are collinear. 8. hsp, Nth HSP in the genome. (just for improving readability) 9. qcovHSP Query coverage (percentage) per HSP: $(aligned bases in a HSP)/$qlen. 10. alenHSP, Aligned length in the current HSP. 11. pident, Percentage of identical matches in the current HSP. 12. gaps, Gaps in the current HSP. 13. qstart, Start of alignment in query sequence. 14. qend, End of alignment in query sequence. 15. sstart, Start of alignment in subject sequence. 16. send, End of alignment in subject sequence. 17. sstr, Subject strand. 18. slen, Subject sequence length. 19. evalue, Expect value. 20. bitscore, Bit score. 21. cigar, CIGAR string of the alignment. (optional with -a/--all) 22. qseq, Aligned part of query sequence. (optional with -a/--all) 23. sseq, Aligned part of subject sequence. (optional with -a/--all) 24. align, Alignment text (\u0026#34;|\u0026#34; and \u0026#34; \u0026#34;) between qseq and sseq. (optional with -a/--all) Result ordering: For a HSP cluster, SimilarityScore = max(bitscore*pident) 1. Within each HSP cluster, HSPs are sorted by sstart. 2. Within each subject genome, HSP clusters are sorted in descending order by SimilarityScore. 3. Results of multiple subject genomes are sorted by the highest SimilarityScore of HSP clusters. Usage: lexicmap search [flags] -d \u0026lt;index path\u0026gt; [query.fasta.gz ...] [-o query.tsv.gz] Flags: --align-band int ► Band size in backtracking the score matrix (pseudo alignment phase). (default 100) --align-ext-len int ► Extend length of upstream and downstream of seed regions, for extracting query and target sequences for alignment. It should be \u0026lt;= contig interval length in database. (default 1000) --align-max-gap int ► Maximum gap in a HSP segment. (default 20) -l, --align-min-match-len int ► Minimum aligned length in a HSP segment. (default 50) -i, --align-min-match-pident float ► Minimum base identity (percentage) in a HSP segment. (default 70) -a, --all ► Output more columns, e.g., matched sequences. Use this if you want to output blast-style format with \u0026#34;lexicmap utils 2blast\u0026#34;. --debug ► Print debug information, including a progress bar. (recommended when searching with one query). -h, --help help for search -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. -w, --load-whole-seeds ► Load the whole seed data into memory for faster seed matching. It will consume a lot of RAM. -e, --max-evalue float ► Maximum evalue of a HSP segment. (default 10) --max-open-files int ► Maximum opened files. It mainly affects candidate subsequence extraction. Increase this value if you have hundreds of genome batches or have multiple queries, and do not forgot to set a bigger \u0026#34;ulimit -n\u0026#34; in shell if the value is \u0026gt; 1024. (default 1024) -J, --max-query-conc int ► Maximum number of concurrent queries. Bigger values do not improve the batch searching speed and consume much memory. (default 12) -Q, --min-qcov-per-genome float ► Minimum query coverage (percentage) per genome. -q, --min-qcov-per-hsp float ► Minimum query coverage (percentage) per HSP. -o, --out-file string ► Out file, supports a \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) --seed-max-dist int ► Minimum distance between seeds in seed chaining. It should be \u0026lt;= contig interval length in database. (default 1000) --seed-max-gap int ► Minimum gap in seed chaining. (default 50) -p, --seed-min-prefix int ► Minimum (prefix/suffix) length of matched seeds (anchors). (default 15) -P, --seed-min-single-prefix int ► Minimum (prefix/suffix) length of matched seeds (anchors) if there\u0026#39;s only one pair of seeds matched. (default 17) -n, --top-n-genomes int ► Keep top N genome matches for a query (0 for all) in chaining phase. Value 1 is not recommended as the best chaining result does not always bring the best alignment, so it better be \u0026gt;= 100. (default 0) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples See Searching "},{"id":12,"href":"/LexicMap/usage/utils/subseq/","title":"subseq","parent":"utils","content":" Usage $ lexicmap utils subseq -h Exextract subsequence via reference name, sequence ID, position and strand Attention: 1. The option -s/--seq-id is optional. 1) If given, the positions are these in the original sequence. 2) If not given, the positions are these in the concatenated sequence. 2. All degenerate bases in reference genomes were converted to the lexicographic first bases. E.g., N was converted to A. Therefore, consecutive A\u0026#39;s in output might be N\u0026#39;s in the genomes. Usage: lexicmap utils subseq [flags] Flags: -h, --help help for subseq -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. -w, --line-width int ► Line width of sequence (0 for no wrap). (default 60) -o, --out-file string ► Out file, supports the \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) -n, --ref-name string ► Reference name. -r, --region string ► Region of the subsequence (1-based). -R, --revcom ► Extract subsequence on the negative strand. -s, --seq-id string ► Sequence ID. If the value is empty, the positions in the region are treated as that in the concatenated sequence. Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples Extracting subsequence with genome ID, sequence ID, position range and strand information.\n$ lexicmap utils subseq -d demo.lmi/ -n GCF_003697165.2 -s NZ_CP033092.2 -r 4591684:4593225 -R \u0026gt;NZ_CP033092.2:4591684-4593225:- AAATTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGGCCTAACACATGCAA GTCGAACGGTAACAGGAAGCAGCTTGCTGCTTTGCTGACGAGTGGCGGACGGGTGAGTAA TGTCTGGGAAACTGCCTGATGGAGGGGGATAACTACTGGAAACGGTAGCTAATACCGCAT AACGTCGCAAGACCAAAGAGGGGGACCTTAGGGCCTCTTGCCATCGGATGTGCCCAGATG GGATTAGCTAGTAGGTGGGGTAACGGCTCACCTAGGCGACGATCCCTAGCTGGTCTGAGA GGATGACCAGCCACACTGGAACTGAGACACGGTCCAGACTCCTACGGGAGGCAGCAGTGG GGAATATTGCACAATGGGCGCAAGCCTGATGCAGCCATGCCGCGTGTATGAAGAAGGCCT TCGGGTTGTAAAGTACTTTCAGCGGGGAGGAAGGGAGTAAAGTTAATACCTTTGCTCATT GACGTTACCCGCAGAAGAAGCACCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAG GGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAGCGCACGCAGGCGGTTTGTTAAGTCA GATGTGAAATCCCCGGGCTCAACCTGGGAACTGCATCTGATACTGGCAAGCTTGAGTCTC GTAGAGGGGGGTAGAATTCCAGGTGTAGCGGTGAAATGCGTAGAGATCTGGAGGAATACC GGTGGCGAAGGCGGCCCCCTGGACGAAGACTGACGCTCAGGTGCGAAAGCGTGGGGAGCA AACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGATGTCGACTTGGAGGTTGTGCC CTTGAGGCGTGGCTTCCGGAGCTAACGCGTTAAGTCGACCGCCTGGGGAGTACGGCCGCA AGGTTAAAACTCAAATGAATTGACGGGGGCCCGCACAAGCGGTGGAGCATGTGGTTTAAT TCGATGCAACGCGAAGAACCTTACCTGGTCTTGACATCCACGGAAGTTTTCAGAGATGAG AATGTGCCTTCGGGAACCGTGAGACAGGTGCTGCATGGCTGTCGTCAGCTCGTGTTGTGA AATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCTTATCCTTTGTTGCCAGCGGTCCGGC CGGGAACTCAAAGGAGACTGCCAGTGATAAACTGGAGGAAGGTGGGGATGACGTCAAGTC ATCATGGCCCTTACGACCAGGGCTACACACGTGCTACAATGGCGCATACAAAGAGAAGCG ACCTCGCGAGAGCAAGCGGACCTCATAAAGTGCGTCGTAGTCCGGATTGGAGTCTGCAAC TCGACTCCATGAAGTCGGAATCGCTAGTAATCGTGGATCAGAATGCCACGGTGAATACGT TCCCGGGCCTTGTACACACCGCCCGTCACACCATGGGAGTGGGTTGCAAAAGAAGTAGGT AGCTTAACCTTCGGGAGGGCGCTTACCACTTTGTGATTCATGACTGGGGTGAAGTCGTAA CAAGGTAACCGTAGGGGAACCTGCGGTTGGATCACCTCCTTA If the sequence ID (-s/--seq-id) is not given, the positions are these in the concatenated sequence.\nChecking sequence lengths of a genome with seqkit.\n$ seqkit fx2tab -nil refs/GCF_003697165.2.fa.gz NZ_CP033092.2 4903501 NZ_CP033091.2 131333 Extracting the 1000-bp interval sequence inserted by lexicmap index.\n$ lexicmap utils subseq -d demo.lmi/ -n GCF_003697165.2 -r 4903502:4904501 \u0026gt;GCF_003697165.2:4903502-4904501:+ AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA It detects if the end position is larger than the sequence length.\n# the length of NZ_CP033092.2 is 4903501 $ lexicmap utils subseq -d demo.lmi/ -n GCF_003697165.2 -s NZ_CP033092.2 -r 4903501:1000000000 \u0026gt;NZ_CP033092.2:4903501-4903501:+ C $ lexicmap utils subseq -d demo.lmi/ -n GCF_003697165.2 -s NZ_CP033092.2 -r 4903502:1000000000 \u0026gt;NZ_CP033092.2:4903502-4903501:+ ","description":" Usage $ lexicmap utils subseq -h Exextract subsequence via reference name, sequence ID, position and strand Attention: 1. The option -s/--seq-id is optional. 1) If given, the positions are these in the original sequence. 2) If not given, the positions are these in the concatenated sequence. 2. All degenerate bases in reference genomes were converted to the lexicographic first bases. E.g., N was converted to A. Therefore, consecutive A\u0026#39;s in output might be N\u0026#39;s in the genomes. Usage: lexicmap utils subseq [flags] Flags: -h, --help help for subseq -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. -w, --line-width int ► Line width of sequence (0 for no wrap). (default 60) -o, --out-file string ► Out file, supports the \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) -n, --ref-name string ► Reference name. -r, --region string ► Region of the subsequence (1-based). -R, --revcom ► Extract subsequence on the negative strand. -s, --seq-id string ► Sequence ID. If the value is empty, the positions in the region are treated as that in the concatenated sequence. Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples Extracting subsequence with genome ID, sequence ID, position range and strand information.\n"},{"id":13,"href":"/LexicMap/tutorials/misc/index-uhgg/","title":"Indexing UHGG","parent":"More","content":"Info:\nUnified Human Gastrointestinal Genome (UHGG) v2.0.2 A unified catalog of 204,938 reference genomes from the human gut microbiome Number of Genomes: 289,232 Tools:\nhttps://github.com/shenwei356/seqkit, for checking sequence files https://github.com/shenwei356/rush, for running jobs Data:\n# meta data wget https://ftp.ebi.ac.uk/pub/databases/metagenomics/mgnify_genomes/human-gut/v2.0.2/genomes-all_metadata.tsv # gff url sed 1d genomes-all_metadata.tsv | cut -f 20 | sed 's/v2.0/v2.0.2/' | sed -E 's/^ftp/https/' \u0026gt; url.txt # download gff files mkdir -p files; cd files time cat ../url.txt \\ | rush --eta -v 'dir={///%}/{//%}' \\ 'mkdir -p {dir}; curl -s -o {dir}/{%} {}' \\ -c -C download.rush -j 12 cd .. # extract sequences from gff files find files/ -name \u0026quot;*.gff.gz\u0026quot; \\ | rush --eta \\ 'zcat {} | perl -ne \u0026quot;print if \\$s; \\$s=true if /^##FASTA/\u0026quot; | seqkit seq -w 0 -o {/}/{%:}.fna.gz' \\ -c -C extract.rush Indexing. On a 48-CPU machine, time: 3 h, ram: 41 GB, index size: 426 GB. If you don\u0026rsquo;t have enough memory, please decrease the value of -b.\nlexicmap index \\ -I files/ \\ -O uhgg.lmi --log uhgg.lmi.log \\ -b 5000 File sizes:\n$ du -sh files/ uhgg.lmi 658G files/ 509G uhgg.lmi $ du -sh files/ uhgg.lmi --apparent-size 425G files/ 426G uhgg.lmi $ dirsize uhgg.lmi uhgg.lmi: 425.15 GiB (456,497,171,291) 243.47 GiB seeds 181.67 GiB genomes 6.34 MiB genomes.map.bin 312.53 KiB masks.bin 330 B info.toml ","description":"Info:\nUnified Human Gastrointestinal Genome (UHGG) v2.0.2 A unified catalog of 204,938 reference genomes from the human gut microbiome Number of Genomes: 289,232 Tools:\nhttps://github.com/shenwei356/seqkit, for checking sequence files https://github.com/shenwei356/rush, for running jobs Data:\n# meta data wget https://ftp.ebi.ac.uk/pub/databases/metagenomics/mgnify_genomes/human-gut/v2.0.2/genomes-all_metadata.tsv # gff url sed 1d genomes-all_metadata.tsv | cut -f 20 | sed 's/v2.0/v2.0.2/' | sed -E 's/^ftp/https/' \u0026gt; url.txt # download gff files mkdir -p files; cd files time cat ../url.txt \\ | rush --eta -v 'dir={///%}/{//%}' \\ 'mkdir -p {dir}; curl -s -o {dir}/{%} {}' \\ -c -C download.rush -j 12 cd .. # extract sequences from gff files find files/ -name \u0026quot;*.gff.gz\u0026quot; \\ | rush --eta \\ 'zcat {} | perl -ne \u0026quot;print if \\$s; \\$s=true if /^##FASTA/\u0026quot; | seqkit seq -w 0 -o {/}/{%:}.fna.gz' \\ -c -C extract.rush Indexing. On a 48-CPU machine, time: 3 h, ram: 41 GB, index size: 426 GB. If you don\u0026rsquo;t have enough memory, please decrease the value of -b.\n"},{"id":14,"href":"/LexicMap/releases/","title":"Releases","parent":"","content":" Latest version Note Please run lexicmap version to check update !!! Please run lexicmap autocompletion to update shell autocompletion script !!! v0.7.0 - 2025-04-11 v0.7.0 - 2025-04-10 Please rebuild the index, as some seeds in the genome end regions were missed during computation.\nlexicmap index: Fix a little bug in seed desert filling \u0026ndash; forgot to fill the region (a few hundred bases) behind the last seed. lexicmap search: Improve seed chaining \u0026ndash; more accurate for complex anchors. Improve pseudoalignment in repetitive regions. Change the default value of --seed-max-gap from 200 to 50. Previous versions v0.6.1 - 2025-03-31 v0.6.1 - 2025-03-31 lexicmap search: Fix the program hang in the debug mode when no chaining result is returned. lexicmap version: Do not show commit hash by default. v0.6.0 - 2025-03-25 v0.6.0 - 2025-03-25 This version is compatible with indexes created by previous versions (requires a one-time, automatic preprocessing), but rebuilding the index is recommended for more accurate results on short queries (\u0026lt;500bp). However, indexes created by this version are not compatible with previous versions when the number of batches is \u0026lt;= 512.\nlexicmap index: Change default option values to bring a higher sensitivity for short (\u0026lt;=500, especially \u0026lt;=250) queries, faster indexing speed, and faster seed-matching speed, at a cost of slightly larger index. -m/--masks: 40,000 -\u0026gt; 20,000. 40k is unnecessary especially for small genomes, where seeds would be very crowded, with a big proportion of seed distance being between 0-50 bp. -D/--seed-max-desert: 200 -\u0026gt; 100. This provides a smaller seed window guarantee. Reduce index size by using 3 bytes rather than 4 for saving seed data when the number of batches is \u0026lt;= 512, which requires only 9 (17 minus 8) bits to store the batch index. We also recommend controlling the number of batches for better performance. Fix seed desert filling near gap regions. lexicmap search: Improve pseudoalignment to produce longer alignment regions. Add 3 extra columns: cls, evalue and bitscore, and a new option -e/--max-evalue. Reduce memory usage. Remove flag --pseudo-align. Add a progress bar for --debug. lexicmap utils seed-pos: Change default option values of sliding window. v0.5.0 v0.5.0 - 2025-12-18 This version is compatible with indexes created by LexicMap v0.4.0, but rebuilding the index is recommended for more accurate results.\nNew commands: lexicmap utils remerge: Rerun the merging step for an unfinished index. lexicmap index: Big genomes with thousands of contigs (big yet fragmented assemblies) are automatically split into multiple chunks, and alignments from these chunks will be merged. Change the default value of --partitions from 1024 to 4096, which increases the seed-matching speed at the cost of 2 GiB more memory occupation. For existing lexicmap indexes, just run lexicmap utils reindex-seeds --partitions 4096 to re-create seed indexes. Do not save seeds of low-complexity. Fix high memory usage in writing seed data. Change the default value of -c/--chunks from all available CPUs to the value of -j/--threads. Change the default value of --max-open-files from 512 to 1024. Add a new flag --debug. lexicmap search: Improving chaining, pseudoalignment, and alignment for highly repetitive sequences. More accurate chaining score with better chaining of overlapped anchors, this produces more accurate results with -n/--top-n-genomes: Merging two overlapped non-gapped anchors into a longer one. For these with gaps, only the non-overlapped part of the second anchor is used to compute the weight. Using the score of the best chain (rather than the sum) for sorting genomes when using -n. Fix positions and alignment texts for queries with highly repetitive sequences in end regions. #9 Skip seeds of low-complexity. Change the default value of --max-open-files from 512 to 1024. Change the default value of --align-band from 50 to 100. Improve the speed of anchor deduplication, genome information extraction, and result ordering. Improve the speed of chaining for long queries. Improve the speed of seed matching when using -w/--load-whole-seeds. Improve the speed of alignment, and reduce the memory usage. Remain compatible after the change of lexicmap index. Add a new flag --debug. lexicmap utils genomes: Do not sort genome ids. Add a header line and add another column to show if the reference genome is chunked. lexicmap utils subseq: Remain compatible after the change of lexicmap index. lexicmap utils seed-pos: Remain compatible after the change of lexicmap index, while histograms are plotted separately for multiple genome chunks. lexicmap utils reindex-seeds: Change the default value of --partitions from 1024 to 4096. v0.4.0 v0.4.0 - 2024-08-15 New commands: lexicmap utils 2blast: Convert the default search output to blast-style format. lexicmap index: Support suffix matching of seeds, now seeds are immune to any single SNP!!!, at the cost of doubled seed data. Better sketching desert filling for highly-repetitive regions. Change the default value of --seed-max-desert from 900 to 200 to increase alignment sensitivity. Mask gap regions (N\u0026rsquo;s). Fix skipping interval regions by further including the last k-1 bases of contigs. Fix a bug in indexing small genomes. Change the default value of -b, --batch-size from 10,000 to 5,000. Improve lexichash data structure. Write and merge seed data in parallel, new flag -J/--seed-data-threads. Improve the log. lexicmap search: Fix chaining for highly-repetitive regions. Perform more accurate alignment with WFA. Use buffered reader for seeds file reading. Fix object recycling and reduce memory usage. Fix alignment against genomes with many short contigs. Fix early quit when meeting a sequence shorter than k. Add a new option -J/--max-query-conc to limit the miximum number of concurrent queries, with a default valule of 12 instead of the number of CPUs, which reduces the memory usage in batch searching. Result format: Cluster alignments of each target sequence. Remove the column seeds. Add columns gaps, cigar, align, which can be reformated with lexicmap utils 2blast. lexicmap utils kmers: Fix the progress bar. Fix a bug where some masks do not have any k-mer. Add a new column prefix to show the length of common prefix between the seed and the probe. Add a new column reversed to indicate if the k-mer is reversed for suffix matching. lexicmap utils masks: Add the support of only outputting a specific mask. lexicmap utils seed-pos: New columns: sseqid and pos_seq. More accurate seed distance. Add histograms of numbers of seed in sliding windows. lexicmap utils subseq: Fix a bug when the given end position is larger than the sequence length. Add the strand (\u0026quot;+\u0026quot; or \u0026ldquo;-\u0026rdquo;) in the sequence header. v0.3.0 v0.3.0 - 2024-05-14 lexicmap index: Better seed coverage by filling sketching deserts. Use longer (1000bp N\u0026rsquo;s, previous: k-1) intervals between contigs. Fix a concurrency bug between genome data writing and k-mer-value data collecting. Change the format of k-mer-value index file, and fix the computation of index partitions. Optionally save seed positions which can be outputted by lexicmap utils seed-pos. lexicmap search: Improved seed-chaining algorithm. Better support of long queries. Add a new flag -w/--load-whole-seeds for loading the whole seed data into memory for faster search. Parallelize alignment in each query, so it\u0026rsquo;s faster for a single query. Optional outputing matched query and subject sequences. 2-5X searching speed with a faster masking method. Change output format. Add output of query start and end positions. Fix a target sequence extracting bug. Keep indexes of genome data in memory. lexicmap utils kmers: Fix a little bug, wrong number of k-mers for the second k-mer in each k-mer pair. New commands: lexicmap utils gen-masks for generating masks from the top N largest genomes. lexicmap utils seed-pos for extracting seed positions via reference names. lexicmap utils reindex-seeds for recreating indexes of k-mer-value (seeds) data. lexicmap utils genomes for list genomes IDs in the index. v0.2.0 v0.2.0 - 2024-02-02 Software architecture and index formats are redesigned to reduce searching memory occupation. Indexing: genomes are processed in batches to reduce RAM usage, then indexes of all batches are merged. Searching: seeds matching is performed on disk yet it\u0026rsquo;s ultra-fast. v0.1.0 v0.1.0 - 2024-01-15 The first release. Seed indexing and querying are performed in RAM. GTDB r214 with 10k masks: index size 75GB, RAM: 130GB. ","description":" Latest version Note Please run lexicmap version to check update !!! Please run lexicmap autocompletion to update shell autocompletion script !!! v0.7.0 - 2025-04-11 v0.7.0 - 2025-04-10 "},{"id":15,"href":"/LexicMap/usage/utils/seed-pos/","title":"seed-pos","parent":"utils","content":" Usage $ lexicmap utils seed-pos -h Extract and plot seed positions via reference name(s) Attention: 0. This command requires the index to be created with the flag --save-seed-pos in lexicmap index. 1. Seed/K-mer positions (column pos) are 1-based. For reference genomes with multiple sequences, the sequences were concatenated to a single sequence with intervals of N\u0026#39;s. So values of column pos_gnm and pos_seq might be different. The positions can be used to extract subsequence with \u0026#39;lexicmap utils subseq\u0026#39;. 2. All degenerate bases in reference genomes were converted to the lexicographic first bases. E.g., N was converted to A. Therefore, consecutive A\u0026#39;s in output might be N\u0026#39;s in the genomes. Extra columns: Using -v/--verbose will output more columns: len_aaa, length of consecutive A\u0026#39;s. seq, sequence between the previous and current seed. Figures: Using -O/--plot-dir will write plots into given directory: - Histograms of seed distances. - Histograms of numbers of seeds in sliding windows. Usage: lexicmap utils seed-pos [flags] Flags: -a, --all-refs ► Output for all reference genomes. This would take a long time for an index with a lot of genomes. -b, --bins int ► Number of bins in histograms. (default 100) --color-index int ► Color index (1-7). (default 1) --force ► Overwrite existing output directory. --height float ► Histogram height (unit: inch). (default 4) -h, --help help for seed-pos -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. --max-open-files int ► Maximum opened files, used for extracting sequences. (default 512) -D, --min-dist int ► Only output records with seed distance \u0026gt;= this value. -o, --out-file string ► Out file, supports and recommends a \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) -O, --plot-dir string ► Output directory for 1) histograms of seed distances, 2) histograms of numbers of seeds in sliding windows. --plot-ext string ► Histogram plot file extention. (default \u0026#34;.png\u0026#34;) -n, --ref-name strings ► Reference name(s). -s, --slid-step int ► The step size of sliding windows for counting the number of seeds (default 200) -w, --slid-window int ► The window size of sliding windows for counting the number of seeds (default 500) -v, --verbose ► Show more columns including position of the previous seed and sequence between the two seeds. Warning: it\u0026#39;s slow to extract the sequences, recommend set -D 1000 or higher values to filter results --width float ► Histogram width (unit: inch). (default 6) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples Adding the flag --save-seed-pos in index building.\n$ lexicmap index -I refs/ -O demo.lmi --save-seed-pos --force Listing seed position of one genome.\n$ lexicmap utils seed-pos -d demo.lmi/ -n GCF_000017205.1 -o seed_distance.tsv $ head -n 10 seed_distance.tsv | csvtk pretty -t ref seqid pos_gnm pos_seq strand distance --------------- ----------- ------- ------- ------ -------- GCF_000017205.1 NC_009656.1 90 90 - 89 GCF_000017205.1 NC_009656.1 122 122 - 32 GCF_000017205.1 NC_009656.1 160 160 - 38 GCF_000017205.1 NC_009656.1 209 209 - 49 GCF_000017205.1 NC_009656.1 259 259 - 50 GCF_000017205.1 NC_009656.1 309 309 + 50 GCF_000017205.1 NC_009656.1 357 357 + 48 GCF_000017205.1 NC_009656.1 360 360 + 3 GCF_000017205.1 NC_009656.1 387 387 - 27 Check the biggest seed distances.\n$ csvtk freq -t -f distance seed_distance.tsv \\ | csvtk sort -t -k distance:nr \\ | head -n 10 \\ | csvtk pretty -t distance frequency -------- --------- 126 1 99 32 98 36 97 40 96 36 95 40 94 37 93 48 92 62 Or only list records with seed distances longer than a threshold.\n$ lexicmap utils seed-pos -d demo.lmi/ -n GCF_000017205.1 -D 100 \\ | csvtk pretty -t | head -n 5 ref seqid pos_gnm pos_seq strand distance --------------- ----------- ------- ------- ------ -------- GCF_000017205.1 NC_009656.1 168652 168652 + 126 Plot histogram of distances between seeds and histogram of number of seeds in sliding windows.\n$ lexicmap utils seed-pos -d demo.lmi/ -n GCF_000017205.1 -o seed_distance.tsv --plot-dir seed_distance -w 250 In the plot below, there\u0026rsquo;s a peak at 50 bp, because LexicMap fills sketching deserts with extra k-mers (seeds) of which their distance is 50 bp by default.\nMore columns including sequences between two seeds.\n$ lexicmap utils seed-pos -d demo.lmi/ -n GCF_000017205.1 -v \\ | head -n4 | csvtk pretty -t -W 40 --clip ref seqid pos_gnm pos_seq strand distance len_aaa seq --------------- ----------- ------- ------- ------ -------- ------- ---------------------------------------- GCF_000017205.1 NC_009656.1 90 90 - 89 9 TTAAAGAGACCGGCGATTCTAGTGAAATCGAACGGGC... GCF_000017205.1 NC_009656.1 122 122 - 32 3 TTTCTTTTAAAGGATAGAAGCGGTTATTGCTC GCF_000017205.1 NC_009656.1 160 160 - 38 3 TTGGTTGGACCGGTTTCTGTGTATAACTCATTGAAAGC Or only list records with seed distance longer than a threshold.\n$ lexicmap utils seed-pos -d demo.lmi/ -n GCF_000017205.1 -v -D 100 \\ | csvtk pretty -t -W 40 ref seqid pos_gnm pos_seq strand distance len_aaa seq --------------- ----------- ------- ------- ------ -------- ------- ---------------------------------------- GCF_000017205.1 NC_009656.1 168652 168652 + 126 0 GGCGGCGTCGGCGGCGCCACGCTCGCTGGCTGTGGCTGTG GCTGTGGCTGTGGCTGTGGCTGTGGCTGTGGCTGTGGCTG TGGCTGTGGCTGTGGCTGTGGCTGTGGCGGCTGCTGGGTG ATCCCG It appears to be a highly repetitive region, specifically a tandem repeat with the unit sequence CTGTGG:\n$ lexicmap utils seed-pos -d demo.lmi/ -n GCF_000017205.1 -v -D 100 \\ | csvtk cut -t -f seqid,seq \\ | csvtk del-header -t \\ | seqkit tab2fx \\ | seqkit locate --only-positive-strand --non-greedy --pattern CTGTGG \\ | csvtk pretty seqID patternName pattern strand start end matched ----------- ----------- ------- ------ ----- --- ------- NC_009656.1 CTGTGG CTGTGG + 30 35 CTGTGG NC_009656.1 CTGTGG CTGTGG + 36 41 CTGTGG NC_009656.1 CTGTGG CTGTGG + 42 47 CTGTGG NC_009656.1 CTGTGG CTGTGG + 48 53 CTGTGG NC_009656.1 CTGTGG CTGTGG + 54 59 CTGTGG NC_009656.1 CTGTGG CTGTGG + 60 65 CTGTGG NC_009656.1 CTGTGG CTGTGG + 66 71 CTGTGG NC_009656.1 CTGTGG CTGTGG + 72 77 CTGTGG NC_009656.1 CTGTGG CTGTGG + 78 83 CTGTGG NC_009656.1 CTGTGG CTGTGG + 84 89 CTGTGG NC_009656.1 CTGTGG CTGTGG + 90 95 CTGTGG NC_009656.1 CTGTGG CTGTGG + 96 101 CTGTGG NC_009656.1 CTGTGG CTGTGG + 102 107 CTGTGG A similar case in another genome.\n$ lexicmap utils seed-pos -d demo.lmi/ -n GCF_000017205.1 -v -D 100 \\ | csvtk pretty -t -W 40 ref seqid pos_gnm pos_seq strand distance len_aaa seq --------------- ------------- ------- ------- ------ -------- ------- ---------------------------------------- GCF_003697165.2 NZ_CP033092.2 1563265 1563265 - 202 29 TAAGACTCAAGACTCAAGACTCAAGACTCAAGACTCAAGA CTCAAGACTCAAGACTCAAGACTCAAGACTCAAGACTCAA GACTCAAGACTCAAGACTCAAGACTCAAGACTCAAGACTC AAGACTCAAGACTCAAGACTCAAGACTCAAGACTCAAGAC TCAAGACTCAAGACTCAAGACTCAAGACTCAAGACTCAAG AC Listing seed position of all genomes.\n$ lexicmap utils seed-pos -d demo.lmi/ --all-refs -o seed-pos.tsv.gz Show the number of seed positions in each genome.\n$ csvtk freq -t -f ref -nr seed-pos.tsv.gz | csvtk pretty -t ref frequency --------------- --------- GCF_000017205.1 143165 GCF_000742135.1 120758 GCF_003697165.2 110132 GCF_000006945.2 108387 GCF_002950215.1 108272 GCF_002949675.1 101098 GCF_009759685.1 88632 GCF_000392875.1 65403 GCF_001027105.1 64176 GCF_001544255.1 57167 GCF_006742205.1 57086 GCF_001096185.1 49482 GCF_900638025.1 48959 GCF_001457655.1 45771 GCF_000148585.2 44752 Plot the histograms of distances between seeds for all genomes.\n$ lexicmap utils seed-pos -d demo.lmi/ --all-refs -o seed-pos.tsv.gz \\ --plot-dir seed_distance --force 09:56:34.059 [INFO] creating genome reader pools, each batch with 1 readers... processed files: 15 / 15 [======================================] ETA: 0s. done 09:56:34.656 [INFO] seed positions of 15 genomes(s) saved to seed-pos.tsv.gz 09:56:34.656 [INFO] histograms of 15 genomes(s) saved to seed_distance 09:56:34.656 [INFO] 09:56:34.656 [INFO] elapsed time: 598.080462ms 09:56:34.656 [INFO] $ ls seed_distance/ GCF_000006945.2.png GCF_000742135.1.png GCF_001544255.1.png GCF_006742205.1.png GCF_000006945.2.seed_number.png GCF_000742135.1.seed_number.png GCF_001544255.1.seed_number.png GCF_006742205.1.seed_number.png GCF_000017205.1.png GCF_001027105.1.png GCF_002949675.1.png GCF_009759685.1.png GCF_000017205.1.seed_number.png GCF_001027105.1.seed_number.png GCF_002949675.1.seed_number.png GCF_009759685.1.seed_number.png GCF_000148585.2.png GCF_001096185.1.png GCF_002950215.1.png GCF_900638025.1.png GCF_000148585.2.seed_number.png GCF_001096185.1.seed_number.png GCF_002950215.1.seed_number.png GCF_900638025.1.seed_number.png GCF_000392875.1.png GCF_001457655.1.png GCF_003697165.2.png GCF_000392875.1.seed_number.png GCF_001457655.1.seed_number.png GCF_003697165.2.seed_number.png In the plots below, there\u0026rsquo;s a peak at 50 bp, because LexicMap fills sketching deserts with extra k-mers (seeds) of which their distance is 50 bp by default. And they show that the seed number, seed distance and seed density are related to genome sizes.\nGCF_000392875.1 (genome size: 2.9 Mb)\n","description":" Usage $ lexicmap utils seed-pos -h Extract and plot seed positions via reference name(s) Attention: 0. This command requires the index to be created with the flag --save-seed-pos in lexicmap index. 1. Seed/K-mer positions (column pos) are 1-based. For reference genomes with multiple sequences, the sequences were concatenated to a single sequence with intervals of N\u0026#39;s. So values of column pos_gnm and pos_seq might be different. The positions can be used to extract subsequence with \u0026#39;lexicmap utils subseq\u0026#39;. 2. All degenerate bases in reference genomes were converted to the lexicographic first bases. E.g., N was converted to A. Therefore, consecutive A\u0026#39;s in output might be N\u0026#39;s in the genomes. Extra columns: Using -v/--verbose will output more columns: len_aaa, length of consecutive A\u0026#39;s. seq, sequence between the previous and current seed. Figures: Using -O/--plot-dir will write plots into given directory: - Histograms of seed distances. - Histograms of numbers of seeds in sliding windows. Usage: lexicmap utils seed-pos [flags] Flags: -a, --all-refs ► Output for all reference genomes. This would take a long time for an index with a lot of genomes. -b, --bins int ► Number of bins in histograms. (default 100) --color-index int ► Color index (1-7). (default 1) --force ► Overwrite existing output directory. --height float ► Histogram height (unit: inch). (default 4) -h, --help help for seed-pos -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. --max-open-files int ► Maximum opened files, used for extracting sequences. (default 512) -D, --min-dist int ► Only output records with seed distance \u0026gt;= this value. -o, --out-file string ► Out file, supports and recommends a \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) -O, --plot-dir string ► Output directory for 1) histograms of seed distances, 2) histograms of numbers of seeds in sliding windows. --plot-ext string ► Histogram plot file extention. (default \u0026#34;.png\u0026#34;) -n, --ref-name strings ► Reference name(s). -s, --slid-step int ► The step size of sliding windows for counting the number of seeds (default 200) -w, --slid-window int ► The window size of sliding windows for counting the number of seeds (default 500) -v, --verbose ► Show more columns including position of the previous seed and sequence between the two seeds. Warning: it\u0026#39;s slow to extract the sequences, recommend set -D 1000 or higher values to filter results --width float ► Histogram width (unit: inch). (default 6) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples Adding the flag --save-seed-pos in index building.\n"},{"id":16,"href":"/LexicMap/tutorials/misc/","title":"More","parent":"Tutorials","content":"","description":""},{"id":17,"href":"/LexicMap/tutorials/","title":"Tutorials","parent":"","content":"","description":""},{"id":18,"href":"/LexicMap/usage/utils/","title":"utils","parent":"Usage","content":"$ lexicmap utils Some utilities Usage: lexicmap utils [command] Available Commands: 2blast Convert the default search output to blast-style format genomes View genome IDs in the index kmers View k-mers captured by the masks masks View masks of the index or generate new masks randomly reindex-seeds Recreate indexes of k-mer-value (seeds) data remerge Rerun the merging step for an unfinished index seed-pos Extract and plot seed positions via reference name(s) subseq Extract subsequence via reference name, sequence ID, position and strand Flags: -h, --help help for utils Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Subcommands:\n2blast masks kmers genomes subseq seed-pos reindex-seeds remerge ","description":"$ lexicmap utils Some utilities Usage: lexicmap utils [command] Available Commands: 2blast Convert the default search output to blast-style format genomes View genome IDs in the index kmers View k-mers captured by the masks masks View masks of the index or generate new masks randomly reindex-seeds Recreate indexes of k-mer-value (seeds) data remerge Rerun the merging step for an unfinished index seed-pos Extract and plot seed positions via reference name(s) subseq Extract subsequence via reference name, sequence ID, position and strand Flags: -h, --help help for utils Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Subcommands:\n"},{"id":19,"href":"/LexicMap/usage/utils/reindex-seeds/","title":"reindex-seeds","parent":"utils","content":" Usage $ lexicmap utils reindex-seeds -h Recreate indexes of k-mer-value (seeds) data Usage: lexicmap utils reindex-seeds [flags] Flags: -h, --help help for reindex-seeds -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. --partitions int ► Number of partitions for re-indexing seeds (k-mer-value data) files. The value needs to be the power of 4. (default 4096) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples $ lexicmap utils reindex-seeds -d demo.lmi/ --partitions 1024 10:20:29.150 [INFO] recreating seed indexes with 1024 partitions for: demo.lmi/ processed files: 16 / 16 [======================================] ETA: 0s. done 10:20:29.166 [INFO] update index information file: demo.lmi/info.toml 10:20:29.166 [INFO] finished updating the index information file: demo.lmi/info.toml 10:20:29.166 [INFO] 10:20:29.166 [INFO] elapsed time: 15.981266ms 10:20:29.166 [INFO] ","description":" Usage $ lexicmap utils reindex-seeds -h Recreate indexes of k-mer-value (seeds) data Usage: lexicmap utils reindex-seeds [flags] Flags: -h, --help help for reindex-seeds -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. --partitions int ► Number of partitions for re-indexing seeds (k-mer-value data) files. The value needs to be the power of 4. (default 4096) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples $ lexicmap utils reindex-seeds -d demo.lmi/ --partitions 1024 10:20:29.150 [INFO] recreating seed indexes with 1024 partitions for: demo.lmi/ processed files: 16 / 16 [======================================] ETA: 0s. done 10:20:29.166 [INFO] update index information file: demo.lmi/info.toml 10:20:29.166 [INFO] finished updating the index information file: demo.lmi/info.toml 10:20:29.166 [INFO] 10:20:29.166 [INFO] elapsed time: 15.981266ms 10:20:29.166 [INFO] "},{"id":20,"href":"/LexicMap/usage/","title":"Usage","parent":"","content":"","description":""},{"id":21,"href":"/LexicMap/faqs/","title":"FAQs","parent":"","content":" Table of contents Table of contents Does LexicMap support short reads? Does LexicMap support fungi genomes? How\u0026rsquo;s the hardware requirement? How to resume the indexing as Slurm job time limit is almost reached while lexicmap index is still in the merging step? Can I extract the matched sequences? How can I extract the upstream and downstream flanking sequences of matched regions? Why isn\u0026rsquo;t the pident 100% when aligning with a sequence from the reference genomes? Why is LexicMap slow for batch searching? Does LexicMap support short reads? LexicMap is mainly designed for sequence alignment with a small number of queries (gene/plasmid/virus/phage sequences) longer than 100 bp by default.\nIf you just want to search long (\u0026gt;1kb) queries for highly similar (\u0026gt;95%) targets, you can build an index with a bigger -D/--seed-max-desert (default 100) and -d/--seed-in-desert-dist (default 50), e.g.,\n--seed-max-desert 300 --seed-in-desert-dist 150 Bigger values decrease the search sensitivity for distant targets, speed up the indexing speed, decrease the indexing memory occupation and decrease the index size. While the alignment speed is almost not affected.\nDoes LexicMap support fungi genomes? Yes. LexicMap mainly supports small genomes including prokaryotic, viral, and plasmid genomes. Fungi can also be supported, just remember to increase the value of -g/--max-genome when running lexicmap index, which is used to skip genomes larger than 15Mb by default.\n-g, --max-genome int ► Maximum genome size. Extremely large genomes (e.g., non-isolate assemblies from Genbank) will be skipped. (default 15000000) Maximum genome size is about 268 Mb (268,435,456). More precisely:\n$total_bases + ($num_contigs - 1) * 1000 \u0026lt;= 268,435,456 as we concatenate contigs with 1000-bp intervals of N’s to reduce the sequence scale to index.\nFor big and complex genomes, like the human genome (chr1 is ~248 Mb) which has many repetitive sequences, LexicMap would be slow to align.\nHow\u0026rsquo;s the hardware requirement? For index building. See details hardware requirement. For seaching. See details hardware requirement. How to resume the indexing as Slurm job time limit is almost reached while lexicmap index is still in the merging step? Use lexicmap utils remerge (available since v0.5.0), which reruns the merging step for an unfinished index.\nWhen to use this command?\nOnly one thread is used for merging indexes, which happens when there are a lot (\u0026gt;200 batches) of batches ($inpu_files / --batch-size) and the value of --max-open-files is not big enough. The Slurm/PBS job time limit is almost reached and the merging step won\u0026rsquo;t be finished before that. Disk quota is reached in the merging step. So you can stop the indexing command by press Ctrl + C (make sure it is in the merging step, see example below), and run lexicmap utils remerge -d index.lmi, where index.lmi is the output index directory in lexicmap index.\nOptionally, you might set bigger values of flag --max-open-files and -J/--seed-data-threads if you have hundreds of thousands of input genomes or have set a small batch size with -b/--batch-size. E.g.,\n22:54:24.420 [INFO] merging 297 indexes... 22:54:24.455 [INFO] [round 1] 22:54:24.455 [INFO] batch 1/1, merging 297 indexes to xxx.lmi.tmp/r1_b1 with 1 threads... There\u0026rsquo;s only one thread was used for seed data merging, it would take a long time. So we can set a larger --max-open-files, e.g., 4096, and it would allow 4096 / (297+2) = 13.7 threads for merging, let\u0026rsquo;s set --seed-data-threads 12.\n# specify the maximum open files per process ulimit -n 4096 lexicmap utils remerge -d index.lmi --max-open-files 4096 --seed-data-threads 12 Can I extract the matched sequences? Yes, lexicmap search has a flag\n-a, --all ► Output more columns, e.g., matched sequences. Use this if you want to output blast-style format with \u0026#34;lexicmap utils 2blast\u0026#34;. to output CIGAR string, aligned query and subject sequences.\n21. cigar, CIGAR string of the alignment. (optional with -a/--all) 22. qseq, Aligned part of query sequence. (optional with -a/--all) 23. sseq, Aligned part of subject sequence. (optional with -a/--all) 24. align, Alignment text (\u0026quot;|\u0026quot; and \u0026quot; \u0026quot;) between qseq and sseq. (optional with -a/--all) An example:\n# Extracting similar sequences for a query gene. # search matches with query coverage \u0026gt;= 90% lexicmap search -d gtdb_complete.lmi/ b.gene_E_faecalis_SecY.fasta -o results.tsv \\ --min-qcov-per-hsp 90 --all # extract matched sequences as FASTA format sed 1d results.tsv | awk -F'\\t' '{print \u0026quot;\u0026gt;\u0026quot;$5\u0026quot;:\u0026quot;$15\u0026quot;-\u0026quot;$16\u0026quot;:\u0026quot;$17\u0026quot;\\n\u0026quot;$23;}' \\ | seqkit seq -g \u0026gt; results.fasta seqkit head -n 1 results.fasta | head -n 3 \u0026gt;NZ_JALSCK010000007.1:39224-40522:- TTGTTCAAGCTATTAAAGAACGCCTTTAAAGTCAAAGACATTAGATCAAAAATCTTATTT ACAGTTTTAATCTTGTTTGTATTTCGCCTAGGTGCGCACATTACTGTGCCCGGGGTGAAT And lexicmap util 2blast can help to convert the tabular format to Blast-style format, see examples.\nHow can I extract the upstream and downstream flanking sequences of matched regions? lexicmap utils subseq can extract subsequencess via genome ID, sequence ID and positions. So you can use these information from the search result and expand the region positions to extract flanking sequences.\nWhy isn\u0026rsquo;t the pident 100% when aligning with a sequence from the reference genomes? It happens if there are some degenerate bases (e.g., N) in the query sequence. In the indexing step, all degenerate bases are converted to their lexicographic first bases. E.g., N is converted to A. While for the query sequences, we don\u0026rsquo;t convert them.\nWhy is LexicMap slow for batch searching? LexicMap is mainly designed for sequence alignment with a small number of queries against a database with a huge number (up to 17 million) of genomes.\nThere are some ways to improve the search speed of lexicmap search: http://bioinf.shenwei.me/LexicMap/tutorials/search/#improving-searching-speed\nClick to read more detail of the usage.\n","description":" Table of contents Table of contents Does LexicMap support short reads? Does LexicMap support fungi genomes? How\u0026rsquo;s the hardware requirement? How to resume the indexing as Slurm job time limit is almost reached while lexicmap index is still in the merging step? Can I extract the matched sequences? How can I extract the upstream and downstream flanking sequences of matched regions? Why isn\u0026rsquo;t the pident 100% when aligning with a sequence from the reference genomes? Why is LexicMap slow for batch searching? Does LexicMap support short reads? LexicMap is mainly designed for sequence alignment with a small number of queries (gene/plasmid/virus/phage sequences) longer than 100 bp by default.\n"},{"id":22,"href":"/LexicMap/usage/utils/remerge/","title":"remerge","parent":"utils","content":"$ lexicmap utils remerge -h Rerun the merging step for an unfinished index When to use this command? - Only one thread is used for merging indexes, which happens when there are a lot (\u0026gt;200 batches) of batches ($inpu_files / --batch-size) and the value of --max-open-files is not big enough. E.g., 22:54:24.420 [INFO] merging 297 indexes... 22:54:24.455 [INFO] [round 1] 22:54:24.455 [INFO] batch 1/1, merging 297 indexes to xxx.lmi.tmp/r1_b1 with 1 threads... ► Then you can run this command with a bigger --max-open-files (e.g., 4096) and -J/--seed-data-threads (e.g., 12. 12 needs be \u0026lt;= 4096/(297+2)=13.7). And you need to set a bigger \u0026#39;ulimit -n\u0026#39; if the value of --max-open-files is bigger than 1024. - The Slurm/PBS job time limit is almost reached and the merging step won\u0026#39;t be finished before that. - Disk quota is reached in the merging step. Usage: lexicmap utils remerge [flags] [flags] -d \u0026lt;index path\u0026gt; Flags: -h, --help help for remerge -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. --max-open-files int ► Maximum opened files, used in merging indexes. If there are \u0026gt;100 batches, please increase this value and set a bigger \u0026#34;ulimit -n\u0026#34; in shell. (default 1024) -J, --seed-data-threads int ► Number of threads for writing seed data and merging seed chunks from all batches, the value should be in range of [1, -c/--chunks]. If there are \u0026gt;100 batches, please also increase the value of --max-open-files and set a bigger \u0026#34;ulimit -n\u0026#34; in shell. (default 8) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) ","description":"$ lexicmap utils remerge -h Rerun the merging step for an unfinished index When to use this command? - Only one thread is used for merging indexes, which happens when there are a lot (\u0026gt;200 batches) of batches ($inpu_files / --batch-size) and the value of --max-open-files is not big enough. E.g., 22:54:24.420 [INFO] merging 297 indexes... 22:54:24.455 [INFO] [round 1] 22:54:24.455 [INFO] batch 1/1, merging 297 indexes to xxx.lmi.tmp/r1_b1 with 1 threads... ► Then you can run this command with a bigger --max-open-files (e.g., 4096) and -J/--seed-data-threads (e.g., 12. 12 needs be \u0026lt;= 4096/(297+2)=13.7). And you need to set a bigger \u0026#39;ulimit -n\u0026#39; if the value of --max-open-files is bigger than 1024. - The Slurm/PBS job time limit is almost reached and the merging step won\u0026#39;t be finished before that. - Disk quota is reached in the merging step. Usage: lexicmap utils remerge [flags] [flags] -d \u0026lt;index path\u0026gt; Flags: -h, --help help for remerge -d, --index string ► Index directory created by \u0026#34;lexicmap index\u0026#34;. --max-open-files int ► Maximum opened files, used in merging indexes. If there are \u0026gt;100 batches, please increase this value and set a bigger \u0026#34;ulimit -n\u0026#34; in shell. (default 1024) -J, --seed-data-threads int ► Number of threads for writing seed data and merging seed chunks from all batches, the value should be in range of [1, -c/--chunks]. If there are \u0026gt;100 batches, please also increase the value of --max-open-files and set a bigger \u0026#34;ulimit -n\u0026#34; in shell. (default 8) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) "},{"id":23,"href":"/LexicMap/notes/","title":"Notes","parent":"","content":"","description":""},{"id":24,"href":"/LexicMap/","title":"","parent":"","content":" LexicMap LexicMap is a nucleotide sequence alignment tool for efficiently querying gene, plasmid, virus, or long-read sequences (\u0026gt;100 bp) against up to millions of prokaryotic genomes.\nIntroduction Feature overview Easy to install Linux, Windows, MacOS and more OS are supported.\nBoth x86 and ARM CPUs are supported.\nJust download the binary files and run!\nOr install it by\nconda install -c bioconda lexicmap Installation Releases Easy to use Step 1: indexing\nlexicmap index -I genomes/ -O db.lmi Step 2: searching\nlexicmap search -d db.lmi q.fasta -o r.tsv Tutorials Usages FAQs Accurate and efficient alignment Using LexicMap to align in the whole 2,340,672 Genbank+Refseq prokaryotic genomes with 48 CPUs.\nQuery Genome hits Time RAM(GB) A 1.3-kb gene 41,718 3m:06s 3.97 A 1.5-kb 16S rRNA 1,955,167 32m:59s 11.09 A 52.8-kb plasmid 560,330 52m:22s 14.48 1003 AMR genes 30,967,882 15h:52m 24.86 Blastn is unable to run with the same dataset on common servers as it requires \u0026gt;2000 GB RAM.\n","description":" LexicMap LexicMap is a nucleotide sequence alignment tool for efficiently querying gene, plasmid, virus, or long-read sequences (\u0026gt;100 bp) against up to millions of prokaryotic genomes.\nIntroduction Feature overview Easy to install Linux, Windows, MacOS and more OS are supported.\n"},{"id":25,"href":"/LexicMap/usage/utils/2blast/","title":"2blast","parent":"utils","content":" Usage $ lexicmap utils 2blast -h Convert the default search output to blast-style format LexicMap only stores genome IDs and sequence IDs, without description information. But the option -g/--kv-file-genome enables adding description data after the genome ID with a tabular key-value mapping file. Input: - Output of \u0026#39;lexicmap search\u0026#39; with the flag -a/--all. Usage: lexicmap utils 2blast [flags] Flags: -b, --buffer-size string ► Size of buffer, supported unit: K, M, G. You need increase the value when \u0026#34;bufio.Scanner: token too long\u0026#34; error reported (default \u0026#34;20M\u0026#34;) -h, --help help for 2blast -i, --ignore-case ► Ignore cases of sgenome and sseqid -g, --kv-file-genome string ► Two-column tabular file for mapping the target genome ID (sgenome) to the corresponding value -s, --kv-file-seq string ► Two-column tabular file for mapping the target sequence ID (sseqid) to the corresponding value -o, --out-file string ► Out file, supports and recommends a \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples From stdin.\n$ seqkit seq -M 500 q.long-reads.fasta.gz \\ | seqkit head -n 2 \\ | lexicmap search -d demo.lmi/ -a \\ | lexicmap utils 2blast --kv-file-genome ass2species.map Query = GCF_000017205.1_r160 Length = 478 [Subject genome #1/1] = GCF_000017205.1 Pseudomonas aeruginosa Query coverage per genome = 98.536% \u0026gt;NC_009656.1 Length = 6588339 HSP cluster #1, HSP #1 Score = 883 bits, Expect = 3.60e-256 Query coverage per seq = 98.536%, Aligned length = 479, Identities = 94.990%, Gaps = 15 Query range = 7-477, Subject range = 4866857-4867328, Strand = Plus/Plus Query 7 GGTGGCCCTCAAACGAGTCC-AACAGGCCAACGCCTAGCAATCCCTCCCCTGTGGGGCAG 65 ||||||| |||||||||||| |||||||| |||||| | ||||||||||||| |||||| Sbjct 4866857 GGTGGCC-TCAAACGAGTCCGAACAGGCCCACGCCTCACGATCCCTCCCCTGTCGGGCAG 4866915 Query 66 GGAAAATCGTCCTTTATGGTCCGTTCCGGGCACGCACCGGAACGGCGGTCATCTTCCACG 125 |||||||||||||||||||||||||||||||||||||||||||||||||||| ||||||| Sbjct 4866916 GGAAAATCGTCCTTTATGGTCCGTTCCGGGCACGCACCGGAACGGCGGTCAT-TTCCACG 4866974 Query 126 GTGCCCGCCCACGGCGGACCCGCGGAAACCGACCCGGGCGCCAAGGCGCCCGGGAACGGA 185 ||||||||| ||||||||||| |||||||||||||||||||||||||||||||||||||| Sbjct 4866975 GTGCCCGCC-ACGGCGGACCC-CGGAAACCGACCCGGGCGCCAAGGCGCCCGGGAACGGA 4867032 Query 186 GTA-CACTCGGCGTTCGGCCAGCGACAGC---GACGCGTTGCCGCCCACCGCGGTGGTGT 241 ||| |||||||||| |||||||||||||| |||||||||||||||||||||||||||| Sbjct 4867033 GTATCACTCGGCGT-CGGCCAGCGACAGCAGCGACGCGTTGCCGCCCACCGCGGTGGTGT 4867091 Query 242 TCACCGAGGTGGTGCGCTCGCTGAC-AAACGCAGCAGGTAGTTCGGCCCGCCGGCCTTGG 300 ||||||||||||||||||||||||| |||||||||||||||||||||||||||||||||| Sbjct 4867092 TCACCGAGGTGGTGCGCTCGCTGACGAAACGCAGCAGGTAGTTCGGCCCGCCGGCCTTGG 4867151 Query 301 GACCG-TGCCGGACAGCCCGTGGCCGCCGAACAGTTGCACGCCCACCACCGCGCCGAT-T 358 ||||| |||||||||||||||||||||||||| ||||||||||||||||||||||||| | Sbjct 4867152 GACCGGTGCCGGACAGCCCGTGGCCGCCGAACGGTTGCACGCCCACCACCGCGCCGATCT 4867211 Query 359 GGTTTCGGTTGACGTAGAGGTTGCCGACCCGCGCCAGCTCTTGGATGCGGCGGGCGGTTT 418 |||| ||||||||||||||||||||||||||||||||||||| ||||||||||||||||| Sbjct 4867212 GGTTGCGGTTGACGTAGAGGTTGCCGACCCGCGCCAGCTCTTCGATGCGGCGGGCGGTTT 4867271 Query 419 CCTCGTTGCGGCTGTGGACCCCCATGGTCAGGCCGAAACCGGTGGCGTTTGATGGCCCT 477 ||||||||||||||||||||||||||||||||||||||||||||||||| ||| ||| | Sbjct 4867272 CCTCGTTGCGGCTGTGGACCCCCATGGTCAGGCCGAAACCGGTGGCGTT-GATCGCC-T 4867328 Query = GCF_006742205.1_r100 Length = 431 [Subject genome #1/1] = GCF_006742205.1 Staphylococcus epidermidis Query coverage per genome = 93.968% \u0026gt;NZ_AP019721.1 Length = 2422602 HSP cluster #1, HSP #1 Score = 740 bits, Expect = 2.39e-213 Query coverage per seq = 93.968%, Aligned length = 408, Identities = 98.284%, Gaps = 4 Query range = 27-431, Subject range = 1321677-1322083, Strand = Plus/Minus Query 27 TTCATTTAAAACGATTGCTAATGAGTCACGTATTTCATCTGGTTCGGTAACTATACCGTC 86 ||||| |||||||||||||||||||||||||||||||||||||||||||||||||||||| Sbjct 1322083 TTCATCTAAAACGATTGCTAATGAGTCACGTATTTCATCTGGTTCGGTAACTATACCGTC 1322024 Query 87 TACTATGGACTCAGTGTAACCCTGTAATAAAGAGATTGGCGTACGTAATTCATGTG-TAC 145 |||||||||||||||||||||||||||||||||||||||||||||||||||||||| ||| Sbjct 1322023 TACTATGGACTCAGTGTAACCCTGTAATAAAGAGATTGGCGTACGTAATTCATGTGATAC 1321964 Query 146 ATTTGCTATAAAATCTTTTTTCATTTGATCAAGATTATGTTCATTTGTCATATCACAGGA 205 |||||||||||||||||||||||||||||||||||||||||||||||||||||||| ||| Sbjct 1321963 ATTTGCTATAAAATCTTTTTTCATTTGATCAAGATTATGTTCATTTGTCATATCAC-GGA 1321905 Query 206 TGACCATGACAATACCACTTCTACCATTTGTTTGAATTCTATCTATATAACTGGAGATAA 265 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| Sbjct 1321904 TGACCATGACAATACCACTTCTACCATTTGTTTGAATTCTATCTATATAACTGGAGATAA 1321845 Query 266 ATACATAGTACCTTGTATTAATTTCTAATTCTAA-TACTCATTCTGTTGTGATTCAAATG 324 |||||||||||||||||||||||||||||||||| ||||||||||||||||||||||||| Sbjct 1321844 ATACATAGTACCTTGTATTAATTTCTAATTCTAAATACTCATTCTGTTGTGATTCAAATG 1321785 Query 325 GTGCTTCAATTTGCTGTTCAATAGATTCTTTTGAAAAATCATCAATGTGACGCATAATAT 384 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| Sbjct 1321784 TTGCTTCAATTTGCTGTTCAATAGATTCTTTTGAAAAATCATCAATGTGACGCATAATAT 1321725 Query 385 AATCAGCCATCTTGTT-GACAATATGATTTCACGTTGATTATTAATGC 431 ||||||||||||||| ||||||||||||||||||||||||||||||| Sbjct 1321724 CATCAGCCATCTTGTTTGACAATATGATTTCACGTTGATTATTAATGC 1321677 From file.\n$ lexicmap utils 2blast r.lexicmap.tsv -o r.lexicmap.txt ","description":" Usage $ lexicmap utils 2blast -h Convert the default search output to blast-style format LexicMap only stores genome IDs and sequence IDs, without description information. But the option -g/--kv-file-genome enables adding description data after the genome ID with a tabular key-value mapping file. Input: - Output of \u0026#39;lexicmap search\u0026#39; with the flag -a/--all. Usage: lexicmap utils 2blast [flags] Flags: -b, --buffer-size string ► Size of buffer, supported unit: K, M, G. You need increase the value when \u0026#34;bufio.Scanner: token too long\u0026#34; error reported (default \u0026#34;20M\u0026#34;) -h, --help help for 2blast -i, --ignore-case ► Ignore cases of sgenome and sseqid -g, --kv-file-genome string ► Two-column tabular file for mapping the target genome ID (sgenome) to the corresponding value -s, --kv-file-seq string ► Two-column tabular file for mapping the target sequence ID (sseqid) to the corresponding value -o, --out-file string ► Out file, supports and recommends a \u0026#34;.gz\u0026#34; suffix (\u0026#34;-\u0026#34; for stdout). (default \u0026#34;-\u0026#34;) Global Flags: -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Examples From stdin.\n"},{"id":26,"href":"/LexicMap/usage/lexicmap/","title":"lexicmap","parent":"Usage","content":"$ lexicmap -h LexicMap: efficient sequence alignment against millions of prokaryotic genomes Version: v0.7.0 Documents: https://bioinf.shenwei.me/LexicMap Source code: https://github.com/shenwei356/LexicMap Usage: lexicmap [command] Available Commands: autocompletion Generate shell autocompletion scripts index Generate an index from FASTA/Q sequences search Search sequences against an index utils Some utilities version Print version information and check for update Flags: -h, --help help for lexicmap -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Use \u0026#34;lexicmap [command] --help\u0026#34; for more information about a command. ","description":"$ lexicmap -h LexicMap: efficient sequence alignment against millions of prokaryotic genomes Version: v0.7.0 Documents: https://bioinf.shenwei.me/LexicMap Source code: https://github.com/shenwei356/LexicMap Usage: lexicmap [command] Available Commands: autocompletion Generate shell autocompletion scripts index Generate an index from FASTA/Q sequences search Search sequences against an index utils Some utilities version Print version information and check for update Flags: -h, --help help for lexicmap -X, --infile-list string ► File of input file list (one file per line). If given, they are appended to files from CLI arguments. --log string ► Log file. --quiet ► Do not print any verbose information. But you can write them to a file with --log. -j, --threads int ► Number of CPU cores to use. By default, it uses all available cores. (default 16) Use \u0026#34;lexicmap [command] --help\u0026#34; for more information about a command. "},{"id":27,"href":"/LexicMap/notes/motivation/","title":"Motivation","parent":"Notes","content":" BLASTN is not able to scale to millions of bacterial genomes, it\u0026rsquo;s slow and has a high memory occupation. For example, it requires \u0026gt;2000 GB for alignment a 2-kb gene sequence against all the 2.34 millions of prokaryotics genomes in Genbank and RefSeq.\nLarge-scale sequence searching tools only return which genomes a query matches (color), but they can\u0026rsquo;t return positional information.\n","description":" BLASTN is not able to scale to millions of bacterial genomes, it\u0026rsquo;s slow and has a high memory occupation. For example, it requires \u0026gt;2000 GB for alignment a 2-kb gene sequence against all the 2.34 millions of prokaryotics genomes in Genbank and RefSeq.\nLarge-scale sequence searching tools only return which genomes a query matches (color), but they can\u0026rsquo;t return positional information.\n"},{"id":28,"href":"/LexicMap/tutorials/index/","title":"Step 1. Building a database","parent":"Tutorials","content":" Note Terminology differences:\nOn this page and in the LexicMap command line options, the term \u0026ldquo;mask\u0026rdquo; is used, following the terminology in the LexicHash paper. In the LexicMap manuscript, however, we use \u0026ldquo;probe\u0026rdquo; as it is easier to understand. Because these masks, which consist of thousands of k-mers and capture k-mers from sequences through prefix matching, function similarly to DNA probes in molecular biology. Table of contents Table of contents TL;DR Input Hardware requirements Algorithm Parameters Notes for indexing with large datasets Steps Output File structure Index size Explore the index TL;DR Prepare input files: Sequences of each reference genome should be saved in separate FASTA files, with identifiers (no tab symbols) in the file names. E.g., GCF_000006945.2.fna.gz A regular expression is also available to extract reference id from the file name. E.g., --ref-name-regexp '^(\\w{3}_\\d{9}\\.\\d+)' extracts GCF_000006945.2 from GenBank assembly file GCF_000006945.2_ASM694v2_genomic.fna.gz While if you save a few small (viral) complete genomes (one sequence per genome) in each file, it\u0026rsquo;s feasible as sequence IDs in search result can help to distinguish target genomes. Run: From a directory with multiple genome files:\nlexicmap index -I genomes/ -O db.lmi From a file list with one file per line:\nlexicmap index --skip-file-check -X files.txt -O db.lmi Input Note Genome size\nLexicMap is mainly suitable for small genomes like Archaea, Bacteria, Viruses, fungi, and plasmids.\nMaximum genome size: 268 Mb (268,435,456). More precisely:\n$total_bases + ($num_contigs - 1) * 1000 \u0026lt;= 268,435,456 as we concatenate contigs with 1000-bp intervals of N’s to reduce the sequence scale to index.\nSequences of each reference genome should be saved in separate FASTA files, with identifiers in the file names. While if you save a few small (viral) complete genomes (one sequence per genome) in each file, it\u0026rsquo;s feasible as sequence IDs in search result can help to distinguish target genomes.\nFile type: FASTA/Q files, in plain text or gzip/xz/zstd/bzip2 compressed formats. File name: \u0026ldquo;Genome ID\u0026rdquo; + \u0026ldquo;File extention\u0026rdquo;. E.g., GCF_000006945.2.fna.gz. Genome ID: they must not contain tab (\u0026quot;\\t\u0026quot;) symbols, and should be distinct for accurate result interpretation, which will be shown in the search result. A regular expression is also available to extract reference id from the file name. E.g., --ref-name-regexp '^(\\w{3}_\\d{9}\\.\\d+)' extracts GCF_000006945.2 from GenBank assembly file GCF_000006945.2_ASM694v2_genomic.fna.gz File extention: a regular expression set by the flag -r/--file-regexp is used to match input files. The default value supports common sequence file extentions, e.g., .fa, .fasta, .fna, .fa.gz, .fasta.gz, .fna.gz, fasta.xz, fasta.zst, and fasta.bz2. Sequences: Only DNA or RNA sequences are supported. Sequence IDs should be distinct for accurate result interpretation, which will be shown in the search result. Sequence description (text behind sequence ID) is not saved. If you do need it, you can create a mapping file (seqkit seq -n ref.fa.gz | sed -E 's/\\s+/\\t/' \u0026gt; id2desc.tsv) and use it to add description in search result. One or more sequences (contigs) in each file are allowed. Unwanted sequences can be filtered out by regular expressions from the flag -B/--seq-name-filter. Genome size limit. Some none-isolate assemblies might have extremely large genomes, e.g., GCA_000765055.1 has \u0026gt;150 Mb. The flag -g/--max-genome (default 15 Mb) is used to skip these input files, and the file list would be written to a file via the flag -G/--big-genomes. Changes since v0.5.0: Genomes with any single contig larger than the threshold will be skipped as before. However, fragmented (with many contigs) genomes with the total bases larger than the threshold will be split into chunks and alignments from these chunks will be merged in lexicmap search. For fungi genomes, please increase the value of -g/--max-genome. Minimum sequence length. A flag -l/--min-seq-len can filter out sequences shorter than the threshold (default is the k value). At most 17,179,869,184 (234) genomes are supported. For more genomes, please create a file list and split it into multiple parts, and build an index for each part. Input files can be given via one of the following ways:\nPositional arguments. For a few input files. A file list via the flag -X/--infile-list with one file per line. It can be STDIN (-), e.g., you can filter a file list and pass it to lexicmap index. The flag -S/--skip-file-check is optional for skiping input file checking if you believe these files do exist. Because, by default, LexicMap checks the existence of all input files, which would take tens of minutes for \u0026gt;1M files. A directory containing input files via the flag -I/--in-dir. Multiple-level directories are supported. So you don\u0026rsquo;t need to saved hundreds of thousand files into one directoy. Directory and file symlinks are followed. Hardware requirements See benchmark of index building.\nLexicMap is designed to provide fast and low-memory sequence alignment against millions of prokaryotic genomes.\nCPU: No specific requirements on CPU type and instruction sets. Both x86 and ARM chips are supported. More is better as LexicMap is a CPU-intensive software. It uses all CPUs by default (-j/--threads). RAM More RAM (\u0026gt; 200 GB) is preferred. The memory usage in index building is mainly related to: The number of masks (-m/--masks, default 20,000). Bigger values improve the search sensitivity slightly, increase the index size, and slow down the search speed. For smaller genomes like phages/viruses, m=5,000 is high enough. The number of genomes. Generally, more genomes consume more memory, but we can control the genome batch size. The genome batch size (-b/--batch-size, default 5,000). This is the main parameter to adjust memory usage. Bigger values increase indexing memory occupation. The divergence between genome sequences in each batch. Diverse genomes consume more memory. The maximum seed distance or the maximum sketching desert size (-D/--seed-max-desert, default 100), and the distance of k-mers to fill deserts (-d/--seed-in-desert-dist, default 50). These are the main parameters to adjust search sensitivity. Bigger -D/--seed-max-desert values decrease the search sensitivity, speed up the indexing speed, decrease the indexing memory occupation and decrease the index size. While the alignment speed is almost not affected. If the RAM is not sufficient. Please: Use a smaller genome batch size. It decreases indexing memory occupation and has little affection on searching performance. Disk More is better. LexicMap index size is related to the number of input genomes, the divergence between genome sequences, the number of masks, and the maximum seed distance. See some examples. Note that the index size is not linear with the number of genomes, it\u0026rsquo;s sublinear. Because the seed data are compressed with VARINT-GB algorithm, more genomes bring smaller compression rates. SSD disks are preferred, while HDD disks are also fast enough. Algorithm Click to show details. ... Generating m LexicHash masks.\nGenerate m prefixes. Generating all permutations of p-bp prefixes that can cover all possible k-mers, p is the biggest value for 4p \u0026lt;= m (desired number of masks), e.g., p=7 for 20,000 masks. (47 = 16384) Duplicating these prefixes to m prefixes. For each prefix, Randomly generating left k-p bases. If the mask is duplicated, re-generating. Building an index for each genome batch (-b/--batch-size, default 5,000, max 131,072).\nFor each genome file in a genome batch. Optionally discarding sequences via regular expression (-B/--seq-name-filter). Skipping genomes bigger than the value of -g/--max-genome. Concatenating all sequences, with intervals of 1000-bp N\u0026rsquo;s. Capturing the most similar k-mer (in non-gap and non-interval regions) for each mask and recording the k-mer and its location(s) and strand information. Base N is treated as A. Filling sketching deserts (genome regions longer than --seed-max-desert [default 100] without any captured k-mers/seeds). In a sketching desert, not a single k-mer is captured because there\u0026rsquo;s another k-mer in another place which shares a longer prefix with the mask. As a result, for a query similar to seqs in this region, all captured k-mers can’t match the correct seeds. For a desert region (start, end), masking the extended region (start-1000, end+1000) with the masks. Starting from start, every around --seed-in-desert-dist (default 50) bp, finding a k-mer which is captured by some mask, and adding the k-mer and its position information into the index of that mask. Saving the concatenated genome sequence (bit-packed, 2 bits for one base, N is treated as A) and genome information (genome ID, size, and lengths of all sequences) into the genome data file, and creating an index file for the genome data file for fast random subsequence extraction. Duplicate and reverse all k-mers, and save each reversed k-mer along with the duplicated position information in the seed data of the closest (sharing the longgest prefix) mask. This is for suffix matching of seeds. Compressing k-mers and the corresponding data (k-mer-data, or seeds data, including genome batch, genome number, location, and strand) into chunks of files, and creating an index file for each k-mer-data file for fast seeding. Writing summary information into info.toml file. Merging indexes of multiple batches.\nFor each k-mer-data chunk file (belonging to a list of masks), serially reading data of each mask from all batches, merging them and writting to a new file. For genome data files, just moving them. Concatenating genomes.map.bin, which maps each genome ID to its batch ID and index in the batch. Update the index summary file. Parameters Note Query length\nLexicMap is mainly designed for sequence alignment with a small number of queries (gene/plasmid/virus/phage sequences) longer than 100 bp by default. However, short queries can also be aligned.\nIf you just want to search long (\u0026gt;1kb) queries for highly similar (\u0026gt;95%) targets, you can build an index with a bigger -D/--seed-max-desert (default 50) and -d/--seed-in-desert-dist (default 50), e.g.,\n--seed-max-desert 300 --seed-in-desert-dist 150 Bigger values decrease the search sensitivity for distant targets, speed up the indexing speed, decrease the indexing memory occupation and decrease the index size. While the alignment speed is almost not affected.\nFlags in bold text are important and frequently used.\nGeneral Flag Value Function Comment -j/--threads Default: all available CPUs Number of CPU cores to use. ► If the value is smaller than the number of available CPUs, make sure set the same value to -c/--chunks. Genome batches Flag Value Function Comment -b/--batch-size Max: 131072, default: 5000 Maximum number of genomes in each batch If the number of input files exceeds this number, input files are split into multiple batches and indexes are built for all batches. In the end, seed files are merged, while genome data files are kept unchanged and collected. ■ Bigger values increase indexing memory occupation and increase batch searching speed, while single query searching speed is not affected. LexicHash mask generation Flag Value Function Comment -M/--mask-file A file File with custom masks File with custom masks, which could be exported from an existing index or newly generated by \u0026ldquo;lexicmap utils masks\u0026rdquo;. This flag oversides -k/--kmer, -m/--masks, -s/--rand-seed, etc. -k/--kmer Max: 32, default: 31 K-mer size ■ Bigger values improve the search specificity and do not increase the index size. -m/--masks Default: 20,000 Number of masks ■ Bigger values improve the search sensitivity slightly, increase the index size, and slow down the search speed. For smaller genomes like phages/viruses, m=5,000 is high enough. Seeds (k-mer-value) data Flag Value Function Comment --seed-max-desert Default: 100 Maximum length of distances between seeds The default value of 100 guarantees queries \u0026gt;=200 bp would match at least two seeds. ► Large regions with no seeds are called sketching deserts. Deserts with seed distance larger than this value will be filled by choosing k-mers roughly every \u0026ndash;seed-in-desert-dist (50 by default) bases. ■ Bigger values decrease the search sensitivity for distant targets, speed up the indexing speed, decrease the indexing memory occupation and decrease the index size. While the alignment speed is almost not affected. -c/--chunks Maximum: 128, default: value of -j/\u0026ndash;threads Number of seed file chunks Bigger values accelerate the search speed at the cost of a high disk reading load. ► The value should not exceed the maximum number of open files set by the operating systems. ► Make sure the value of -j/--threads in lexicmap search is \u0026gt;= this value. -J/--seed-data-threads Maximum: -c/\u0026ndash;chunks, default: 8 Number of threads for writing seed data and merging seed chunks from all batches The actual value is min(\u0026ndash;seed-data-threads, max(1, \u0026ndash;max-open-files/($batches_1_round + 2))), where $batches_1_round = min(int($input_files / \u0026ndash;batch-size), \u0026ndash;max-open-files). ■ Bigger values increase indexing speed at the cost of slightly higher memory occupation. -p/--partitions Default: 4096 Number of partitions for indexing each seed file Bigger values bring a little higher memory occupation. ► After indexing, lexicmap utils reindex-seeds can be used to reindex the seeds data with another value of this flag. --max-open-files Default: 1024 Maximum number of open files It\u0026rsquo;s only used in merging indexes of multiple genome batches. If there are \u0026gt;100 batches, i.e., ($input_files / \u0026ndash;batch-size), please increase this value and set a bigger ulimit -n in shell. Also see the usage of lexicmap index.\nNotes for indexing with large datasets If you have hundreds of thousands of input genomes or more, it\u0026rsquo;s better to control the number of genome batches, which can be calculated via\n$num_input_files / --batch-size E.g, for GenBank prokaryotic genomes: 2,340,672 / 5000 (default) = 468. The number is too big, and it would slow down the seed-data merging step in lexicmap index and candidate sequence extraction in lexicmap search.\nTherefore, if you have enough memory, you can set a bigger --batch-size (e.g., 2,340,672 / 25000 = 93.6).\nIf the batch number is still big (e.g. 300), you can set bigger --max-open-files (e.g., 4096) and -J/--seed-data-threads (e.g., 12. 12 \u0026lt;= 4096/300 = 13.6) to accelerate the merging step. Meanwhile, don\u0026rsquo;t forget to increase the maximum open files per process via ulimit -n 4096.\nIf you forgot these setting, you can rerun the merging step for an unfinished index via lexicmap utils remerge (available since v0.5.0, also see FAQ: how to resume the indexing). Other cases to use this command:\nOnly one thread is used for merging indexes, which happens when there are a lot (\u0026gt;200 batches) of batches ($inpu_files / --batch-size) and the value of --max-open-files is not big enough. The Slurm/PBS job time limit is almost reached and the merging step won\u0026rsquo;t be finished before that. Disk quota is reached in the merging step. Steps We use a small dataset for demonstration.\nPreparing the test genomes (15 bacterial genomes) in the refs directory.\nNote that the genome files contain the assembly accessions (ID) in the file names.\ngit clone https://github.com/shenwei356/LexicMap cd LexicMap/demo/ ls refs/ GCF_000006945.2.fa.gz GCF_000392875.1.fa.gz GCF_001096185.1.fa.gz GCF_002949675.1.fa.gz GCF_006742205.1.fa.gz GCF_000017205.1.fa.gz GCF_000742135.1.fa.gz GCF_001457655.1.fa.gz GCF_002950215.1.fa.gz GCF_009759685.1.fa.gz GCF_000148585.2.fa.gz GCF_001027105.1.fa.gz GCF_001544255.1.fa.gz GCF_003697165.2.fa.gz GCF_900638025.1.fa.gz Building an index with genomes from a directory.\nlexicmap index -I refs/ -O demo.lmi It would take about 6 seconds and 3 GB RAM in a 16-CPU PC.\nOptionally, we can also use a file list as the input.\n$ head -n 3 files.txt refs/GCF_000006945.2.fa.gz refs/GCF_000017205.1.fa.gz refs/GCF_000148585.2.fa.gz lexicmap index -S -X files.txt -O demo.lmi Click to show the log of a demo run. ... # here we set a small --batch-size 5 $ lexicmap index -I refs/ -O demo.lmi --batch-size 5 09:44:36.593 [INFO] LexicMap v0.7.0 09:44:36.593 [INFO] https://github.com/shenwei356/LexicMap 09:44:36.593 [INFO] 09:44:36.593 [INFO] checking input files ... 09:44:36.593 [INFO] scanning files from directory: refs/ 09:44:36.593 [INFO] 15 input file(s) given 09:44:36.593 [INFO] 09:44:36.593 [INFO] --------------------- [ main parameters ] --------------------- 09:44:36.593 [INFO] 09:44:36.593 [INFO] input and output: 09:44:36.593 [INFO] input directory: refs/ 09:44:36.593 [INFO] regular expression of input files: (?i)\\.(f[aq](st[aq])?|fna)(\\.gz|\\.xz|\\.zst|\\.bz2)?$ 09:44:36.593 [INFO] *regular expression for extracting reference name from file name: (?i)(.+)\\.(f[aq](st[aq])?|fna)(\\.gz|\\.xz|\\.zst|\\.bz2)?$ 09:44:36.593 [INFO] *regular expressions for filtering out sequences: [] 09:44:36.593 [INFO] min sequence length: 31 09:44:36.593 [INFO] max genome size: 15000000 09:44:36.593 [INFO] output directory: demo.lmi 09:44:36.593 [INFO] 09:44:36.593 [INFO] mask generation: 09:44:36.593 [INFO] k-mer size: 31 09:44:36.593 [INFO] number of masks: 20000 09:44:36.593 [INFO] rand seed: 1 09:44:36.593 [INFO] 09:44:36.593 [INFO] seed data: 09:44:36.593 [INFO] maximum sketching desert length: 100 09:44:36.593 [INFO] distance of k-mers to fill deserts: 50 09:44:36.593 [INFO] seeds data chunks: 16 09:44:36.593 [INFO] seeds data indexing partitions: 4096 09:44:36.593 [INFO] 09:44:36.593 [INFO] general: 09:44:36.593 [INFO] genome batch size: 5 09:44:36.593 [INFO] threads: 16 09:44:36.593 [INFO] batch merge threads: 8 09:44:36.593 [INFO] 09:44:36.593 [INFO] 09:44:36.593 [INFO] --------------------- [ generating masks ] --------------------- 09:44:36.598 [INFO] 09:44:36.598 [INFO] --------------------- [ building index ] --------------------- 09:44:36.778 [INFO] 09:44:36.778 [INFO] ------------------------[ batch 1/3 ]------------------------ 09:44:36.778 [INFO] building index for batch 1 with 5 files... processed files: 5 / 5 [======================================] ETA: 0s. done 09:44:39.270 [INFO] writing seeds... 09:44:39.354 [INFO] finished writing seeds in 83.439262ms 09:44:39.354 [INFO] finished building index for batch 1 in: 2.575661773s 09:44:39.354 [INFO] 09:44:39.354 [INFO] ------------------------[ batch 2/3 ]------------------------ 09:44:39.354 [INFO] building index for batch 2 with 5 files... processed files: 5 / 5 [======================================] ETA: 0s. done 09:44:41.913 [INFO] writing seeds... 09:44:41.975 [INFO] finished writing seeds in 61.478898ms 09:44:41.975 [INFO] finished building index for batch 2 in: 2.621098554s 09:44:41.975 [INFO] 09:44:41.975 [INFO] ------------------------[ batch 3/3 ]------------------------ 09:44:41.975 [INFO] building index for batch 3 with 5 files... processed files: 5 / 5 [======================================] ETA: 0s. done 09:44:44.421 [INFO] writing seeds... 09:44:44.489 [INFO] finished writing seeds in 67.328842ms 09:44:44.489 [INFO] finished building index for batch 3 in: 2.513863923s 09:44:44.489 [INFO] 09:44:44.489 [INFO] merging 3 indexes... 09:44:44.489 [INFO] [round 1] 09:44:44.489 [INFO] batch 1/1, merging 3 indexes to demo.lmi.tmp/r1_b1 with 8 threads... 09:44:44.691 [INFO] [round 1] finished in 201.445296ms 09:44:44.691 [INFO] rename demo.lmi.tmp/r1_b1 to demo.lmi 09:44:44.708 [INFO] 09:44:44.708 [INFO] finished building LexicMap index from 15 files with 20000 masks in 8.115840913s 09:44:44.708 [INFO] LexicMap index saved: demo.lmi 09:44:44.708 [INFO] 09:44:44.708 [INFO] elapsed time: 8.115880865s 09:44:44.708 [INFO] Output The LexicMap index is a directory with multiple files.\nFile structure $ tree demo.lmi/ demo.lmi/ # the index directory ├── genomes # directory of genome data │ ├── batch_0000 # genome data of one batch │ │ ├── genomes.bin # genome data file, containing genome ID, size, sequence lengths, bit-packed sequences │ │ └── genomes.bin.idx # index of genome data file, for fast subsequence extraction │ └── batch_0001 │ │ ├── genomes.bin │ │ └── genomes.bin.idx │ ... ... ├── seeds # seed data: pairs of k-mer and its location information (genome batch, genome number, location, strand) │ ├── chunk_000.bin # seed data file │ ├── chunk_000.bin.idx # index of seed data file, for fast seed searching and data extraction │ ... ... │ ├── chunk_015.bin # the number of chunks is set by flag `-c/--chunks`, default: #cpus │ └── chunk_015.bin.idx ├── genomes.chunks.bin # lists of genome chunks which belong to the same genome ├── genomes.map.bin # mapping genome ID to batch number and genome number in the batch ├── info.toml # summary of the index └── masks.bin # mask data Index size LexicMap index size is related to the number of input genomes, the divergence between genome sequences, the number of masks, and the maximum seed distance.\nNote that the index size is not linear with the number of genomes, it\u0026rsquo;s sublinear. Because the seed data are compressed with VARINT-GB algorithm, more genome bring smaller compression rates (smaller is good).\nDemo data # 15 genomes, 54 Mb (54,142,446 bp) demo.lmi/: 78.36 MiB (82,165,269) 65.26 MiB seeds 12.94 MiB genomes 156.28 KiB masks.bin 600 B info.toml 375 B genomes.map.bin 0 B genomes.chunks.bin GTDB repr # 85,205 genomes, 274 Gbp (273,848,490,566 bp) gtdb_repr.lmi: 213.27 GiB (228,999,914,466) 146.49 GiB seeds 66.78 GiB genomes 2.03 MiB genomes.map.bin 156.28 KiB masks.bin 613 B info.toml 48 B genomes.chunks.bin GTDB complete # 402,538 genomes, 1.5 Tbp (1,501,864,915,560 bp) gtdb_complete.lmi: 905.34 GiB (972,098,200,328) 542.34 GiB seeds 362.99 GiB genomes 9.60 MiB genomes.map.bin 156.28 KiB masks.bin 616 B info.toml 168 B genomes.chunks.bin GenBank\u0026#43;RefSeq # 2,340,672 genomes, 9.2 Tbp (9,192,651,650,196 bp) genbank_refseq.lmi: 4.96 TiB (5,454,659,703,138) 2.79 TiB seeds 2.17 TiB genomes 55.81 MiB genomes.map.bin 156.28 KiB masks.bin 3.59 KiB genomes.chunks.bin 619 B info.toml AllTheBacteria HQ # 1,858,610 genomes, 7.5 Tbp (7,493,622,021,123 bp) atb_hq.lmi: 3.91 TiB (4,304,515,140,156) 2.15 TiB seeds 1.77 TiB genomes 39.22 MiB genomes.map.bin 156.28 KiB masks.bin 619 B info.toml 24 B genomes.chunks.bin Directory/file sizes are counted with https://github.com/shenwei356/dirsize v1.2.1 (dirsize $file, base: 1024). Index building parameters: -k 31 -m 20000 -D 100 -d 50. Genome batch size: -b 25000 for GenBank+RefSeq and AllTheBacteria datasets, -b 5000 (default) for others. Explore the index We provide several commands to explore the index data and extract indexed subsequences:\nlexicmap utils genomes can list genome IDs of indexed genomes, see the usage and example. lexicmap utils masks can list masks of the index, see the usage and example. lexicmap utils kmers can list details of all seeds (k-mers), including reference, location(s), the strand, and the k-mer direction. see the usage and example. lexicmap utils seed-pos can help to explore the seed positions, see the usage and example. Before that, the flag --save-seed-pos needs to be added to lexicmap index. lexicmap utils subseq can extract subsequences via genome ID, sequence ID and positions, see the usage and example. What\u0026rsquo;s next: Searching ","description":" Note Terminology differences:\nOn this page and in the LexicMap command line options, the term \u0026ldquo;mask\u0026rdquo; is used, following the terminology in the LexicHash paper. In the LexicMap manuscript, however, we use \u0026ldquo;probe\u0026rdquo; as it is easier to understand. Because these masks, which consist of thousands of k-mers and capture k-mers from sequences through prefix matching, function similarly to DNA probes in molecular biology. Table of contents Table of contents TL;DR Input Hardware requirements Algorithm Parameters Notes for indexing with large datasets Steps Output File structure Index size Explore the index TL;DR Prepare input files: Sequences of each reference genome should be saved in separate FASTA files, with identifiers (no tab symbols) in the file names. E.g., GCF_000006945.2.fna.gz A regular expression is also available to extract reference id from the file name. E.g., --ref-name-regexp '^(\\w{3}_\\d{9}\\.\\d+)' extracts GCF_000006945.2 from GenBank assembly file GCF_000006945.2_ASM694v2_genomic.fna.gz While if you save a few small (viral) complete genomes (one sequence per genome) in each file, it\u0026rsquo;s feasible as sequence IDs in search result can help to distinguish target genomes. Run: From a directory with multiple genome files:\n"},{"id":29,"href":"/LexicMap/tags/","title":"Tags","parent":"","content":"","description":""}]